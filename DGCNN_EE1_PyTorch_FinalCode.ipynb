{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XS_6buTBwPl"
      },
      "source": [
        "### **Import and Install Libraries. Download Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2WB_AlhDx9_",
        "outputId": "11a539d4-1537-4342-d5e8-6d8b6fa25419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rZLVYrPJeOk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "from scipy.stats import entropy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "import sklearn.metrics as metrics\n",
        "import copy\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UH_X_YHfYkK",
        "outputId": "435b5384-9468-4d37-c30c-ce9de7c72178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-26 03:51:35--  https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435212151 (415M) [application/zip]\n",
            "Saving to: ‘modelnet40_ply_hdf5_2048.zip’\n",
            "\n",
            "modelnet40_ply_hdf5 100%[===================>] 415.05M  35.0MB/s    in 10s     \n",
            "\n",
            "2024-04-26 03:51:46 (39.6 MB/s) - ‘modelnet40_ply_hdf5_2048.zip’ saved [435212151/435212151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
        "!unzip -q modelnet40_ply_hdf5_2048.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ekUukrU6v2Kz"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore specific warnings related to multiprocessing and os.fork\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\".*os.fork.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fTRjk6Lp_cJW"
      },
      "outputs": [],
      "source": [
        "#Class for your arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.exp_name = 'exp'\n",
        "        self.model = 'dgcnn'\n",
        "        self.dataset = 'modelnet40'\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 16\n",
        "        self.epochs = 250\n",
        "        self.use_sgd = True\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.9\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.eval = False\n",
        "        self.num_points = 1024\n",
        "        self.dropout = 0.5\n",
        "        self.emb_dims = 1024\n",
        "        self.k = 10\n",
        "        self.model_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERQ6I6HnfprZ"
      },
      "outputs": [],
      "source": [
        "#Method to retrieve your training and testing files\n",
        "def getDataFiles(list_filename):\n",
        "    print(list_filename)\n",
        "    return [line.rstrip() for line in open(list_filename)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8yn70xofrpU",
        "outputId": "04eee836-2a52-400a-ba3c-4b939c98a35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/modelnet40_ply_hdf5_2048/train_files.txt\n",
            "data/modelnet40_ply_hdf5_2048/test_files.txt\n"
          ]
        }
      ],
      "source": [
        "#Store your dataset in the folder 'data'\n",
        "import shutil\n",
        "os.mkdir('data')\n",
        "shutil.move('modelnet40_ply_hdf5_2048', 'data')\n",
        "TRAIN_FILES = getDataFiles( \\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/train_files.txt'))\n",
        "TEST_FILES = getDataFiles(\\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/test_files.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3sIrLnpFg5Gk"
      },
      "outputs": [],
      "source": [
        "def cal_loss(pred, gold, smoothing=True):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.2\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "    else:\n",
        "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7Te875Og7xc"
      },
      "outputs": [],
      "source": [
        "class IOStream():\n",
        "    \"\"\"\n",
        "    A utility class for outputting text to both console and a file. This class provides a method to concurrently print\n",
        "    information to the console and append it to a file. This can be particularly useful for logging purposes in\n",
        "    applications like long-running processes where monitoring and retaining output history is necessary.\n",
        "\n",
        "    Attributes:\n",
        "    f (file object): File object used to append text to the specified file.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initialize the IOStream by opening or creating a file for appending text.\n",
        "\n",
        "        Parameters:\n",
        "        path (str): The file path where text will be appended. If the file does not exist, it will be created.\n",
        "        \"\"\"\n",
        "        self.f = open(path, 'a')  # Open the file in append mode.\n",
        "\n",
        "    def cprint(self, text):\n",
        "        \"\"\"\n",
        "        Prints text to the console and appends it to the file initialized in this class instance.\n",
        "\n",
        "        Parameters:\n",
        "        text (str): The text to be printed and logged.\n",
        "        \"\"\"\n",
        "        print(text)  # Print text to console.\n",
        "        self.f.write(text + '\\n')  # Append text to file and add a newline.\n",
        "        self.f.flush()  # Flush the internal buffer, ensuring all file operations are completed immediately.\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Closes the file associated with this instance. It is important to call this method to free up system resources.\n",
        "        \"\"\"\n",
        "        self.f.close()  # Close the file to release resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH-3GRMgB4eu"
      },
      "source": [
        "### **Calculate 10 k-nearest neighbors based on the Euclidean distance $(x_1-x_2)^2$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jJz0UTK3h2pV"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    # print(idx[1,:,1].size, 'idx of knn')\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbIW2MZCCEwy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "soeA9B4Nh3cr"
      },
      "outputs": [],
      "source": [
        "def get_graph_feature(x, k=10, idx=None):\n",
        "    # print(x.shape, 'Input x to get_graph_feature')\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "    # print(idx)\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "    # print(idx[1,1,:], 'idx of get_graph_feature')\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36SyVuaCKTb"
      },
      "source": [
        "### **DGCNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JU0hruirh9Xt"
      },
      "outputs": [],
      "source": [
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=args.dropout)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=args.dropout)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j48wtIIvVID2"
      },
      "source": [
        "### **DGCNN EE1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZhsO2Y5HjpKN"
      },
      "outputs": [],
      "source": [
        "class eeModel_E1(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(eeModel_E1, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        ################################Base Model###################################\n",
        "        self.baseModelconv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                       self.bn1,\n",
        "                                       nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        #############################################################################\n",
        "\n",
        "        #############################Short Branch####################################\n",
        "        self.shortBranch = nn.Sequential(nn.Linear(128*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ################################################################################\n",
        "\n",
        "        ####################################Long Branch#################################\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.longBranch_fc = nn.Sequential(nn.Linear(args.emb_dims*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ####################################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x_baseModelconv1 = self.baseModelconv1(get_graph_feature(x, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv2 = self.baseModelconv2(get_graph_feature(x_baseModelconv1, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModel = torch.cat((x_baseModelconv1, x_baseModelconv2), dim=1)\n",
        "        x_shortBranch, x_longBranch = self.get_short_branch_output(x_baseModel, batch_size), self.get_long_branch_output(x_baseModelconv1, x_baseModelconv2, batch_size)\n",
        "        return x_shortBranch, x_longBranch\n",
        "\n",
        "    def get_short_branch_output(self, x_baseModel, batch_size):\n",
        "        x_shortBranch = self.shortBranch(torch.cat((F.adaptive_max_pool1d(x_baseModel, 1).view(batch_size, -1),\n",
        "                                                    F.adaptive_avg_pool1d(x_baseModel, 1).view(batch_size, -1)), 1))\n",
        "        return x_shortBranch\n",
        "\n",
        "    def get_long_branch_output(self, x_baseModelconv1, x_baseModelconv2, batch_size):\n",
        "        x3_longBranch = self.conv3(get_graph_feature(x_baseModelconv2, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x4_longBranch = self.conv4(get_graph_feature(x3_longBranch, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_longBranch = self.conv5(torch.cat((x_baseModelconv1, x_baseModelconv2, x3_longBranch, x4_longBranch), dim=1))\n",
        "        x_longBranch = torch.cat((F.adaptive_max_pool1d(x_longBranch, 1).view(batch_size, -1),\n",
        "                                  F.adaptive_avg_pool1d(x_longBranch, 1).view(batch_size, -1)), 1)\n",
        "        x_longBranch = self.longBranch_fc(x_longBranch)\n",
        "        return x_longBranch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4AgLkE_7e1NL"
      },
      "outputs": [],
      "source": [
        "def load_data(partition):\n",
        "    \"\"\"\n",
        "    Load pointcloud data and labels from HDF5 files based on the specified partition (train or test).\n",
        "    This function is designed to work within a filesystem structure expected for ModelNet40 dataset files,\n",
        "    aggregating data from multiple files into a single array for both data points and labels.\n",
        "\n",
        "    Parameters:\n",
        "    partition (str): Specifies which dataset partition to load. Expected values are 'train' or 'test'.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy arrays: one for the data (pointclouds) and one for the labels.\n",
        "    \"\"\"\n",
        "    # Define base directory relative to this script's location.\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(r'\\data\\modelnet40_ply_hdf5_2048'))\n",
        "    # Define data directory path combining base directory with the data subdirectory.\n",
        "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "\n",
        "    # Initialize lists to hold data and labels from all files.\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "\n",
        "    # Loop over each file matching the pattern for the specified partition.\n",
        "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', f'ply_data_{partition}*.h5')):\n",
        "        # Open the HDF5 file for reading.\n",
        "        f = h5py.File(h5_name)\n",
        "        # Load all data points as float32 and labels as int64 from the file.\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        # Ensure the file is closed after its contents are loaded.\n",
        "        f.close()\n",
        "\n",
        "        # Append the data and labels to their respective lists.\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "\n",
        "    # Concatenate all data and labels from the list into single numpy arrays.\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "\n",
        "    # Return the aggregated data and labels.\n",
        "    return all_data, all_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b4AH8w7Ke6Nt"
      },
      "outputs": [],
      "source": [
        "def translate_pointcloud(pointcloud):\n",
        "    \"\"\"\n",
        "    Apply a random translation to a pointcloud. This is done by first scaling the pointcloud with a random factor\n",
        "    and then adding a small random shift. This can be used as a data augmentation technique to make models robust\n",
        "    to variations in object position and scale.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, 3) where N is the number of points.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The translated pointcloud as a new numpy array of type 'float32'.\n",
        "    \"\"\"\n",
        "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])  # Random scaling factors.\n",
        "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])    # Random translation offsets.\n",
        "\n",
        "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')  # Apply scaling and translation\n",
        "    return translated_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nB31Q97vf4bN"
      },
      "outputs": [],
      "source": [
        "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):\n",
        "    \"\"\"\n",
        "    Apply Gaussian noise to a pointcloud. Each point's position is altered by adding a noise vector drawn from a\n",
        "    Gaussian distribution, clipped to a maximum magnitude to prevent excessive perturbation. This augmentation\n",
        "    promotes robustness to small variations or noise.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, C) where N is the number of points and C is the number of coordinates.\n",
        "    sigma (float): Standard deviation of the Gaussian noise.\n",
        "    clip (float): Maximum allowed value for noise applied to the point coordinates.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The jittered pointcloud.\n",
        "    \"\"\"\n",
        "    N, C = pointcloud.shape  # Number of points N and dimensions C in the pointcloud.\n",
        "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)  # Add clipped Gaussian noise.\n",
        "    return pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rGxrJjODf7iU"
      },
      "outputs": [],
      "source": [
        "class ModelNet40(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for ModelNet40, which includes methods for loading and preprocessing pointcloud data for training or testing.\n",
        "    Data augmentation (translation and shuffling) is applied to training data to improve model generalization.\n",
        "\n",
        "    Attributes:\n",
        "    num_points (int): Number of points per pointcloud to use.\n",
        "    partition (str): Dataset partition to use, either 'train' or 'test'.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points, partition='train'):\n",
        "        \"\"\"\n",
        "        Initialize the dataset object, loading data and labels according to the specified partition.\n",
        "\n",
        "        Parameters:\n",
        "        num_points (int): Number of points to sample from each pointcloud.\n",
        "        partition (str): Which dataset partition to use, 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        self.data, self.label = load_data(partition)  # Load dataset.\n",
        "        self.num_points = num_points  # Points per pointcloud.\n",
        "        self.partition = partition  # Dataset partition.\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Retrieve a pointcloud and its label, applying data augmentation if in training mode.\n",
        "\n",
        "        Parameters:\n",
        "        item (int): Index of the pointcloud to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Tuple containing the pointcloud and its label.\n",
        "        \"\"\"\n",
        "        pointcloud = self.data[item][:self.num_points]  # Get the subset of points.\n",
        "        label = self.label[item]\n",
        "        if self.partition == 'train':  # Conditionally apply augmentations.\n",
        "            pointcloud = translate_pointcloud(pointcloud)\n",
        "            np.random.shuffle(pointcloud)  # Shuffle points to remove any order bias.\n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of pointclouds in the dataset.\n",
        "\n",
        "        Returns:\n",
        "        int: The number of pointclouds.\n",
        "        \"\"\"\n",
        "        return self.data.shape[0]  # Number of pointclouds in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eaxTC3jlNufT"
      },
      "outputs": [],
      "source": [
        "# Dictionary for ModelNet40 classes. Helpful when printing confusion matrix. Note that ModelNet40 sorts its classes alphabetically\n",
        "label_dict = {\n",
        "    'airplane': 0,\n",
        "    'bathtub': 1,\n",
        "    'bed': 2,\n",
        "    'bench': 3,\n",
        "    'bookshelf': 4,\n",
        "    'bottle': 5,\n",
        "    'bowl': 6,\n",
        "    'car': 7,\n",
        "    'chair': 8,\n",
        "    'cone': 9,\n",
        "    'cup': 10,\n",
        "    'curtain': 11,\n",
        "    'desk': 12,\n",
        "    'door': 13,\n",
        "    'dresser': 14,\n",
        "    'flower_pot': 15,\n",
        "    'glass_box': 16,\n",
        "    'guitar': 17,\n",
        "    'keyboard': 18,\n",
        "    'lamp': 19,\n",
        "    'laptop': 20,\n",
        "    'mantel': 21,\n",
        "    'monitor': 22,\n",
        "    'night_stand': 23,\n",
        "    'person': 24,\n",
        "    'piano': 25,\n",
        "    'plant': 26,\n",
        "    'radio': 27,\n",
        "    'range_hood': 28,\n",
        "    'sink': 29,\n",
        "    'sofa': 30,\n",
        "    'stairs': 31,\n",
        "    'stool': 32,\n",
        "    'table': 33,\n",
        "    'tent': 34,\n",
        "    'toilet': 35,\n",
        "    'tv_stand': 36,\n",
        "    'vase': 37,\n",
        "    'wardrobe': 38,\n",
        "    'xbox': 39\n",
        "}\n",
        "modes = list(label_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMOAvhfCU2r"
      },
      "source": [
        "### **Training and Testing algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gYGrRCMWgBGG"
      },
      "outputs": [],
      "source": [
        "def train(args, io):\n",
        "    # 1. Determine the size of the original training dataset\n",
        "    total_train_samples = len(ModelNet40(partition='train', num_points=args.num_points))\n",
        "    train_size = int(0.75 * total_train_samples)  # 60% of the original training dataset\n",
        "    validation_size = total_train_samples - train_size  # Remaining samples for validation\n",
        "\n",
        "    # 2. Split the original training dataset\n",
        "    train_dataset, validation_dataset = random_split(ModelNet40(partition='train', num_points=args.num_points), [train_size, validation_size])\n",
        "\n",
        "    # 3. Create DataLoader for the training and validation datasets\n",
        "    train_loader = DataLoader(train_dataset, num_workers=2, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    validation_loader = DataLoader(validation_dataset, num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    # Test DataLoader remains unchanged\n",
        "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "    history = {\"1\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"2\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"T\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}}}\n",
        "    loss1_list = []\n",
        "    loss2_list = []\n",
        "    acc1_list = []\n",
        "    acc2_list = []\n",
        "    eStopThreshold, eStopCounter = 8, 0\n",
        "    device = \"cuda\" # Set up your NVIDIA GPU.\n",
        "    model = eeModel_E1(args).to(device) #Initialize your model.\n",
        "    print(summary(model))## Print your model summary.\n",
        "    print(\"Let's use\", torch.cpu.device_count(), \"GPUs!\") ## Print how many GPUs are being used.\n",
        "\n",
        "    #Set up your optimizer and loss\n",
        "    if args.use_sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        loss1Total, loss2Total, totalLoss = 0, 0, 0\n",
        "        acc1Total, acc2Total, totalAcc = 0, 0, 0\n",
        "        loss1Total_v, loss2Total_v, valLoss = 0, 0, 0\n",
        "        acc1Total_v, acc2Total_v, valAcc = 0, 0, 0\n",
        "        train_loss = 0.0\n",
        "        loss = 0\n",
        "        bestAcc = 0\n",
        "        best_loss = 100\n",
        "        preValLoss = 100\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data, label in train_loader:\n",
        "            data, label = data.to(device), label.to(device).squeeze() # Send your input data and label to device e.g. GPU\n",
        "            data = data.permute(0, 2, 1) # Permute your data for subsequent operations\n",
        "            batch_size = data.size()[0] # Retrieve your batch size\n",
        "            opt.zero_grad() # Zero your optimizer\n",
        "            logits1, logits2 = model(data) # Compute unnormalized model outputs e.g. short branch and long branch outputs\n",
        "            loss1, loss2 = criterion(logits1, label), criterion(logits2, label) # Calculate your losses e.g. short branch and long branch losses\n",
        "            loss1_list.append(loss1.item()) # Append your short branch losses\n",
        "            loss2_list.append(loss2.item()) # Append your long branch losses\n",
        "            loss1Total += loss1.item() # Aggregate your short branch losses\n",
        "            loss2Total += loss2.item() # Aggregate your long branch losses\n",
        "            totalLoss += 0.5*loss1.item() + 0.5*loss2.item() # Average your loss\n",
        "            loss1.backward(retain_graph=True) # Backward propagate your short branch loss\n",
        "            loss2.backward(retain_graph=True) # Backward propagate your long branch loss\n",
        "            _, predicted1 = torch.max(logits1, 1) # Max pool your short branch predicitions\n",
        "            _, predicted2 = torch.max(logits2, 1) # Max pool your long branch predicitions\n",
        "            acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy()) # Calculate your short branch accuracy\n",
        "            acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy()) # Calculate your long branch accurac\n",
        "            acc1_list.append(acc1) # Append your short branch accuracies\n",
        "            acc2_list.append(acc2) # Append your long branch accuracies\n",
        "            acc1Total += acc1 # Aggregate your short branch accuracies\n",
        "            acc2Total += acc2 # Aggregate your long branch accuracies\n",
        "            totalAcc += 0.5*acc1+0.5*acc2 # Average your accuracy\n",
        "            opt.step() # Step your optimizer\n",
        "            count += batch_size # Recursively add number of prediciton counts\n",
        "        loss1Total = loss1Total/len(train_loader) # Normalize your short branch losses\n",
        "        loss2Total = loss2Total/len(train_loader) # Normalize your long branch losses\n",
        "        totalLoss = totalLoss/len(train_loader) # Normalize your total loss\n",
        "        acc1Total = acc1Total/len(train_loader) # Normalize your short branch accuracy\n",
        "        acc2Total = acc2Total/len(train_loader) # Normalize your long branch accuracy\n",
        "        totalAcc = totalAcc/len(train_loader) # Normalize your total accuracy\n",
        "        ############## Append to your history dictionaty################\n",
        "        history[\"1\"][\"train\"][\"loss\"].append(loss1Total)\n",
        "        history[\"1\"][\"train\"][\"accuracy\"].append(acc1Total)\n",
        "        history[\"2\"][\"train\"][\"loss\"].append(loss2Total)\n",
        "        history[\"2\"][\"train\"][\"accuracy\"].append(acc2Total)\n",
        "        history[\"T\"][\"train\"][\"loss\"].append(totalLoss)\n",
        "        history[\"T\"][\"train\"][\"accuracy\"].append(totalAcc)\n",
        "        ###############################################################\n",
        "        print(\"epoch {} --> trainLoss: {:0.3f}, trainAcc: {:0.3f}\" # Print your epoch, total normalized loss, total normalized accuracy.\n",
        "                  .format(epoch+1, totalLoss, totalAcc), end=\"\")\n",
        "\n",
        "        ####################### Validation is identical training####################\n",
        "        if validation_loader:\n",
        "          with torch.no_grad():\n",
        "            model.eval() # Set up your model for evaluation\n",
        "            for data, label in validation_loader:\n",
        "              data, label = data.to(device), label.to(device).squeeze()\n",
        "              data = data.permute(0, 2, 1)\n",
        "              batch_size = data.size()[0]\n",
        "              opt.zero_grad()\n",
        "              logits1, logits2 = model(data) ## ADD TWO LOGITS\n",
        "\n",
        "              loss1, loss2 = criterion(logits1, label.long()), criterion(logits2, label.long())\n",
        "              loss1Total_v += loss1.item()\n",
        "              loss2Total_v += loss2.item()\n",
        "              valLoss += 0.5*loss1.item() + 0.5*loss2.item()\n",
        "\n",
        "              _, predicted1 = torch.max(logits1, 1)\n",
        "              _, predicted2 = torch.max(logits2, 1)\n",
        "              acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy())\n",
        "              acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy())\n",
        "\n",
        "              acc1Total_v += acc1\n",
        "              acc2Total_v += acc2\n",
        "              valAcc += 0.5*acc1 + 0.5*acc2\n",
        "\n",
        "            loss1Total_v = loss1Total_v/len(validation_loader)\n",
        "            loss2Total_v = loss2Total_v/len(validation_loader)\n",
        "            valLoss = valLoss/len(validation_loader)\n",
        "            acc1Total_v = acc1Total_v/len(validation_loader)\n",
        "            acc2Total_v = acc2Total_v/len(validation_loader)\n",
        "            valAcc = valAcc/len(validation_loader)\n",
        "\n",
        "            history[\"1\"][\"validation\"][\"loss\"].append(loss1Total_v)\n",
        "            history[\"1\"][\"validation\"][\"accuracy\"].append(acc1Total_v)\n",
        "            history[\"2\"][\"validation\"][\"loss\"].append(loss2Total_v)\n",
        "            history[\"2\"][\"validation\"][\"accuracy\"].append(acc2Total_v)\n",
        "            history[\"T\"][\"validation\"][\"loss\"].append(valLoss)\n",
        "            history[\"T\"][\"validation\"][\"accuracy\"].append(valAcc)\n",
        "\n",
        "          print(\", validLoss: {:0.3f}, validAcc: {:0.3f}\"\n",
        "                  .format(valLoss, valAcc))\n",
        "#############Save best performing model if current test accuracy outperforms the recorded best accuracy#############\n",
        "          if valLoss <= best_loss:\n",
        "            # Save the model with the lowest validation loss.\n",
        "            best_loss = valLoss\n",
        "            torch.save(model.state_dict(), 'checkpoints/%s/models/model.pth' % args.exp_name)\n",
        "            print(\"Model Saved!\")\n",
        "#####################################################################################################################\n",
        "\n",
        "########################Stop training if validation loss is increasing#############################\n",
        "          if valLoss >= preValLoss:\n",
        "            eStopCounter += 1\n",
        "            if eStopCounter >= eStopThreshold:\n",
        "              print(\"Training Stopped!\")\n",
        "              break;\n",
        "          else:\n",
        "            eStopCounter = 0\n",
        "          preValLoss = valLoss\n",
        "        else:\n",
        "          print(\"\")\n",
        "#####################################################################################################\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oy1DG9OAlwYg"
      },
      "outputs": [],
      "source": [
        "train_demo = ModelNet40(1024)\n",
        "test_demo = ModelNet40(1024, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1wNYf788EJk2"
      },
      "outputs": [],
      "source": [
        "#Initialize your hyperparametr arguments\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N05X14SdBmwb",
        "outputId": "7b08ebfe-f58c-42c9-e251-863dc4c10535"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if not os.path.exists('checkpoints'):\n",
        "  os.makedirs('checkpoints')\n",
        "if not os.path.exists('checkpoints/'+args.exp_name):\n",
        "  os.makedirs('checkpoints/'+args.exp_name)\n",
        "if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):\n",
        "  os.makedirs('checkpoints/'+args.exp_name+'/'+'models')\n",
        "os.system('cp main.py checkpoints'+'/'+args.exp_name+'/'+'main.py.backup')\n",
        "os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
        "os.system('cp util.py checkpoints' + '/' + args.exp_name + '/' + 'util.py.backup')\n",
        "os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jKeuCJWJ_Mr9"
      },
      "outputs": [],
      "source": [
        "io = IOStream('checkpoints/' + args.exp_name + '/run.log')\n",
        "args.no_cuda = False\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpAkmrEq0-y",
        "outputId": "2da3c24e-786c-4254-d116-466add1c24de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "eeModel_E1                               --\n",
            "├─BatchNorm2d: 1-1                       128\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─BatchNorm2d: 1-3                       256\n",
            "├─BatchNorm2d: 1-4                       512\n",
            "├─BatchNorm1d: 1-5                       2,048\n",
            "├─Sequential: 1-6                        128\n",
            "│    └─Conv2d: 2-1                       384\n",
            "│    └─BatchNorm2d: 2-2                  (recursive)\n",
            "│    └─LeakyReLU: 2-3                    --\n",
            "├─Sequential: 1-7                        128\n",
            "│    └─Conv2d: 2-4                       8,192\n",
            "│    └─BatchNorm2d: 2-5                  (recursive)\n",
            "│    └─LeakyReLU: 2-6                    --\n",
            "├─Sequential: 1-8                        --\n",
            "│    └─Linear: 2-7                       131,072\n",
            "│    └─BatchNorm1d: 2-8                  1,024\n",
            "│    └─LeakyReLU: 2-9                    --\n",
            "│    └─Dropout: 2-10                     --\n",
            "│    └─Linear: 2-11                      131,328\n",
            "│    └─BatchNorm1d: 2-12                 512\n",
            "│    └─LeakyReLU: 2-13                   --\n",
            "│    └─Dropout: 2-14                     --\n",
            "│    └─Linear: 2-15                      10,280\n",
            "├─Sequential: 1-9                        256\n",
            "│    └─Conv2d: 2-16                      16,384\n",
            "│    └─BatchNorm2d: 2-17                 (recursive)\n",
            "│    └─LeakyReLU: 2-18                   --\n",
            "├─Sequential: 1-10                       512\n",
            "│    └─Conv2d: 2-19                      65,536\n",
            "│    └─BatchNorm2d: 2-20                 (recursive)\n",
            "│    └─LeakyReLU: 2-21                   --\n",
            "├─Sequential: 1-11                       2,048\n",
            "│    └─Conv1d: 2-22                      524,288\n",
            "│    └─BatchNorm1d: 2-23                 (recursive)\n",
            "│    └─LeakyReLU: 2-24                   --\n",
            "├─Sequential: 1-12                       --\n",
            "│    └─Linear: 2-25                      1,048,576\n",
            "│    └─BatchNorm1d: 2-26                 1,024\n",
            "│    └─LeakyReLU: 2-27                   --\n",
            "│    └─Dropout: 2-28                     --\n",
            "│    └─Linear: 2-29                      131,328\n",
            "│    └─BatchNorm1d: 2-30                 512\n",
            "│    └─LeakyReLU: 2-31                   --\n",
            "│    └─Dropout: 2-32                     --\n",
            "│    └─Linear: 2-33                      10,280\n",
            "=================================================================\n",
            "Total params: 2,086,864\n",
            "Trainable params: 2,086,864\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 --> trainLoss: 2.980, trainAcc: 0.368, validLoss: 2.429, validAcc: 0.543\n",
            "Model Saved!\n",
            "epoch 2 --> trainLoss: 2.421, trainAcc: 0.544, validLoss: 2.296, validAcc: 0.593\n",
            "Model Saved!\n",
            "epoch 3 --> trainLoss: 2.283, trainAcc: 0.597, validLoss: 2.194, validAcc: 0.624\n",
            "Model Saved!\n",
            "epoch 4 --> trainLoss: 2.184, trainAcc: 0.646, validLoss: 2.112, validAcc: 0.669\n",
            "Model Saved!\n",
            "epoch 5 --> trainLoss: 2.114, trainAcc: 0.674, validLoss: 2.084, validAcc: 0.694\n",
            "Model Saved!\n",
            "epoch 6 --> trainLoss: 2.064, trainAcc: 0.692, validLoss: 1.947, validAcc: 0.741\n",
            "Model Saved!\n",
            "epoch 7 --> trainLoss: 2.006, trainAcc: 0.720, validLoss: 1.930, validAcc: 0.746\n",
            "Model Saved!\n",
            "epoch 8 --> trainLoss: 1.985, trainAcc: 0.731, validLoss: 1.959, validAcc: 0.728\n",
            "Model Saved!\n",
            "epoch 9 --> trainLoss: 1.946, trainAcc: 0.750, validLoss: 1.907, validAcc: 0.762\n",
            "Model Saved!\n",
            "epoch 10 --> trainLoss: 1.927, trainAcc: 0.758, validLoss: 1.829, validAcc: 0.780\n",
            "Model Saved!\n",
            "epoch 11 --> trainLoss: 1.905, trainAcc: 0.767, validLoss: 1.865, validAcc: 0.760\n",
            "Model Saved!\n",
            "epoch 12 --> trainLoss: 1.890, trainAcc: 0.774, validLoss: 1.848, validAcc: 0.780\n",
            "Model Saved!\n",
            "epoch 13 --> trainLoss: 1.876, trainAcc: 0.779, validLoss: 1.778, validAcc: 0.806\n",
            "Model Saved!\n",
            "epoch 14 --> trainLoss: 1.856, trainAcc: 0.787, validLoss: 1.827, validAcc: 0.783\n",
            "Model Saved!\n",
            "epoch 15 --> trainLoss: 1.851, trainAcc: 0.787, validLoss: 1.800, validAcc: 0.810\n",
            "Model Saved!\n",
            "epoch 16 --> trainLoss: 1.843, trainAcc: 0.789, validLoss: 1.783, validAcc: 0.819\n",
            "Model Saved!\n",
            "epoch 17 --> trainLoss: 1.823, trainAcc: 0.800, validLoss: 1.782, validAcc: 0.808\n",
            "Model Saved!\n",
            "epoch 18 --> trainLoss: 1.828, trainAcc: 0.798, validLoss: 1.781, validAcc: 0.801\n",
            "Model Saved!\n",
            "epoch 19 --> trainLoss: 1.805, trainAcc: 0.808, validLoss: 1.725, validAcc: 0.833\n",
            "Model Saved!\n",
            "epoch 20 --> trainLoss: 1.799, trainAcc: 0.810, validLoss: 1.743, validAcc: 0.822\n",
            "Model Saved!\n",
            "epoch 21 --> trainLoss: 1.806, trainAcc: 0.806, validLoss: 1.728, validAcc: 0.825\n",
            "Model Saved!\n",
            "epoch 22 --> trainLoss: 1.793, trainAcc: 0.811, validLoss: 1.726, validAcc: 0.824\n",
            "Model Saved!\n",
            "epoch 23 --> trainLoss: 1.778, trainAcc: 0.822, validLoss: 1.766, validAcc: 0.813\n",
            "Model Saved!\n",
            "epoch 24 --> trainLoss: 1.773, trainAcc: 0.824, validLoss: 1.695, validAcc: 0.830\n",
            "Model Saved!\n",
            "epoch 25 --> trainLoss: 1.764, trainAcc: 0.825, validLoss: 1.733, validAcc: 0.832\n",
            "Model Saved!\n",
            "epoch 26 --> trainLoss: 1.763, trainAcc: 0.827, validLoss: 1.735, validAcc: 0.824\n",
            "Model Saved!\n",
            "epoch 27 --> trainLoss: 1.770, trainAcc: 0.824, validLoss: 1.684, validAcc: 0.839\n",
            "Model Saved!\n",
            "epoch 28 --> trainLoss: 1.756, trainAcc: 0.833, validLoss: 1.679, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 29 --> trainLoss: 1.756, trainAcc: 0.829, validLoss: 1.704, validAcc: 0.833\n",
            "Model Saved!\n",
            "epoch 30 --> trainLoss: 1.748, trainAcc: 0.836, validLoss: 1.737, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 31 --> trainLoss: 1.741, trainAcc: 0.838, validLoss: 1.703, validAcc: 0.829\n",
            "Model Saved!\n",
            "epoch 32 --> trainLoss: 1.744, trainAcc: 0.832, validLoss: 1.667, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 33 --> trainLoss: 1.738, trainAcc: 0.837, validLoss: 1.683, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 34 --> trainLoss: 1.738, trainAcc: 0.837, validLoss: 1.667, validAcc: 0.854\n",
            "Model Saved!\n",
            "epoch 35 --> trainLoss: 1.724, trainAcc: 0.841, validLoss: 1.684, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 36 --> trainLoss: 1.721, trainAcc: 0.843, validLoss: 1.649, validAcc: 0.858\n",
            "Model Saved!\n",
            "epoch 37 --> trainLoss: 1.720, trainAcc: 0.845, validLoss: 1.709, validAcc: 0.834\n",
            "Model Saved!\n",
            "epoch 38 --> trainLoss: 1.713, trainAcc: 0.846, validLoss: 1.706, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 39 --> trainLoss: 1.717, trainAcc: 0.844, validLoss: 1.664, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 40 --> trainLoss: 1.712, trainAcc: 0.849, validLoss: 1.659, validAcc: 0.858\n",
            "Model Saved!\n",
            "epoch 41 --> trainLoss: 1.708, trainAcc: 0.851, validLoss: 1.695, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 42 --> trainLoss: 1.707, trainAcc: 0.849, validLoss: 1.677, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 43 --> trainLoss: 1.709, trainAcc: 0.850, validLoss: 1.727, validAcc: 0.829\n",
            "Model Saved!\n",
            "epoch 44 --> trainLoss: 1.709, trainAcc: 0.848, validLoss: 1.641, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 45 --> trainLoss: 1.694, trainAcc: 0.858, validLoss: 1.662, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 46 --> trainLoss: 1.698, trainAcc: 0.852, validLoss: 1.628, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 47 --> trainLoss: 1.690, trainAcc: 0.861, validLoss: 1.717, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 48 --> trainLoss: 1.691, trainAcc: 0.857, validLoss: 1.687, validAcc: 0.845\n",
            "Model Saved!\n",
            "epoch 49 --> trainLoss: 1.688, trainAcc: 0.858, validLoss: 1.653, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 50 --> trainLoss: 1.686, trainAcc: 0.860, validLoss: 1.633, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 51 --> trainLoss: 1.677, trainAcc: 0.863, validLoss: 1.671, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 52 --> trainLoss: 1.679, trainAcc: 0.863, validLoss: 1.653, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 53 --> trainLoss: 1.684, trainAcc: 0.859, validLoss: 1.637, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 54 --> trainLoss: 1.677, trainAcc: 0.862, validLoss: 1.629, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 55 --> trainLoss: 1.673, trainAcc: 0.865, validLoss: 1.637, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 56 --> trainLoss: 1.678, trainAcc: 0.864, validLoss: 1.629, validAcc: 0.871\n",
            "Model Saved!\n",
            "epoch 57 --> trainLoss: 1.671, trainAcc: 0.866, validLoss: 1.649, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 58 --> trainLoss: 1.665, trainAcc: 0.866, validLoss: 1.654, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 59 --> trainLoss: 1.669, trainAcc: 0.867, validLoss: 1.634, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 60 --> trainLoss: 1.680, trainAcc: 0.863, validLoss: 1.653, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 61 --> trainLoss: 1.673, trainAcc: 0.865, validLoss: 1.658, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 62 --> trainLoss: 1.661, trainAcc: 0.870, validLoss: 1.619, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 63 --> trainLoss: 1.660, trainAcc: 0.871, validLoss: 1.666, validAcc: 0.852\n",
            "Model Saved!\n",
            "epoch 64 --> trainLoss: 1.656, trainAcc: 0.870, validLoss: 1.681, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 65 --> trainLoss: 1.656, trainAcc: 0.867, validLoss: 1.608, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 66 --> trainLoss: 1.657, trainAcc: 0.868, validLoss: 1.622, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 67 --> trainLoss: 1.655, trainAcc: 0.871, validLoss: 1.664, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 68 --> trainLoss: 1.649, trainAcc: 0.875, validLoss: 1.603, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 69 --> trainLoss: 1.647, trainAcc: 0.877, validLoss: 1.659, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 70 --> trainLoss: 1.648, trainAcc: 0.876, validLoss: 1.661, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 71 --> trainLoss: 1.649, trainAcc: 0.873, validLoss: 1.639, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 72 --> trainLoss: 1.649, trainAcc: 0.873, validLoss: 1.623, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 73 --> trainLoss: 1.645, trainAcc: 0.877, validLoss: 1.638, validAcc: 0.858\n",
            "Model Saved!\n",
            "epoch 74 --> trainLoss: 1.648, trainAcc: 0.875, validLoss: 1.640, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 75 --> trainLoss: 1.641, trainAcc: 0.877, validLoss: 1.648, validAcc: 0.853\n",
            "Model Saved!\n",
            "epoch 76 --> trainLoss: 1.640, trainAcc: 0.878, validLoss: 1.611, validAcc: 0.871\n",
            "Model Saved!\n",
            "epoch 77 --> trainLoss: 1.637, trainAcc: 0.879, validLoss: 1.639, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 78 --> trainLoss: 1.639, trainAcc: 0.879, validLoss: 1.639, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 79 --> trainLoss: 1.635, trainAcc: 0.881, validLoss: 1.619, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 80 --> trainLoss: 1.638, trainAcc: 0.876, validLoss: 1.606, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 81 --> trainLoss: 1.631, trainAcc: 0.881, validLoss: 1.640, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 82 --> trainLoss: 1.631, trainAcc: 0.880, validLoss: 1.629, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 83 --> trainLoss: 1.624, trainAcc: 0.885, validLoss: 1.626, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 84 --> trainLoss: 1.622, trainAcc: 0.885, validLoss: 1.637, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 85 --> trainLoss: 1.627, trainAcc: 0.883, validLoss: 1.626, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 86 --> trainLoss: 1.626, trainAcc: 0.884, validLoss: 1.631, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 87 --> trainLoss: 1.628, trainAcc: 0.883, validLoss: 1.603, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 88 --> trainLoss: 1.627, trainAcc: 0.883, validLoss: 1.616, validAcc: 0.865\n",
            "Model Saved!\n",
            "epoch 89 --> trainLoss: 1.626, trainAcc: 0.883, validLoss: 1.607, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 90 --> trainLoss: 1.621, trainAcc: 0.887, validLoss: 1.643, validAcc: 0.858\n",
            "Model Saved!\n",
            "epoch 91 --> trainLoss: 1.624, trainAcc: 0.886, validLoss: 1.678, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 92 --> trainLoss: 1.622, trainAcc: 0.883, validLoss: 1.635, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 93 --> trainLoss: 1.614, trainAcc: 0.890, validLoss: 1.590, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 94 --> trainLoss: 1.614, trainAcc: 0.889, validLoss: 1.584, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 95 --> trainLoss: 1.617, trainAcc: 0.888, validLoss: 1.603, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 96 --> trainLoss: 1.612, trainAcc: 0.890, validLoss: 1.602, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 97 --> trainLoss: 1.609, trainAcc: 0.891, validLoss: 1.642, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 98 --> trainLoss: 1.614, trainAcc: 0.889, validLoss: 1.584, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 99 --> trainLoss: 1.604, trainAcc: 0.892, validLoss: 1.614, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 100 --> trainLoss: 1.606, trainAcc: 0.891, validLoss: 1.584, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 101 --> trainLoss: 1.601, trainAcc: 0.893, validLoss: 1.626, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 102 --> trainLoss: 1.594, trainAcc: 0.895, validLoss: 1.629, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 103 --> trainLoss: 1.599, trainAcc: 0.893, validLoss: 1.598, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 104 --> trainLoss: 1.592, trainAcc: 0.899, validLoss: 1.578, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 105 --> trainLoss: 1.593, trainAcc: 0.897, validLoss: 1.609, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 106 --> trainLoss: 1.590, trainAcc: 0.897, validLoss: 1.617, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 107 --> trainLoss: 1.593, trainAcc: 0.895, validLoss: 1.597, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 108 --> trainLoss: 1.588, trainAcc: 0.898, validLoss: 1.591, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 109 --> trainLoss: 1.589, trainAcc: 0.896, validLoss: 1.621, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 110 --> trainLoss: 1.588, trainAcc: 0.899, validLoss: 1.593, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 111 --> trainLoss: 1.595, trainAcc: 0.897, validLoss: 1.604, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 112 --> trainLoss: 1.587, trainAcc: 0.900, validLoss: 1.613, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 113 --> trainLoss: 1.588, trainAcc: 0.899, validLoss: 1.558, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 114 --> trainLoss: 1.581, trainAcc: 0.902, validLoss: 1.592, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 115 --> trainLoss: 1.584, trainAcc: 0.901, validLoss: 1.570, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 116 --> trainLoss: 1.581, trainAcc: 0.904, validLoss: 1.569, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 117 --> trainLoss: 1.577, trainAcc: 0.903, validLoss: 1.597, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 118 --> trainLoss: 1.575, trainAcc: 0.903, validLoss: 1.573, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 119 --> trainLoss: 1.573, trainAcc: 0.906, validLoss: 1.596, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 120 --> trainLoss: 1.579, trainAcc: 0.899, validLoss: 1.578, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 121 --> trainLoss: 1.575, trainAcc: 0.903, validLoss: 1.559, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 122 --> trainLoss: 1.573, trainAcc: 0.905, validLoss: 1.596, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 123 --> trainLoss: 1.567, trainAcc: 0.909, validLoss: 1.572, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 124 --> trainLoss: 1.575, trainAcc: 0.904, validLoss: 1.565, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 125 --> trainLoss: 1.574, trainAcc: 0.901, validLoss: 1.568, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 126 --> trainLoss: 1.568, trainAcc: 0.908, validLoss: 1.586, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 127 --> trainLoss: 1.566, trainAcc: 0.907, validLoss: 1.570, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 128 --> trainLoss: 1.569, trainAcc: 0.906, validLoss: 1.564, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 129 --> trainLoss: 1.561, trainAcc: 0.909, validLoss: 1.593, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 130 --> trainLoss: 1.561, trainAcc: 0.909, validLoss: 1.573, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 131 --> trainLoss: 1.558, trainAcc: 0.910, validLoss: 1.565, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 132 --> trainLoss: 1.558, trainAcc: 0.911, validLoss: 1.555, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 133 --> trainLoss: 1.558, trainAcc: 0.913, validLoss: 1.573, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 134 --> trainLoss: 1.561, trainAcc: 0.908, validLoss: 1.576, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 135 --> trainLoss: 1.554, trainAcc: 0.912, validLoss: 1.551, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 136 --> trainLoss: 1.552, trainAcc: 0.913, validLoss: 1.549, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 137 --> trainLoss: 1.551, trainAcc: 0.914, validLoss: 1.575, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 138 --> trainLoss: 1.550, trainAcc: 0.915, validLoss: 1.549, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 139 --> trainLoss: 1.549, trainAcc: 0.916, validLoss: 1.557, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 140 --> trainLoss: 1.547, trainAcc: 0.916, validLoss: 1.577, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 141 --> trainLoss: 1.546, trainAcc: 0.916, validLoss: 1.563, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 142 --> trainLoss: 1.546, trainAcc: 0.914, validLoss: 1.546, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 143 --> trainLoss: 1.542, trainAcc: 0.917, validLoss: 1.548, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 144 --> trainLoss: 1.539, trainAcc: 0.918, validLoss: 1.531, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 145 --> trainLoss: 1.538, trainAcc: 0.919, validLoss: 1.537, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 146 --> trainLoss: 1.536, trainAcc: 0.921, validLoss: 1.537, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 147 --> trainLoss: 1.532, trainAcc: 0.921, validLoss: 1.555, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 148 --> trainLoss: 1.531, trainAcc: 0.921, validLoss: 1.552, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 149 --> trainLoss: 1.536, trainAcc: 0.920, validLoss: 1.543, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 150 --> trainLoss: 1.528, trainAcc: 0.922, validLoss: 1.519, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 151 --> trainLoss: 1.530, trainAcc: 0.922, validLoss: 1.549, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 152 --> trainLoss: 1.528, trainAcc: 0.925, validLoss: 1.556, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 153 --> trainLoss: 1.524, trainAcc: 0.924, validLoss: 1.531, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 154 --> trainLoss: 1.527, trainAcc: 0.923, validLoss: 1.557, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 155 --> trainLoss: 1.520, trainAcc: 0.926, validLoss: 1.547, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 156 --> trainLoss: 1.524, trainAcc: 0.923, validLoss: 1.527, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 157 --> trainLoss: 1.523, trainAcc: 0.924, validLoss: 1.541, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 158 --> trainLoss: 1.519, trainAcc: 0.927, validLoss: 1.531, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 159 --> trainLoss: 1.517, trainAcc: 0.928, validLoss: 1.531, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 160 --> trainLoss: 1.519, trainAcc: 0.926, validLoss: 1.525, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 161 --> trainLoss: 1.506, trainAcc: 0.932, validLoss: 1.529, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 162 --> trainLoss: 1.511, trainAcc: 0.929, validLoss: 1.521, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 163 --> trainLoss: 1.516, trainAcc: 0.928, validLoss: 1.523, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 164 --> trainLoss: 1.510, trainAcc: 0.931, validLoss: 1.530, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 165 --> trainLoss: 1.513, trainAcc: 0.928, validLoss: 1.514, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 166 --> trainLoss: 1.505, trainAcc: 0.934, validLoss: 1.537, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 167 --> trainLoss: 1.505, trainAcc: 0.930, validLoss: 1.521, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 168 --> trainLoss: 1.505, trainAcc: 0.932, validLoss: 1.512, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 169 --> trainLoss: 1.507, trainAcc: 0.932, validLoss: 1.539, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 170 --> trainLoss: 1.503, trainAcc: 0.933, validLoss: 1.524, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 171 --> trainLoss: 1.499, trainAcc: 0.934, validLoss: 1.528, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 172 --> trainLoss: 1.499, trainAcc: 0.934, validLoss: 1.527, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 173 --> trainLoss: 1.498, trainAcc: 0.934, validLoss: 1.508, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 174 --> trainLoss: 1.500, trainAcc: 0.931, validLoss: 1.516, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 175 --> trainLoss: 1.495, trainAcc: 0.934, validLoss: 1.510, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 176 --> trainLoss: 1.498, trainAcc: 0.933, validLoss: 1.511, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 177 --> trainLoss: 1.492, trainAcc: 0.937, validLoss: 1.519, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 178 --> trainLoss: 1.490, trainAcc: 0.938, validLoss: 1.514, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 179 --> trainLoss: 1.491, trainAcc: 0.938, validLoss: 1.508, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 180 --> trainLoss: 1.491, trainAcc: 0.937, validLoss: 1.509, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 181 --> trainLoss: 1.493, trainAcc: 0.936, validLoss: 1.508, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 182 --> trainLoss: 1.484, trainAcc: 0.939, validLoss: 1.502, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 183 --> trainLoss: 1.488, trainAcc: 0.939, validLoss: 1.506, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 184 --> trainLoss: 1.482, trainAcc: 0.941, validLoss: 1.510, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 185 --> trainLoss: 1.481, trainAcc: 0.941, validLoss: 1.503, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 186 --> trainLoss: 1.480, trainAcc: 0.940, validLoss: 1.515, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 187 --> trainLoss: 1.480, trainAcc: 0.940, validLoss: 1.499, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 188 --> trainLoss: 1.482, trainAcc: 0.941, validLoss: 1.510, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 189 --> trainLoss: 1.476, trainAcc: 0.941, validLoss: 1.494, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 190 --> trainLoss: 1.477, trainAcc: 0.942, validLoss: 1.510, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 191 --> trainLoss: 1.473, trainAcc: 0.946, validLoss: 1.495, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 192 --> trainLoss: 1.473, trainAcc: 0.944, validLoss: 1.501, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 193 --> trainLoss: 1.472, trainAcc: 0.945, validLoss: 1.493, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 194 --> trainLoss: 1.473, trainAcc: 0.943, validLoss: 1.501, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 195 --> trainLoss: 1.473, trainAcc: 0.943, validLoss: 1.498, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 196 --> trainLoss: 1.469, trainAcc: 0.947, validLoss: 1.495, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 197 --> trainLoss: 1.468, trainAcc: 0.948, validLoss: 1.485, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 198 --> trainLoss: 1.469, trainAcc: 0.947, validLoss: 1.493, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 199 --> trainLoss: 1.466, trainAcc: 0.945, validLoss: 1.487, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 200 --> trainLoss: 1.466, trainAcc: 0.948, validLoss: 1.486, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 201 --> trainLoss: 1.467, trainAcc: 0.946, validLoss: 1.487, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 202 --> trainLoss: 1.464, trainAcc: 0.947, validLoss: 1.489, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 203 --> trainLoss: 1.462, trainAcc: 0.946, validLoss: 1.490, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 204 --> trainLoss: 1.462, trainAcc: 0.948, validLoss: 1.486, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 205 --> trainLoss: 1.460, trainAcc: 0.950, validLoss: 1.481, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 206 --> trainLoss: 1.457, trainAcc: 0.949, validLoss: 1.489, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 207 --> trainLoss: 1.453, trainAcc: 0.949, validLoss: 1.484, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 208 --> trainLoss: 1.458, trainAcc: 0.949, validLoss: 1.487, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 209 --> trainLoss: 1.455, trainAcc: 0.952, validLoss: 1.480, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 210 --> trainLoss: 1.454, trainAcc: 0.951, validLoss: 1.484, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 211 --> trainLoss: 1.453, trainAcc: 0.951, validLoss: 1.486, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 212 --> trainLoss: 1.457, trainAcc: 0.947, validLoss: 1.480, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 213 --> trainLoss: 1.452, trainAcc: 0.950, validLoss: 1.479, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 214 --> trainLoss: 1.450, trainAcc: 0.952, validLoss: 1.476, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 215 --> trainLoss: 1.452, trainAcc: 0.952, validLoss: 1.483, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 216 --> trainLoss: 1.448, trainAcc: 0.953, validLoss: 1.476, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 217 --> trainLoss: 1.451, trainAcc: 0.951, validLoss: 1.474, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 218 --> trainLoss: 1.447, trainAcc: 0.953, validLoss: 1.477, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 219 --> trainLoss: 1.451, trainAcc: 0.952, validLoss: 1.479, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 220 --> trainLoss: 1.451, trainAcc: 0.952, validLoss: 1.478, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 221 --> trainLoss: 1.449, trainAcc: 0.953, validLoss: 1.477, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 222 --> trainLoss: 1.446, trainAcc: 0.952, validLoss: 1.473, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 223 --> trainLoss: 1.445, trainAcc: 0.952, validLoss: 1.474, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 224 --> trainLoss: 1.444, trainAcc: 0.953, validLoss: 1.474, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 225 --> trainLoss: 1.450, trainAcc: 0.955, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 226 --> trainLoss: 1.446, trainAcc: 0.952, validLoss: 1.481, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 227 --> trainLoss: 1.445, trainAcc: 0.956, validLoss: 1.477, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 228 --> trainLoss: 1.443, trainAcc: 0.956, validLoss: 1.472, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 229 --> trainLoss: 1.440, trainAcc: 0.954, validLoss: 1.476, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 230 --> trainLoss: 1.441, trainAcc: 0.956, validLoss: 1.473, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 231 --> trainLoss: 1.444, trainAcc: 0.954, validLoss: 1.472, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 232 --> trainLoss: 1.444, trainAcc: 0.954, validLoss: 1.477, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 233 --> trainLoss: 1.441, trainAcc: 0.956, validLoss: 1.472, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 234 --> trainLoss: 1.440, trainAcc: 0.956, validLoss: 1.472, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 235 --> trainLoss: 1.443, trainAcc: 0.955, validLoss: 1.470, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 236 --> trainLoss: 1.438, trainAcc: 0.956, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 237 --> trainLoss: 1.441, trainAcc: 0.956, validLoss: 1.476, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 238 --> trainLoss: 1.440, trainAcc: 0.957, validLoss: 1.469, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 239 --> trainLoss: 1.440, trainAcc: 0.955, validLoss: 1.473, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 240 --> trainLoss: 1.440, trainAcc: 0.957, validLoss: 1.476, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 241 --> trainLoss: 1.439, trainAcc: 0.956, validLoss: 1.483, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 242 --> trainLoss: 1.438, trainAcc: 0.956, validLoss: 1.473, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 243 --> trainLoss: 1.440, trainAcc: 0.955, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 244 --> trainLoss: 1.437, trainAcc: 0.957, validLoss: 1.471, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 245 --> trainLoss: 1.441, trainAcc: 0.956, validLoss: 1.477, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 246 --> trainLoss: 1.440, trainAcc: 0.955, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 247 --> trainLoss: 1.438, trainAcc: 0.957, validLoss: 1.471, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 248 --> trainLoss: 1.438, trainAcc: 0.955, validLoss: 1.470, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 249 --> trainLoss: 1.438, trainAcc: 0.956, validLoss: 1.475, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 250 --> trainLoss: 1.441, trainAcc: 0.956, validLoss: 1.464, validAcc: 0.918\n",
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "model, history = train(args, io)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l2rDIN0H0j4W"
      },
      "outputs": [],
      "source": [
        "def infer(sLoader, threshold=0.05, verbose=False):\n",
        "    \"\"\"\n",
        "    @Inference: we compare the output confidence (entropy) at a branch with a certain threshold\n",
        "\n",
        "    Parameters:\n",
        "    sLoader (DataLoader): Iterable over the dataset, provides batches of (inputs, groundTruth).\n",
        "    threshold (float): Entropy threshold used to decide the stopping point for shortBranch.\n",
        "    verbose (bool): If True, prints entropy values when they are below the threshold.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the recording dictionary of accuracies, list of predicted labels, and overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Softmax layer initialization for converting outputs to probability distributions\n",
        "    softmaxLayer = nn.Softmax(dim=1)\n",
        "\n",
        "    # Initialize accuracy and list to hold predictions\n",
        "    acc = 0\n",
        "    predicted = []\n",
        "\n",
        "    # Dictionary to keep track of accuracy per branch (shortBranch: 0, longBranch: 1)\n",
        "    recorder = {x: [] for x in range(2)}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disables gradient calculations for inference, saving memory and computations\n",
        "    with torch.no_grad():\n",
        "        for inputs, gTruth in sLoader:\n",
        "            # Move input and ground truth data to GPU\n",
        "            inputs, gTruth = inputs.to('cuda'), gTruth.to('cuda')\n",
        "            batch_size = inputs.size()[0] # Retrieve your batch size\n",
        "            # Permute dimensions of inputs to fit model's expected input shape\n",
        "            inputs = inputs.permute(0, 2, 1)\n",
        "            # Process inputs through the base part of the model\n",
        "            x_baseModelconv1 = model.baseModelconv1(get_graph_feature(inputs, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv2 = model.baseModelconv2(get_graph_feature(x_baseModelconv1, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x = torch.cat((x_baseModelconv1, x_baseModelconv2), dim=1)\n",
        "            # Iterate through each sample in the batch\n",
        "            for iSample in range(x.shape[0]):\n",
        "                # Process inputs through the short branch of the model\n",
        "                out1 = model.get_short_branch_output(x[iSample:iSample+1], 1)\n",
        "                # Apply softmax to get probabilities\n",
        "                y = softmaxLayer(out1)\n",
        "                # Calculate the entropy of the output probabilities\n",
        "                e = entropy(y.detach().cpu().numpy().squeeze(), base=10)\n",
        "                # Check if entropy is below the threshold\n",
        "                if e <= threshold:\n",
        "                    if verbose:\n",
        "                        print(e)  # Optionally print the entropy\n",
        "                    _, label = torch.max(out1, 1)\n",
        "                    predicted.append(label)\n",
        "                    if label == gTruth[iSample].item():\n",
        "                        recorder[0].append(1)\n",
        "                        acc += 1\n",
        "                    else:\n",
        "                        recorder[0].append(0)\n",
        "                    continue\n",
        "\n",
        "                out2 = model.get_long_branch_output(x_baseModelconv1[iSample:iSample+1], x_baseModelconv2[iSample:iSample+1], 1)\n",
        "                _, label = torch.max(out2, 1)\n",
        "                predicted.append(label)\n",
        "                if label == gTruth[iSample].item():\n",
        "                    acc += 1\n",
        "                    recorder[1].append(1)\n",
        "                else:\n",
        "                    recorder[1].append(0)\n",
        "\n",
        "        # Calculate the total accuracy by summing correct predictions divided by total predictions\n",
        "        acc = acc / sum([len(recorder[x]) for x in range(2)])\n",
        "\n",
        "    return recorder, predicted, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xV7xiet2PEdd"
      },
      "outputs": [],
      "source": [
        "def testingSummary(recorder, nBranches=2, overall=True):\n",
        "    \"\"\"\n",
        "    Prints a summary of testing accuracy for each branch and overall if specified.\n",
        "\n",
        "    Parameters:\n",
        "    recorder (dict): Dictionary containing lists of 0s and 1s where 1 represents a correct prediction, indexed by branch number.\n",
        "    nBranches (int): Number of branches in the model.\n",
        "    overall (bool): If True, prints the overall weighted accuracy across all branches.\n",
        "\n",
        "    Outputs:\n",
        "    Prints the accuracy of each branch and optionally the overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Header for the summary output\n",
        "    print('Summary')\n",
        "    print(\"======================\")\n",
        "\n",
        "    # Initialize accumulators for overall accuracy calculation\n",
        "    overallAcc, acc = 0, 0\n",
        "\n",
        "    # Calculate the total number of samples across all branches\n",
        "    overallCount = sum([len(recorder[x]) for x in range(nBranches)])\n",
        "\n",
        "    # Iterate through each branch to calculate and display individual accuracies\n",
        "    for i in range(nBranches):\n",
        "        # Number of samples in the current branch\n",
        "        countSamples = len(recorder[i])\n",
        "\n",
        "        # Check if there are samples in the current branch\n",
        "        if countSamples != 0:\n",
        "            # Calculate the accuracy for this branch\n",
        "            acc = recorder[i].count(1) / len(recorder[i])\n",
        "            # Print the accuracy and the percentage of total samples this branch represents\n",
        "            print(\"Branch {}: Accuracy {:.2f}% with {:.2f}% of the samples\".format(i+1, acc*100, countSamples/overallCount*100))\n",
        "        else:\n",
        "            # Handle the case where a branch has no samples\n",
        "            print(\"Branch {}: Got 0% of the samples\".format(i+1))\n",
        "\n",
        "        # Accumulate weighted accuracy for overall calculation\n",
        "        overallAcc += acc * countSamples\n",
        "\n",
        "    # If overall accuracy is to be calculated, display it\n",
        "    if overall:\n",
        "        print(\"Overall Weighted Accuracy: {:.2f}%\".format(overallAcc/overallCount*100))\n",
        "    return(overallAcc/overallCount*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9eylNEIahG",
        "outputId": "8724e523-889a-4930-8ff5-38e5c09a5812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->ptflops)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->ptflops)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->ptflops)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->ptflops)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->ptflops)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->ptflops)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->ptflops)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->ptflops)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ptflops-0.7.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P_FNtX2gIUZK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from ptflops import get_model_complexity_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Calculate FLOPs of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yXon4ULIYBT",
        "outputId": "590e3518-8a16-4693-9cef-baf123bb21fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  512, 100.000% Params, 5.9 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(384, 75.000% Params, 3.93 MMac, 66.667% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 25.000% Params, 1.31 MMac, 22.222% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 11.111% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  8.32 k, 100.000% Params, 85.85 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(8.19 k, 98.462% Params, 83.89 MMac, 97.710% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 1.538% Params, 1.31 MMac, 1.527% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.763% MACs, negative_slope=0.2)\n",
            ")\n",
            "FLOPs: 91.750000 MMac\n"
          ]
        }
      ],
      "source": [
        "flopsconv1, paramsconv1 = get_model_complexity_info(model.baseModelconv1, (6, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv2, paramsconv2 = get_model_complexity_info(model.baseModelconv2, (128, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs: {:2f} MMac'.format(5.9+85.85))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32I1XlZlJiD3",
        "outputId": "cbceb548-e2b3-4091-cbc5-6689cedc1597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  274.22 k, 100.000% Params, 274.98 KMac, 100.000% MACs, \n",
            "  (0): Linear(131.07 k, 47.799% Params, 131.07 KMac, 47.665% MACs, in_features=256, out_features=512, bias=False)\n",
            "  (1): BatchNorm1d(1.02 k, 0.373% Params, 1.02 KMac, 0.372% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.186% MACs, negative_slope=0.2)\n",
            "  (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (4): Linear(131.33 k, 47.892% Params, 131.33 KMac, 47.758% MACs, in_features=512, out_features=256, bias=True)\n",
            "  (5): BatchNorm1d(512, 0.187% Params, 512.0 Mac, 0.186% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.093% MACs, negative_slope=0.2)\n",
            "  (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (8): Linear(10.28 k, 3.749% Params, 10.28 KMac, 3.738% MACs, in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "FLOPs: 274.98 KMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model.shortBranch, (256, ), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRModsL7LwxM",
        "outputId": "c7dbdfda-6401-4651-84e4-2fa7a0599ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short path FLOPs: 92.024980 MMac\n",
            "Short path Parameters: 283.052000 k\n"
          ]
        }
      ],
      "source": [
        "print('Short path FLOPs: {:2f} MMac'.format(91.75+0.27498))\n",
        "print('Short path Parameters: {:2f} k'.format(8.832+274.22))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyGwqyz0JYiR",
        "outputId": "0ba9c264-0eb2-4eec-ff8f-68b6e8258165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm1d ptflops can affect your code!\n",
            "Warning: parameters of some of the modules were counted twice because of multiple links to the same modules. Extended per layer parameters num statistic could be unreliable.\n",
            "eeModel_E1(\n",
            "  2.09 M, 100.147% Params, 1.5 GMac, 84.527% MACs, \n",
            "  (bn1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(256, 0.012% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(512, 0.025% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn5): BatchNorm1d(2.05 k, 0.098% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (baseModelconv1): Sequential(\n",
            "    512, 0.025% Params, 5.9 MMac, 0.333% MACs, \n",
            "    (0): Conv2d(384, 0.018% Params, 3.93 MMac, 0.222% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv2): Sequential(\n",
            "    8.32 k, 0.399% Params, 85.85 MMac, 4.849% MACs, \n",
            "    (0): Conv2d(8.19 k, 0.393% Params, 83.89 MMac, 4.738% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (shortBranch): Sequential(\n",
            "    274.22 k, 13.159% Params, 274.98 KMac, 0.016% MACs, \n",
            "    (0): Linear(131.07 k, 6.290% Params, 131.07 KMac, 0.007% MACs, in_features=256, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.049% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 6.302% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.025% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.493% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    16.64 k, 0.799% Params, 171.7 MMac, 9.699% MACs, \n",
            "    (0): Conv2d(16.38 k, 0.786% Params, 167.77 MMac, 9.476% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, 0.012% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.074% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    66.05 k, 3.170% Params, 678.95 MMac, 38.350% MACs, \n",
            "    (0): Conv2d(65.54 k, 3.145% Params, 671.09 MMac, 37.906% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, 0.025% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 2.62 MMac, 0.148% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    526.34 k, 25.259% Params, 540.02 MMac, 30.502% MACs, \n",
            "    (0): Conv1d(524.29 k, 25.160% Params, 536.87 MMac, 30.325% MACs, 512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(2.05 k, 0.098% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.059% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (longBranch_fc): Sequential(\n",
            "    1.19 M, 57.190% Params, 1.19 MMac, 0.067% MACs, \n",
            "    (0): Linear(1.05 M, 50.321% Params, 1.05 MMac, 0.059% MACs, in_features=2048, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.049% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 6.302% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.025% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.493% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            ")\n",
            "FLOPs: 1.77 GMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model, (3, 1024), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Calculate number of parameters of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_kBvvytzVe",
        "outputId": "5804dc0d-3383-4c98-9b92-9a1fc10d9b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters in Short Path: 283048\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate the total number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Parameters in the base model\n",
        "baseModelconv1_params = count_parameters(model.baseModelconv1)\n",
        "baseModelconv2_params = count_parameters(model.baseModelconv2)\n",
        "# Parameters in the short branch\n",
        "short_path_params = count_parameters(model.shortBranch)\n",
        "\n",
        "print(\"Parameters in Short Path:\", short_path_params+baseModelconv1_params+baseModelconv2_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kCXX2hrwNN7",
        "outputId": "7def4761-9ca8-4889-ed07-203865f99d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Linear: 1-1                            131,072\n",
            "├─BatchNorm1d: 1-2                       1,024\n",
            "├─LeakyReLU: 1-3                         --\n",
            "├─Dropout: 1-4                           --\n",
            "├─Linear: 1-5                            131,328\n",
            "├─BatchNorm1d: 1-6                       512\n",
            "├─LeakyReLU: 1-7                         --\n",
            "├─Dropout: 1-8                           --\n",
            "├─Linear: 1-9                            10,280\n",
            "=================================================================\n",
            "Total params: 274,216\n",
            "Trainable params: 274,216\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            384\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 512\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            8,192\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 8,320\n",
            "Trainable params: 8,320\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model.shortBranch))\n",
        "print(summary(model.baseModelconv1))\n",
        "print(summary(model.baseModelconv2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Measure inference time and overall weighted accuracy with varying entropy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x0ln00bI0qZq"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False) # Loading test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z6-w1P3aMzNT"
      },
      "outputs": [],
      "source": [
        "inference_times = []\n",
        "accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxISoQfSjQbG",
        "outputId": "5db0de1b-c966-4cd9-89e4-bbde0c48ffcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 8.284887 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Got 0% of the samples\n",
            "Branch 2: Accuracy 92.50% with 100.00% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhtT-ZIdk70V",
        "outputId": "bb99f02e-6178-4115-ebcd-5ccaf783a4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 7.825197 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 0.08% of the samples\n",
            "Branch 2: Accuracy 92.50% with 99.92% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQE-rELqk-PF",
        "outputId": "aaa6dcac-4c83-4239-c97b-f120afab9aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 7.732193 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 1.70% of the samples\n",
            "Branch 2: Accuracy 92.37% with 98.30% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0PwWILTk__D",
        "outputId": "3b1aae1e-4948-4bb6-b907-5e31df597b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 7.324323 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 9.20% of the samples\n",
            "Branch 2: Accuracy 91.74% with 90.80% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUYayMiwlBpN",
        "outputId": "33f4a983-2e69-4d41-d141-8c6369c6a740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.760874 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.81% with 21.68% of the samples\n",
            "Branch 2: Accuracy 90.48% with 78.32% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_9l0jzxlEND",
        "outputId": "ccff4e20-6f0d-4c55-b9e8-e2a9942470f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.794408 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.29% with 39.71% of the samples\n",
            "Branch 2: Accuracy 88.10% with 60.29% of the samples\n",
            "Overall Weighted Accuracy: 92.54%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TduJVQ9YlF6T",
        "outputId": "ca8826a5-c4a7-485d-dc09-8583d5165eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.800537 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.56% with 58.95% of the samples\n",
            "Branch 2: Accuracy 83.71% with 41.05% of the samples\n",
            "Overall Weighted Accuracy: 92.46%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd_1UvQOlHhc",
        "outputId": "d465d313-63d4-4123-a9f3-e8c73479e09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.307389 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 97.66% with 70.91% of the samples\n",
            "Branch 2: Accuracy 79.67% with 29.09% of the samples\n",
            "Overall Weighted Accuracy: 92.42%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdMnwqQOlJMD",
        "outputId": "d6db47e8-58ab-46ae-cd24-72a0e98d27f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.834833 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 96.56% with 78.89% of the samples\n",
            "Branch 2: Accuracy 76.20% with 21.11% of the samples\n",
            "Overall Weighted Accuracy: 92.26%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewn8ofWPlKq6",
        "outputId": "51d7cbbe-77a7-4ce0-fc7b-e8bfccac0625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.498860 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 95.22% with 84.85% of the samples\n",
            "Branch 2: Accuracy 73.53% with 15.15% of the samples\n",
            "Overall Weighted Accuracy: 91.94%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLXHLaVC7e7",
        "outputId": "2b9376da-3166-4cc0-fe36-c282304b6beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.306288 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 94.42% with 89.26% of the samples\n",
            "Branch 2: Accuracy 70.94% with 10.74% of the samples\n",
            "Overall Weighted Accuracy: 91.90%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHDKqmxZlMGj",
        "outputId": "55ea8bc9-025b-4a28-aa54-f5ec275bf5d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.163348 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 93.42% with 92.99% of the samples\n",
            "Branch 2: Accuracy 69.36% with 7.01% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM2caHq_lNoY",
        "outputId": "0adc9a09-f4ee-45a5-bb6b-52c2ec4a45a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.952765 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 92.44% with 95.91% of the samples\n",
            "Branch 2: Accuracy 61.39% with 4.09% of the samples\n",
            "Overall Weighted Accuracy: 91.17%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S--mC_5slPqo",
        "outputId": "1c389dbb-3869-47bb-8121-78191b12a42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.847859 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.28% with 98.50% of the samples\n",
            "Branch 2: Accuracy 56.76% with 1.50% of the samples\n",
            "Overall Weighted Accuracy: 90.76%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqQAsnGtlR3n",
        "outputId": "6b083f0f-3814-4f2e-c1f6-280d2d054475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.789410 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.42% with 99.84% of the samples\n",
            "Branch 2: Accuracy 50.00% with 0.16% of the samples\n",
            "Overall Weighted Accuracy: 90.36%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9UKRbLLlUuV",
        "outputId": "853cb176-98c1-4ef9-ce01-7011f0f902d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.784696 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xawSuhXHM1rA",
        "outputId": "b484e1f2-b952-40cc-8a1e-c28bc6b2cb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.042324 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g0IZt8GM7Qc",
        "outputId": "6c5f17e5-fef1-47f2-de81-f4cc7416a1c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.819669 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fur5evB3M-ln",
        "outputId": "2cefeff3-ee48-4eda-bf1c-1a87f3dbb123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.869324 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ6AJscNBEb",
        "outputId": "141b5f00-5262-4832-aef1-4eb75121e402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.778639 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7S0a1mgNDCh",
        "outputId": "3defe918-cf2f-48c1-a711-8a1cfd207c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.807892 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.28% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 90.28%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEFfCQeaZayA",
        "outputId": "827f7376-5561-4aa5-d3f4-509d8417c284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[92.50405186385737, 92.50405186385737, 92.50405186385737, 92.50405186385737, 92.50405186385737, 92.54457050243113, 92.46353322528364, 92.42301458670988, 92.26094003241491, 91.93679092382496, 91.89627228525121, 91.73419773095624, 91.16693679092383, 90.76175040518638, 90.35656401944895, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147]\n"
          ]
        }
      ],
      "source": [
        "print(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5WzXGEzbu4o",
        "outputId": "a4a7994a-f840-4cfb-ba89-f61acff318b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "NLwWfowBNJBR",
        "outputId": "917634ee-59f5-45be-e16b-2e8749b97a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 5e+06x5e+06 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from adjustText import adjust_text\n",
        "entropies = [x/10 for x in range(0, 21)]\n",
        "# Creating the scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(inference_times, accuracies, c='blue')\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(entropies):\n",
        "    text = ax.annotate(str(txt), (inference_times[i], accuracies[i]))\n",
        "    texts.append(text)\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='black'))\n",
        "plt.figure(figsize=(50000, 50000))\n",
        "ax.set_xlabel('Inference Times')\n",
        "ax.set_ylabel('Accuracies')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qst7s0VP63vS",
        "outputId": "dc89e051-1c58-4995-c8d9-eeb47dd800ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8.284886837005615, 7.825196981430054, 7.7321929931640625, 7.324322700500488, 6.760873556137085, 5.794408082962036, 4.800537347793579, 4.307389259338379, 3.8348333835601807, 3.4988598823547363, 3.306288480758667, 3.1633477210998535, 2.952765464782715, 2.8478591442108154, 2.789409637451172, 2.784695625305176, 3.0423243045806885, 2.819668769836426, 2.869323968887329, 2.7786386013031006, 2.807891607284546]\n",
            "[92.50405186385737, 92.50405186385737, 92.50405186385737, 92.50405186385737, 92.50405186385737, 92.54457050243113, 92.46353322528364, 92.42301458670988, 92.26094003241491, 91.93679092382496, 91.89627228525121, 91.73419773095624, 91.16693679092383, 90.76175040518638, 90.35656401944895, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147, 90.27552674230147]\n"
          ]
        }
      ],
      "source": [
        "print(inference_times)\n",
        "print(accuracies)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
