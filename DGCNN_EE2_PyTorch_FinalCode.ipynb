{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XS_6buTBwPl"
      },
      "source": [
        "### **Import and Install Libraries. Download Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2WB_AlhDx9_",
        "outputId": "25cfadce-c121-4f19-dd1b-d6cd713827ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rZLVYrPJeOk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "from scipy.stats import entropy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "import sklearn.metrics as metrics\n",
        "import copy\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UH_X_YHfYkK",
        "outputId": "edac8e24-1a5a-4529-8e5e-c05fb11c2112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-26 05:45:21--  https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435212151 (415M) [application/zip]\n",
            "Saving to: ‘modelnet40_ply_hdf5_2048.zip’\n",
            "\n",
            "modelnet40_ply_hdf5 100%[===================>] 415.05M  3.94MB/s    in 85s     \n",
            "\n",
            "2024-04-26 05:46:46 (4.91 MB/s) - ‘modelnet40_ply_hdf5_2048.zip’ saved [435212151/435212151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
        "!unzip -q modelnet40_ply_hdf5_2048.zip;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore specific warnings related to multiprocessing and os.fork\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\".*os.fork.*\")"
      ],
      "metadata": {
        "id": "ekUukrU6v2Kz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fTRjk6Lp_cJW"
      },
      "outputs": [],
      "source": [
        "#Class for your arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.exp_name = 'exp'\n",
        "        self.model = 'dgcnn'\n",
        "        self.dataset = 'modelnet40'\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 16\n",
        "        self.epochs = 250\n",
        "        self.use_sgd = True\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.9\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.eval = False\n",
        "        self.num_points = 1024\n",
        "        self.dropout = 0.5\n",
        "        self.emb_dims = 1024\n",
        "        self.k = 10\n",
        "        self.model_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERQ6I6HnfprZ"
      },
      "outputs": [],
      "source": [
        "#Method to retrieve your training and testing files\n",
        "def getDataFiles(list_filename):\n",
        "    print(list_filename)\n",
        "    return [line.rstrip() for line in open(list_filename)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8yn70xofrpU",
        "outputId": "cea1b48d-dbd6-4e44-cebe-1bcf045b324f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/modelnet40_ply_hdf5_2048/train_files.txt\n",
            "data/modelnet40_ply_hdf5_2048/test_files.txt\n"
          ]
        }
      ],
      "source": [
        "#Store your dataset in the folder 'data'\n",
        "import shutil\n",
        "os.mkdir('data')\n",
        "shutil.move('modelnet40_ply_hdf5_2048', 'data')\n",
        "TRAIN_FILES = getDataFiles( \\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/train_files.txt'))\n",
        "TEST_FILES = getDataFiles(\\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/test_files.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3sIrLnpFg5Gk"
      },
      "outputs": [],
      "source": [
        "def cal_loss(pred, gold, smoothing=True):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.2\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "    else:\n",
        "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7Te875Og7xc"
      },
      "outputs": [],
      "source": [
        "class IOStream():\n",
        "    \"\"\"\n",
        "    A utility class for outputting text to both console and a file. This class provides a method to concurrently print\n",
        "    information to the console and append it to a file. This can be particularly useful for logging purposes in\n",
        "    applications like long-running processes where monitoring and retaining output history is necessary.\n",
        "\n",
        "    Attributes:\n",
        "    f (file object): File object used to append text to the specified file.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initialize the IOStream by opening or creating a file for appending text.\n",
        "\n",
        "        Parameters:\n",
        "        path (str): The file path where text will be appended. If the file does not exist, it will be created.\n",
        "        \"\"\"\n",
        "        self.f = open(path, 'a')  # Open the file in append mode.\n",
        "\n",
        "    def cprint(self, text):\n",
        "        \"\"\"\n",
        "        Prints text to the console and appends it to the file initialized in this class instance.\n",
        "\n",
        "        Parameters:\n",
        "        text (str): The text to be printed and logged.\n",
        "        \"\"\"\n",
        "        print(text)  # Print text to console.\n",
        "        self.f.write(text + '\\n')  # Append text to file and add a newline.\n",
        "        self.f.flush()  # Flush the internal buffer, ensuring all file operations are completed immediately.\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Closes the file associated with this instance. It is important to call this method to free up system resources.\n",
        "        \"\"\"\n",
        "        self.f.close()  # Close the file to release resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH-3GRMgB4eu"
      },
      "source": [
        "### **Calculate 10 k-nearest neighbors based on the Euclidean distance $(x_1-x_2)^2$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jJz0UTK3h2pV"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    # print(idx[1,:,1].size, 'idx of knn')\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbIW2MZCCEwy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "soeA9B4Nh3cr"
      },
      "outputs": [],
      "source": [
        "def get_graph_feature(x, k=10, idx=None):\n",
        "    # print(x.shape, 'Input x to get_graph_feature')\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "    # print(idx)\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "    # print(idx[1,1,:], 'idx of get_graph_feature')\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36SyVuaCKTb"
      },
      "source": [
        "### **DGCNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JU0hruirh9Xt"
      },
      "outputs": [],
      "source": [
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=args.dropout)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=args.dropout)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DGCNN EE1**"
      ],
      "metadata": {
        "id": "j48wtIIvVID2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class eeModel_E1(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(eeModel_E1, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        ################################Base Model###################################\n",
        "        self.baseModelconv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                       self.bn1,\n",
        "                                       nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        #############################################################################\n",
        "\n",
        "        #############################Short Branch####################################\n",
        "        self.shortBranch = nn.Sequential(nn.Linear(256*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ################################################################################\n",
        "\n",
        "        ####################################Long Branch#################################\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.longBranch_fc = nn.Sequential(nn.Linear(args.emb_dims*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ####################################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x_baseModelconv1 = self.baseModelconv1(get_graph_feature(x, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv2 = self.baseModelconv2(get_graph_feature(x_baseModelconv1, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv3 = self.baseModelconv3(get_graph_feature(x_baseModelconv2, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModel = torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3), dim=1)\n",
        "        x_shortBranch, x_longBranch = self.get_short_branch_output(x_baseModel, batch_size), self.get_long_branch_output(x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, batch_size)\n",
        "        return x_shortBranch, x_longBranch\n",
        "\n",
        "    def get_short_branch_output(self, x_baseModel, batch_size):\n",
        "        x_shortBranch = self.shortBranch(torch.cat((F.adaptive_max_pool1d(x_baseModel, 1).view(batch_size, -1),\n",
        "                                                    F.adaptive_avg_pool1d(x_baseModel, 1).view(batch_size, -1)), 1))\n",
        "        return x_shortBranch\n",
        "\n",
        "    def get_long_branch_output(self, x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, batch_size):\n",
        "        x4_longBranch = self.conv4(get_graph_feature(x_baseModelconv3, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_longBranch = self.conv5(torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x4_longBranch), dim=1))\n",
        "        x_longBranch = torch.cat((F.adaptive_max_pool1d(x_longBranch, 1).view(batch_size, -1),\n",
        "                                  F.adaptive_avg_pool1d(x_longBranch, 1).view(batch_size, -1)), 1)\n",
        "        x_longBranch = self.longBranch_fc(x_longBranch)\n",
        "        return x_longBranch"
      ],
      "metadata": {
        "id": "ZhsO2Y5HjpKN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4AgLkE_7e1NL"
      },
      "outputs": [],
      "source": [
        "def load_data(partition):\n",
        "    \"\"\"\n",
        "    Load pointcloud data and labels from HDF5 files based on the specified partition (train or test).\n",
        "    This function is designed to work within a filesystem structure expected for ModelNet40 dataset files,\n",
        "    aggregating data from multiple files into a single array for both data points and labels.\n",
        "\n",
        "    Parameters:\n",
        "    partition (str): Specifies which dataset partition to load. Expected values are 'train' or 'test'.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy arrays: one for the data (pointclouds) and one for the labels.\n",
        "    \"\"\"\n",
        "    # Define base directory relative to this script's location.\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(r'\\data\\modelnet40_ply_hdf5_2048'))\n",
        "    # Define data directory path combining base directory with the data subdirectory.\n",
        "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "\n",
        "    # Initialize lists to hold data and labels from all files.\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "\n",
        "    # Loop over each file matching the pattern for the specified partition.\n",
        "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', f'ply_data_{partition}*.h5')):\n",
        "        # Open the HDF5 file for reading.\n",
        "        f = h5py.File(h5_name)\n",
        "        # Load all data points as float32 and labels as int64 from the file.\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        # Ensure the file is closed after its contents are loaded.\n",
        "        f.close()\n",
        "\n",
        "        # Append the data and labels to their respective lists.\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "\n",
        "    # Concatenate all data and labels from the list into single numpy arrays.\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "\n",
        "    # Return the aggregated data and labels.\n",
        "    return all_data, all_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b4AH8w7Ke6Nt"
      },
      "outputs": [],
      "source": [
        "def translate_pointcloud(pointcloud):\n",
        "    \"\"\"\n",
        "    Apply a random translation to a pointcloud. This is done by first scaling the pointcloud with a random factor\n",
        "    and then adding a small random shift. This can be used as a data augmentation technique to make models robust\n",
        "    to variations in object position and scale.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, 3) where N is the number of points.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The translated pointcloud as a new numpy array of type 'float32'.\n",
        "    \"\"\"\n",
        "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])  # Random scaling factors.\n",
        "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])    # Random translation offsets.\n",
        "\n",
        "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')  # Apply scaling and translation\n",
        "    return translated_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nB31Q97vf4bN"
      },
      "outputs": [],
      "source": [
        "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):\n",
        "    \"\"\"\n",
        "    Apply Gaussian noise to a pointcloud. Each point's position is altered by adding a noise vector drawn from a\n",
        "    Gaussian distribution, clipped to a maximum magnitude to prevent excessive perturbation. This augmentation\n",
        "    promotes robustness to small variations or noise.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, C) where N is the number of points and C is the number of coordinates.\n",
        "    sigma (float): Standard deviation of the Gaussian noise.\n",
        "    clip (float): Maximum allowed value for noise applied to the point coordinates.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The jittered pointcloud.\n",
        "    \"\"\"\n",
        "    N, C = pointcloud.shape  # Number of points N and dimensions C in the pointcloud.\n",
        "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)  # Add clipped Gaussian noise.\n",
        "    return pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rGxrJjODf7iU"
      },
      "outputs": [],
      "source": [
        "class ModelNet40(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for ModelNet40, which includes methods for loading and preprocessing pointcloud data for training or testing.\n",
        "    Data augmentation (translation and shuffling) is applied to training data to improve model generalization.\n",
        "\n",
        "    Attributes:\n",
        "    num_points (int): Number of points per pointcloud to use.\n",
        "    partition (str): Dataset partition to use, either 'train' or 'test'.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points, partition='train'):\n",
        "        \"\"\"\n",
        "        Initialize the dataset object, loading data and labels according to the specified partition.\n",
        "\n",
        "        Parameters:\n",
        "        num_points (int): Number of points to sample from each pointcloud.\n",
        "        partition (str): Which dataset partition to use, 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        self.data, self.label = load_data(partition)  # Load dataset.\n",
        "        self.num_points = num_points  # Points per pointcloud.\n",
        "        self.partition = partition  # Dataset partition.\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Retrieve a pointcloud and its label, applying data augmentation if in training mode.\n",
        "\n",
        "        Parameters:\n",
        "        item (int): Index of the pointcloud to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Tuple containing the pointcloud and its label.\n",
        "        \"\"\"\n",
        "        pointcloud = self.data[item][:self.num_points]  # Get the subset of points.\n",
        "        label = self.label[item]\n",
        "        if self.partition == 'train':  # Conditionally apply augmentations.\n",
        "            pointcloud = translate_pointcloud(pointcloud)\n",
        "            np.random.shuffle(pointcloud)  # Shuffle points to remove any order bias.\n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of pointclouds in the dataset.\n",
        "\n",
        "        Returns:\n",
        "        int: The number of pointclouds.\n",
        "        \"\"\"\n",
        "        return self.data.shape[0]  # Number of pointclouds in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary for ModelNet40 classes. Helpful when printing confusion matrix. Note that ModelNet40 sorts its classes alphabetically\n",
        "label_dict = {\n",
        "    'airplane': 0,\n",
        "    'bathtub': 1,\n",
        "    'bed': 2,\n",
        "    'bench': 3,\n",
        "    'bookshelf': 4,\n",
        "    'bottle': 5,\n",
        "    'bowl': 6,\n",
        "    'car': 7,\n",
        "    'chair': 8,\n",
        "    'cone': 9,\n",
        "    'cup': 10,\n",
        "    'curtain': 11,\n",
        "    'desk': 12,\n",
        "    'door': 13,\n",
        "    'dresser': 14,\n",
        "    'flower_pot': 15,\n",
        "    'glass_box': 16,\n",
        "    'guitar': 17,\n",
        "    'keyboard': 18,\n",
        "    'lamp': 19,\n",
        "    'laptop': 20,\n",
        "    'mantel': 21,\n",
        "    'monitor': 22,\n",
        "    'night_stand': 23,\n",
        "    'person': 24,\n",
        "    'piano': 25,\n",
        "    'plant': 26,\n",
        "    'radio': 27,\n",
        "    'range_hood': 28,\n",
        "    'sink': 29,\n",
        "    'sofa': 30,\n",
        "    'stairs': 31,\n",
        "    'stool': 32,\n",
        "    'table': 33,\n",
        "    'tent': 34,\n",
        "    'toilet': 35,\n",
        "    'tv_stand': 36,\n",
        "    'vase': 37,\n",
        "    'wardrobe': 38,\n",
        "    'xbox': 39\n",
        "}\n",
        "modes = list(label_dict.keys())"
      ],
      "metadata": {
        "id": "eaxTC3jlNufT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMOAvhfCU2r"
      },
      "source": [
        "### **Training and Testing algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gYGrRCMWgBGG"
      },
      "outputs": [],
      "source": [
        "def train(args, io):\n",
        "    # 1. Determine the size of the original training dataset\n",
        "    total_train_samples = len(ModelNet40(partition='train', num_points=args.num_points))\n",
        "    train_size = int(0.75 * total_train_samples)  # 60% of the original training dataset\n",
        "    validation_size = total_train_samples - train_size  # Remaining samples for validation\n",
        "\n",
        "    # 2. Split the original training dataset\n",
        "    train_dataset, validation_dataset = random_split(ModelNet40(partition='train', num_points=args.num_points), [train_size, validation_size])\n",
        "\n",
        "    # 3. Create DataLoader for the training and validation datasets\n",
        "    train_loader = DataLoader(train_dataset, num_workers=2, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    validation_loader = DataLoader(validation_dataset, num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    # Test DataLoader remains unchanged\n",
        "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "    history = {\"1\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"2\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"T\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}}}\n",
        "    loss1_list = []\n",
        "    loss2_list = []\n",
        "    acc1_list = []\n",
        "    acc2_list = []\n",
        "    eStopThreshold, eStopCounter = 8, 0\n",
        "    device = \"cuda\" # Set up your NVIDIA GPU.\n",
        "    model = eeModel_E1(args).to(device) #Initialize your model.\n",
        "    print(summary(model))## Print your model summary.\n",
        "    print(\"Let's use\", torch.cpu.device_count(), \"GPUs!\") ## Print how many GPUs are being used.\n",
        "\n",
        "    #Set up your optimizer and loss\n",
        "    if args.use_sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        loss1Total, loss2Total, totalLoss = 0, 0, 0\n",
        "        acc1Total, acc2Total, totalAcc = 0, 0, 0\n",
        "        loss1Total_v, loss2Total_v, valLoss = 0, 0, 0\n",
        "        acc1Total_v, acc2Total_v, valAcc = 0, 0, 0\n",
        "        train_loss = 0.0\n",
        "        loss = 0\n",
        "        bestAcc = 0\n",
        "        best_loss = 100\n",
        "        preValLoss = 100\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data, label in train_loader:\n",
        "            data, label = data.to(device), label.to(device).squeeze() # Send your input data and label to device e.g. GPU, CPU\n",
        "            data = data.permute(0, 2, 1) # Permute your data for subsequent operations\n",
        "            batch_size = data.size()[0] # Retrieve your batch size\n",
        "            opt.zero_grad() # Zero your optimizer\n",
        "            logits1, logits2 = model(data) # Compute unnormalized model outputs e.g. short branch and long branch outputs\n",
        "            loss1, loss2 = criterion(logits1, label), criterion(logits2, label) # Calculate your losses e.g. short branch and long branch losses\n",
        "            loss1_list.append(loss1.item()) # Append your short branch losses\n",
        "            loss2_list.append(loss2.item()) # Append your long branch losses\n",
        "            loss1Total += loss1.item() # Aggregate your short branch losses\n",
        "            loss2Total += loss2.item() # Aggregate your long branch losses\n",
        "            totalLoss += 0.5*loss1.item() + 0.5*loss2.item() # Average your loss\n",
        "            loss1.backward(retain_graph=True) # Backward propagate your short branch loss\n",
        "            loss2.backward(retain_graph=True) # Backward propagate your long branch loss\n",
        "            _, predicted1 = torch.max(logits1, 1) # Max pool your short branch predicitions\n",
        "            _, predicted2 = torch.max(logits2, 1) # Max pool your long branch predicitions\n",
        "            acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy()) # Calculate your short branch accuracy\n",
        "            acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy()) # Calculate your long branch accurac\n",
        "            acc1_list.append(acc1) # Append your short branch accuracies\n",
        "            acc2_list.append(acc2) # Append your long branch accuracies\n",
        "            acc1Total += acc1 # Aggregate your short branch accuracies\n",
        "            acc2Total += acc2 # Aggregate your long branch accuracies\n",
        "            totalAcc += 0.5*acc1+0.5*acc2 # Average your accuracy\n",
        "            opt.step() # Step your optimizer\n",
        "            count += batch_size # Recursively add number of prediciton counts\n",
        "        loss1Total = loss1Total/len(train_loader) # Normalize your short branch losses\n",
        "        loss2Total = loss2Total/len(train_loader) # Normalize your long branch losses\n",
        "        totalLoss = totalLoss/len(train_loader) # Normalize your total loss\n",
        "        acc1Total = acc1Total/len(train_loader) # Normalize your short branch accuracy\n",
        "        acc2Total = acc2Total/len(train_loader) # Normalize your long branch accuracy\n",
        "        totalAcc = totalAcc/len(train_loader) # Normalize your total accuracy\n",
        "        ############## Append to your history dictionaty################\n",
        "        history[\"1\"][\"train\"][\"loss\"].append(loss1Total)\n",
        "        history[\"1\"][\"train\"][\"accuracy\"].append(acc1Total)\n",
        "        history[\"2\"][\"train\"][\"loss\"].append(loss2Total)\n",
        "        history[\"2\"][\"train\"][\"accuracy\"].append(acc2Total)\n",
        "        history[\"T\"][\"train\"][\"loss\"].append(totalLoss)\n",
        "        history[\"T\"][\"train\"][\"accuracy\"].append(totalAcc)\n",
        "        ###############################################################\n",
        "        print(\"epoch {} --> trainLoss: {:0.3f}, trainAcc: {:0.3f}\" # Print your epoch, total normalized loss, total normalized accuracy.\n",
        "                  .format(epoch+1, totalLoss, totalAcc), end=\"\")\n",
        "\n",
        "        ####################### Validation is identical training####################\n",
        "        if validation_loader:\n",
        "          with torch.no_grad():\n",
        "            model.eval() # Set up your model for evaluation\n",
        "            for data, label in validation_loader:\n",
        "              data, label = data.to(device), label.to(device).squeeze()\n",
        "              data = data.permute(0, 2, 1)\n",
        "              batch_size = data.size()[0]\n",
        "              opt.zero_grad()\n",
        "              logits1, logits2 = model(data) ## ADD TWO LOGITS\n",
        "\n",
        "              loss1, loss2 = criterion(logits1, label.long()), criterion(logits2, label.long())\n",
        "              loss1Total_v += loss1.item()\n",
        "              loss2Total_v += loss2.item()\n",
        "              valLoss += 0.5*loss1.item() + 0.5*loss2.item()\n",
        "\n",
        "              _, predicted1 = torch.max(logits1, 1)\n",
        "              _, predicted2 = torch.max(logits2, 1)\n",
        "              acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy())\n",
        "              acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy())\n",
        "\n",
        "              acc1Total_v += acc1\n",
        "              acc2Total_v += acc2\n",
        "              valAcc += 0.5*acc1 + 0.5*acc2\n",
        "\n",
        "            loss1Total_v = loss1Total_v/len(validation_loader)\n",
        "            loss2Total_v = loss2Total_v/len(validation_loader)\n",
        "            valLoss = valLoss/len(validation_loader)\n",
        "            acc1Total_v = acc1Total_v/len(validation_loader)\n",
        "            acc2Total_v = acc2Total_v/len(validation_loader)\n",
        "            valAcc = valAcc/len(validation_loader)\n",
        "\n",
        "            history[\"1\"][\"validation\"][\"loss\"].append(loss1Total_v)\n",
        "            history[\"1\"][\"validation\"][\"accuracy\"].append(acc1Total_v)\n",
        "            history[\"2\"][\"validation\"][\"loss\"].append(loss2Total_v)\n",
        "            history[\"2\"][\"validation\"][\"accuracy\"].append(acc2Total_v)\n",
        "            history[\"T\"][\"validation\"][\"loss\"].append(valLoss)\n",
        "            history[\"T\"][\"validation\"][\"accuracy\"].append(valAcc)\n",
        "\n",
        "          print(\", validLoss: {:0.3f}, validAcc: {:0.3f}\"\n",
        "                  .format(valLoss, valAcc))\n",
        "#############Save best performing model if current test accuracy outperforms the recorded best accuracy#############\n",
        "          if valLoss <= best_loss:\n",
        "            # Save the model with the lowest validation loss.\n",
        "            best_loss = valLoss\n",
        "            torch.save(model.state_dict(), 'checkpoints/%s/models/model.pth' % args.exp_name)\n",
        "            print(\"Model Saved!\")\n",
        "#####################################################################################################################\n",
        "\n",
        "########################Stop training if validation loss is increasing#############################\n",
        "          if valLoss >= preValLoss:\n",
        "            eStopCounter += 1\n",
        "            if eStopCounter >= eStopThreshold:\n",
        "              print(\"Training Stopped!\")\n",
        "              break;\n",
        "          else:\n",
        "            eStopCounter = 0\n",
        "          preValLoss = valLoss\n",
        "        else:\n",
        "          print(\"\")\n",
        "#####################################################################################################\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oy1DG9OAlwYg"
      },
      "outputs": [],
      "source": [
        "train_demo = ModelNet40(1024)\n",
        "test_demo = ModelNet40(1024, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize your hyperparametr arguments\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "1wNYf788EJk2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N05X14SdBmwb",
        "outputId": "fc01e25b-0568-43a0-99ea-b2125d7888c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "if not os.path.exists('checkpoints'):\n",
        "  os.makedirs('checkpoints')\n",
        "if not os.path.exists('checkpoints/'+args.exp_name):\n",
        "  os.makedirs('checkpoints/'+args.exp_name)\n",
        "if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):\n",
        "  os.makedirs('checkpoints/'+args.exp_name+'/'+'models')\n",
        "os.system('cp main.py checkpoints'+'/'+args.exp_name+'/'+'main.py.backup')\n",
        "os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
        "os.system('cp util.py checkpoints' + '/' + args.exp_name + '/' + 'util.py.backup')\n",
        "os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jKeuCJWJ_Mr9"
      },
      "outputs": [],
      "source": [
        "io = IOStream('checkpoints/' + args.exp_name + '/run.log')\n",
        "args.no_cuda = False\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train(args, io)"
      ],
      "metadata": {
        "id": "PfpAkmrEq0-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f277707-f100-4c0f-a22e-1c0529f173ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "eeModel_E1                               --\n",
            "├─BatchNorm2d: 1-1                       128\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─BatchNorm2d: 1-3                       256\n",
            "├─BatchNorm2d: 1-4                       512\n",
            "├─BatchNorm1d: 1-5                       2,048\n",
            "├─Sequential: 1-6                        128\n",
            "│    └─Conv2d: 2-1                       384\n",
            "│    └─BatchNorm2d: 2-2                  (recursive)\n",
            "│    └─LeakyReLU: 2-3                    --\n",
            "├─Sequential: 1-7                        128\n",
            "│    └─Conv2d: 2-4                       8,192\n",
            "│    └─BatchNorm2d: 2-5                  (recursive)\n",
            "│    └─LeakyReLU: 2-6                    --\n",
            "├─Sequential: 1-8                        256\n",
            "│    └─Conv2d: 2-7                       16,384\n",
            "│    └─BatchNorm2d: 2-8                  (recursive)\n",
            "│    └─LeakyReLU: 2-9                    --\n",
            "├─Sequential: 1-9                        --\n",
            "│    └─Linear: 2-10                      262,144\n",
            "│    └─BatchNorm1d: 2-11                 1,024\n",
            "│    └─LeakyReLU: 2-12                   --\n",
            "│    └─Dropout: 2-13                     --\n",
            "│    └─Linear: 2-14                      131,328\n",
            "│    └─BatchNorm1d: 2-15                 512\n",
            "│    └─LeakyReLU: 2-16                   --\n",
            "│    └─Dropout: 2-17                     --\n",
            "│    └─Linear: 2-18                      10,280\n",
            "├─Sequential: 1-10                       512\n",
            "│    └─Conv2d: 2-19                      65,536\n",
            "│    └─BatchNorm2d: 2-20                 (recursive)\n",
            "│    └─LeakyReLU: 2-21                   --\n",
            "├─Sequential: 1-11                       2,048\n",
            "│    └─Conv1d: 2-22                      524,288\n",
            "│    └─BatchNorm1d: 2-23                 (recursive)\n",
            "│    └─LeakyReLU: 2-24                   --\n",
            "├─Sequential: 1-12                       --\n",
            "│    └─Linear: 2-25                      1,048,576\n",
            "│    └─BatchNorm1d: 2-26                 1,024\n",
            "│    └─LeakyReLU: 2-27                   --\n",
            "│    └─Dropout: 2-28                     --\n",
            "│    └─Linear: 2-29                      131,328\n",
            "│    └─BatchNorm1d: 2-30                 512\n",
            "│    └─LeakyReLU: 2-31                   --\n",
            "│    └─Dropout: 2-32                     --\n",
            "│    └─Linear: 2-33                      10,280\n",
            "=================================================================\n",
            "Total params: 2,217,936\n",
            "Trainable params: 2,217,936\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 --> trainLoss: 2.956, trainAcc: 0.380, validLoss: 2.478, validAcc: 0.496\n",
            "Model Saved!\n",
            "epoch 2 --> trainLoss: 2.375, trainAcc: 0.563, validLoss: 2.178, validAcc: 0.640\n",
            "Model Saved!\n",
            "epoch 3 --> trainLoss: 2.219, trainAcc: 0.630, validLoss: 2.074, validAcc: 0.671\n",
            "Model Saved!\n",
            "epoch 4 --> trainLoss: 2.127, trainAcc: 0.669, validLoss: 2.004, validAcc: 0.705\n",
            "Model Saved!\n",
            "epoch 5 --> trainLoss: 2.074, trainAcc: 0.691, validLoss: 1.983, validAcc: 0.728\n",
            "Model Saved!\n",
            "epoch 6 --> trainLoss: 2.018, trainAcc: 0.717, validLoss: 1.889, validAcc: 0.757\n",
            "Model Saved!\n",
            "epoch 7 --> trainLoss: 1.978, trainAcc: 0.732, validLoss: 1.849, validAcc: 0.785\n",
            "Model Saved!\n",
            "epoch 8 --> trainLoss: 1.938, trainAcc: 0.749, validLoss: 1.808, validAcc: 0.793\n",
            "Model Saved!\n",
            "epoch 9 --> trainLoss: 1.919, trainAcc: 0.762, validLoss: 1.794, validAcc: 0.807\n",
            "Model Saved!\n",
            "epoch 10 --> trainLoss: 1.892, trainAcc: 0.769, validLoss: 1.788, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 11 --> trainLoss: 1.867, trainAcc: 0.781, validLoss: 1.801, validAcc: 0.797\n",
            "Model Saved!\n",
            "epoch 12 --> trainLoss: 1.854, trainAcc: 0.790, validLoss: 1.726, validAcc: 0.831\n",
            "Model Saved!\n",
            "epoch 13 --> trainLoss: 1.842, trainAcc: 0.794, validLoss: 1.758, validAcc: 0.810\n",
            "Model Saved!\n",
            "epoch 14 --> trainLoss: 1.820, trainAcc: 0.800, validLoss: 1.720, validAcc: 0.846\n",
            "Model Saved!\n",
            "epoch 15 --> trainLoss: 1.822, trainAcc: 0.801, validLoss: 1.732, validAcc: 0.827\n",
            "Model Saved!\n",
            "epoch 16 --> trainLoss: 1.797, trainAcc: 0.813, validLoss: 1.737, validAcc: 0.824\n",
            "Model Saved!\n",
            "epoch 17 --> trainLoss: 1.791, trainAcc: 0.812, validLoss: 1.750, validAcc: 0.821\n",
            "Model Saved!\n",
            "epoch 18 --> trainLoss: 1.779, trainAcc: 0.821, validLoss: 1.749, validAcc: 0.830\n",
            "Model Saved!\n",
            "epoch 19 --> trainLoss: 1.776, trainAcc: 0.823, validLoss: 1.798, validAcc: 0.810\n",
            "Model Saved!\n",
            "epoch 20 --> trainLoss: 1.768, trainAcc: 0.822, validLoss: 1.685, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 21 --> trainLoss: 1.753, trainAcc: 0.832, validLoss: 1.690, validAcc: 0.839\n",
            "Model Saved!\n",
            "epoch 22 --> trainLoss: 1.747, trainAcc: 0.832, validLoss: 1.775, validAcc: 0.810\n",
            "Model Saved!\n",
            "epoch 23 --> trainLoss: 1.752, trainAcc: 0.829, validLoss: 1.713, validAcc: 0.835\n",
            "Model Saved!\n",
            "epoch 24 --> trainLoss: 1.741, trainAcc: 0.833, validLoss: 1.666, validAcc: 0.847\n",
            "Model Saved!\n",
            "epoch 25 --> trainLoss: 1.728, trainAcc: 0.843, validLoss: 1.715, validAcc: 0.827\n",
            "Model Saved!\n",
            "epoch 26 --> trainLoss: 1.728, trainAcc: 0.839, validLoss: 1.695, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 27 --> trainLoss: 1.718, trainAcc: 0.844, validLoss: 1.707, validAcc: 0.830\n",
            "Model Saved!\n",
            "epoch 28 --> trainLoss: 1.718, trainAcc: 0.845, validLoss: 1.668, validAcc: 0.850\n",
            "Model Saved!\n",
            "epoch 29 --> trainLoss: 1.713, trainAcc: 0.848, validLoss: 1.659, validAcc: 0.852\n",
            "Model Saved!\n",
            "epoch 30 --> trainLoss: 1.710, trainAcc: 0.850, validLoss: 1.700, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 31 --> trainLoss: 1.709, trainAcc: 0.845, validLoss: 1.668, validAcc: 0.850\n",
            "Model Saved!\n",
            "epoch 32 --> trainLoss: 1.705, trainAcc: 0.850, validLoss: 1.644, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 33 --> trainLoss: 1.699, trainAcc: 0.855, validLoss: 1.614, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 34 --> trainLoss: 1.702, trainAcc: 0.853, validLoss: 1.672, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 35 --> trainLoss: 1.688, trainAcc: 0.858, validLoss: 1.627, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 36 --> trainLoss: 1.684, trainAcc: 0.862, validLoss: 1.650, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 37 --> trainLoss: 1.683, trainAcc: 0.859, validLoss: 1.629, validAcc: 0.863\n",
            "Model Saved!\n",
            "epoch 38 --> trainLoss: 1.677, trainAcc: 0.859, validLoss: 1.653, validAcc: 0.853\n",
            "Model Saved!\n",
            "epoch 39 --> trainLoss: 1.676, trainAcc: 0.860, validLoss: 1.629, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 40 --> trainLoss: 1.668, trainAcc: 0.868, validLoss: 1.628, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 41 --> trainLoss: 1.670, trainAcc: 0.861, validLoss: 1.641, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 42 --> trainLoss: 1.675, trainAcc: 0.862, validLoss: 1.637, validAcc: 0.855\n",
            "Model Saved!\n",
            "epoch 43 --> trainLoss: 1.677, trainAcc: 0.862, validLoss: 1.657, validAcc: 0.854\n",
            "Model Saved!\n",
            "epoch 44 --> trainLoss: 1.663, trainAcc: 0.868, validLoss: 1.657, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 45 --> trainLoss: 1.662, trainAcc: 0.871, validLoss: 1.671, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 46 --> trainLoss: 1.660, trainAcc: 0.872, validLoss: 1.629, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 47 --> trainLoss: 1.665, trainAcc: 0.866, validLoss: 1.616, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 48 --> trainLoss: 1.654, trainAcc: 0.872, validLoss: 1.708, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 49 --> trainLoss: 1.651, trainAcc: 0.872, validLoss: 1.614, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 50 --> trainLoss: 1.647, trainAcc: 0.876, validLoss: 1.632, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 51 --> trainLoss: 1.645, trainAcc: 0.872, validLoss: 1.625, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 52 --> trainLoss: 1.643, trainAcc: 0.877, validLoss: 1.639, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 53 --> trainLoss: 1.645, trainAcc: 0.874, validLoss: 1.624, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 54 --> trainLoss: 1.634, trainAcc: 0.878, validLoss: 1.590, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 55 --> trainLoss: 1.635, trainAcc: 0.879, validLoss: 1.593, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 56 --> trainLoss: 1.632, trainAcc: 0.883, validLoss: 1.623, validAcc: 0.863\n",
            "Model Saved!\n",
            "epoch 57 --> trainLoss: 1.634, trainAcc: 0.878, validLoss: 1.619, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 58 --> trainLoss: 1.634, trainAcc: 0.880, validLoss: 1.605, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 59 --> trainLoss: 1.631, trainAcc: 0.880, validLoss: 1.573, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 60 --> trainLoss: 1.629, trainAcc: 0.880, validLoss: 1.630, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 61 --> trainLoss: 1.630, trainAcc: 0.883, validLoss: 1.631, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 62 --> trainLoss: 1.624, trainAcc: 0.885, validLoss: 1.607, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 63 --> trainLoss: 1.625, trainAcc: 0.881, validLoss: 1.588, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 64 --> trainLoss: 1.624, trainAcc: 0.882, validLoss: 1.662, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 65 --> trainLoss: 1.620, trainAcc: 0.885, validLoss: 1.592, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 66 --> trainLoss: 1.618, trainAcc: 0.887, validLoss: 1.616, validAcc: 0.871\n",
            "Model Saved!\n",
            "epoch 67 --> trainLoss: 1.621, trainAcc: 0.883, validLoss: 1.617, validAcc: 0.863\n",
            "Model Saved!\n",
            "epoch 68 --> trainLoss: 1.615, trainAcc: 0.889, validLoss: 1.611, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 69 --> trainLoss: 1.608, trainAcc: 0.893, validLoss: 1.615, validAcc: 0.865\n",
            "Model Saved!\n",
            "epoch 70 --> trainLoss: 1.612, trainAcc: 0.889, validLoss: 1.602, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 71 --> trainLoss: 1.616, trainAcc: 0.889, validLoss: 1.587, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 72 --> trainLoss: 1.603, trainAcc: 0.892, validLoss: 1.572, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 73 --> trainLoss: 1.601, trainAcc: 0.893, validLoss: 1.596, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 74 --> trainLoss: 1.603, trainAcc: 0.892, validLoss: 1.615, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 75 --> trainLoss: 1.602, trainAcc: 0.893, validLoss: 1.578, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 76 --> trainLoss: 1.604, trainAcc: 0.890, validLoss: 1.628, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 77 --> trainLoss: 1.601, trainAcc: 0.897, validLoss: 1.617, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 78 --> trainLoss: 1.594, trainAcc: 0.897, validLoss: 1.568, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 79 --> trainLoss: 1.594, trainAcc: 0.898, validLoss: 1.581, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 80 --> trainLoss: 1.591, trainAcc: 0.898, validLoss: 1.587, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 81 --> trainLoss: 1.592, trainAcc: 0.898, validLoss: 1.550, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 82 --> trainLoss: 1.593, trainAcc: 0.896, validLoss: 1.564, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 83 --> trainLoss: 1.586, trainAcc: 0.902, validLoss: 1.595, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 84 --> trainLoss: 1.582, trainAcc: 0.901, validLoss: 1.568, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 85 --> trainLoss: 1.590, trainAcc: 0.900, validLoss: 1.556, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 86 --> trainLoss: 1.582, trainAcc: 0.902, validLoss: 1.610, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 87 --> trainLoss: 1.583, trainAcc: 0.901, validLoss: 1.581, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 88 --> trainLoss: 1.582, trainAcc: 0.902, validLoss: 1.582, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 89 --> trainLoss: 1.577, trainAcc: 0.902, validLoss: 1.575, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 90 --> trainLoss: 1.580, trainAcc: 0.902, validLoss: 1.562, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 91 --> trainLoss: 1.574, trainAcc: 0.905, validLoss: 1.551, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 92 --> trainLoss: 1.572, trainAcc: 0.906, validLoss: 1.547, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 93 --> trainLoss: 1.574, trainAcc: 0.904, validLoss: 1.584, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 94 --> trainLoss: 1.572, trainAcc: 0.905, validLoss: 1.580, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 95 --> trainLoss: 1.574, trainAcc: 0.905, validLoss: 1.609, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 96 --> trainLoss: 1.565, trainAcc: 0.909, validLoss: 1.585, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 97 --> trainLoss: 1.575, trainAcc: 0.905, validLoss: 1.584, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 98 --> trainLoss: 1.564, trainAcc: 0.910, validLoss: 1.587, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 99 --> trainLoss: 1.564, trainAcc: 0.908, validLoss: 1.636, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 100 --> trainLoss: 1.558, trainAcc: 0.911, validLoss: 1.558, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 101 --> trainLoss: 1.558, trainAcc: 0.911, validLoss: 1.573, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 102 --> trainLoss: 1.561, trainAcc: 0.909, validLoss: 1.579, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 103 --> trainLoss: 1.552, trainAcc: 0.916, validLoss: 1.575, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 104 --> trainLoss: 1.561, trainAcc: 0.914, validLoss: 1.574, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 105 --> trainLoss: 1.548, trainAcc: 0.915, validLoss: 1.553, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 106 --> trainLoss: 1.555, trainAcc: 0.911, validLoss: 1.580, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 107 --> trainLoss: 1.549, trainAcc: 0.917, validLoss: 1.548, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 108 --> trainLoss: 1.547, trainAcc: 0.917, validLoss: 1.546, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 109 --> trainLoss: 1.550, trainAcc: 0.915, validLoss: 1.576, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 110 --> trainLoss: 1.546, trainAcc: 0.914, validLoss: 1.574, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 111 --> trainLoss: 1.551, trainAcc: 0.915, validLoss: 1.540, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 112 --> trainLoss: 1.541, trainAcc: 0.920, validLoss: 1.564, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 113 --> trainLoss: 1.545, trainAcc: 0.916, validLoss: 1.557, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 114 --> trainLoss: 1.544, trainAcc: 0.919, validLoss: 1.587, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 115 --> trainLoss: 1.542, trainAcc: 0.919, validLoss: 1.595, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 116 --> trainLoss: 1.534, trainAcc: 0.922, validLoss: 1.586, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 117 --> trainLoss: 1.539, trainAcc: 0.918, validLoss: 1.556, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 118 --> trainLoss: 1.535, trainAcc: 0.921, validLoss: 1.539, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 119 --> trainLoss: 1.532, trainAcc: 0.923, validLoss: 1.537, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 120 --> trainLoss: 1.529, trainAcc: 0.923, validLoss: 1.512, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 121 --> trainLoss: 1.534, trainAcc: 0.924, validLoss: 1.582, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 122 --> trainLoss: 1.530, trainAcc: 0.922, validLoss: 1.521, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 123 --> trainLoss: 1.526, trainAcc: 0.924, validLoss: 1.543, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 124 --> trainLoss: 1.524, trainAcc: 0.926, validLoss: 1.588, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 125 --> trainLoss: 1.522, trainAcc: 0.926, validLoss: 1.545, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 126 --> trainLoss: 1.525, trainAcc: 0.927, validLoss: 1.541, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 127 --> trainLoss: 1.526, trainAcc: 0.925, validLoss: 1.555, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 128 --> trainLoss: 1.520, trainAcc: 0.927, validLoss: 1.569, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 129 --> trainLoss: 1.518, trainAcc: 0.929, validLoss: 1.536, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 130 --> trainLoss: 1.522, trainAcc: 0.926, validLoss: 1.562, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 131 --> trainLoss: 1.515, trainAcc: 0.930, validLoss: 1.555, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 132 --> trainLoss: 1.516, trainAcc: 0.931, validLoss: 1.562, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 133 --> trainLoss: 1.509, trainAcc: 0.929, validLoss: 1.542, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 134 --> trainLoss: 1.513, trainAcc: 0.930, validLoss: 1.539, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 135 --> trainLoss: 1.509, trainAcc: 0.933, validLoss: 1.538, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 136 --> trainLoss: 1.506, trainAcc: 0.932, validLoss: 1.537, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 137 --> trainLoss: 1.505, trainAcc: 0.933, validLoss: 1.529, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 138 --> trainLoss: 1.504, trainAcc: 0.933, validLoss: 1.518, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 139 --> trainLoss: 1.500, trainAcc: 0.932, validLoss: 1.540, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 140 --> trainLoss: 1.504, trainAcc: 0.934, validLoss: 1.536, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 141 --> trainLoss: 1.504, trainAcc: 0.932, validLoss: 1.517, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 142 --> trainLoss: 1.497, trainAcc: 0.936, validLoss: 1.538, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 143 --> trainLoss: 1.498, trainAcc: 0.938, validLoss: 1.520, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 144 --> trainLoss: 1.489, trainAcc: 0.939, validLoss: 1.500, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 145 --> trainLoss: 1.497, trainAcc: 0.935, validLoss: 1.515, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 146 --> trainLoss: 1.497, trainAcc: 0.937, validLoss: 1.539, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 147 --> trainLoss: 1.488, trainAcc: 0.941, validLoss: 1.513, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 148 --> trainLoss: 1.488, trainAcc: 0.939, validLoss: 1.530, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 149 --> trainLoss: 1.490, trainAcc: 0.939, validLoss: 1.527, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 150 --> trainLoss: 1.487, trainAcc: 0.938, validLoss: 1.519, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 151 --> trainLoss: 1.485, trainAcc: 0.942, validLoss: 1.524, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 152 --> trainLoss: 1.484, trainAcc: 0.940, validLoss: 1.503, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 153 --> trainLoss: 1.480, trainAcc: 0.941, validLoss: 1.524, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 154 --> trainLoss: 1.480, trainAcc: 0.944, validLoss: 1.519, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 155 --> trainLoss: 1.475, trainAcc: 0.945, validLoss: 1.527, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 156 --> trainLoss: 1.480, trainAcc: 0.943, validLoss: 1.519, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 157 --> trainLoss: 1.479, trainAcc: 0.944, validLoss: 1.502, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 158 --> trainLoss: 1.476, trainAcc: 0.944, validLoss: 1.502, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 159 --> trainLoss: 1.472, trainAcc: 0.946, validLoss: 1.532, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 160 --> trainLoss: 1.473, trainAcc: 0.946, validLoss: 1.521, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 161 --> trainLoss: 1.468, trainAcc: 0.948, validLoss: 1.499, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 162 --> trainLoss: 1.469, trainAcc: 0.947, validLoss: 1.496, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 163 --> trainLoss: 1.466, trainAcc: 0.948, validLoss: 1.512, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 164 --> trainLoss: 1.468, trainAcc: 0.947, validLoss: 1.505, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 165 --> trainLoss: 1.461, trainAcc: 0.951, validLoss: 1.490, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 166 --> trainLoss: 1.461, trainAcc: 0.951, validLoss: 1.508, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 167 --> trainLoss: 1.461, trainAcc: 0.952, validLoss: 1.504, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 168 --> trainLoss: 1.463, trainAcc: 0.950, validLoss: 1.519, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 169 --> trainLoss: 1.459, trainAcc: 0.951, validLoss: 1.493, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 170 --> trainLoss: 1.456, trainAcc: 0.953, validLoss: 1.504, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 171 --> trainLoss: 1.459, trainAcc: 0.950, validLoss: 1.490, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 172 --> trainLoss: 1.452, trainAcc: 0.954, validLoss: 1.480, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 173 --> trainLoss: 1.454, trainAcc: 0.954, validLoss: 1.496, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 174 --> trainLoss: 1.452, trainAcc: 0.954, validLoss: 1.493, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 175 --> trainLoss: 1.448, trainAcc: 0.957, validLoss: 1.480, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 176 --> trainLoss: 1.450, trainAcc: 0.955, validLoss: 1.483, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 177 --> trainLoss: 1.450, trainAcc: 0.956, validLoss: 1.496, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 178 --> trainLoss: 1.445, trainAcc: 0.958, validLoss: 1.493, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 179 --> trainLoss: 1.445, trainAcc: 0.956, validLoss: 1.484, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 180 --> trainLoss: 1.441, trainAcc: 0.957, validLoss: 1.493, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 181 --> trainLoss: 1.440, trainAcc: 0.959, validLoss: 1.475, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 182 --> trainLoss: 1.444, trainAcc: 0.956, validLoss: 1.490, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 183 --> trainLoss: 1.435, trainAcc: 0.961, validLoss: 1.484, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 184 --> trainLoss: 1.440, trainAcc: 0.960, validLoss: 1.474, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 185 --> trainLoss: 1.437, trainAcc: 0.960, validLoss: 1.483, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 186 --> trainLoss: 1.433, trainAcc: 0.961, validLoss: 1.490, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 187 --> trainLoss: 1.433, trainAcc: 0.961, validLoss: 1.484, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 188 --> trainLoss: 1.433, trainAcc: 0.962, validLoss: 1.485, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 189 --> trainLoss: 1.433, trainAcc: 0.962, validLoss: 1.471, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 190 --> trainLoss: 1.432, trainAcc: 0.963, validLoss: 1.481, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 191 --> trainLoss: 1.431, trainAcc: 0.963, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 192 --> trainLoss: 1.431, trainAcc: 0.961, validLoss: 1.481, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 193 --> trainLoss: 1.424, trainAcc: 0.964, validLoss: 1.471, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 194 --> trainLoss: 1.427, trainAcc: 0.963, validLoss: 1.475, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 195 --> trainLoss: 1.422, trainAcc: 0.967, validLoss: 1.475, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 196 --> trainLoss: 1.421, trainAcc: 0.966, validLoss: 1.464, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 197 --> trainLoss: 1.421, trainAcc: 0.968, validLoss: 1.474, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 198 --> trainLoss: 1.420, trainAcc: 0.965, validLoss: 1.475, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 199 --> trainLoss: 1.419, trainAcc: 0.966, validLoss: 1.477, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 200 --> trainLoss: 1.422, trainAcc: 0.964, validLoss: 1.474, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 201 --> trainLoss: 1.417, trainAcc: 0.969, validLoss: 1.467, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 202 --> trainLoss: 1.415, trainAcc: 0.968, validLoss: 1.473, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 203 --> trainLoss: 1.415, trainAcc: 0.968, validLoss: 1.472, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 204 --> trainLoss: 1.414, trainAcc: 0.969, validLoss: 1.474, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 205 --> trainLoss: 1.416, trainAcc: 0.967, validLoss: 1.469, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 206 --> trainLoss: 1.414, trainAcc: 0.968, validLoss: 1.474, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 207 --> trainLoss: 1.415, trainAcc: 0.968, validLoss: 1.465, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 208 --> trainLoss: 1.413, trainAcc: 0.969, validLoss: 1.470, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 209 --> trainLoss: 1.410, trainAcc: 0.970, validLoss: 1.470, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 210 --> trainLoss: 1.407, trainAcc: 0.973, validLoss: 1.469, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 211 --> trainLoss: 1.406, trainAcc: 0.973, validLoss: 1.471, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 212 --> trainLoss: 1.408, trainAcc: 0.970, validLoss: 1.460, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 213 --> trainLoss: 1.406, trainAcc: 0.971, validLoss: 1.465, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 214 --> trainLoss: 1.402, trainAcc: 0.973, validLoss: 1.459, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 215 --> trainLoss: 1.405, trainAcc: 0.972, validLoss: 1.470, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 216 --> trainLoss: 1.404, trainAcc: 0.972, validLoss: 1.474, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 217 --> trainLoss: 1.406, trainAcc: 0.971, validLoss: 1.467, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 218 --> trainLoss: 1.404, trainAcc: 0.973, validLoss: 1.469, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 219 --> trainLoss: 1.405, trainAcc: 0.974, validLoss: 1.462, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 220 --> trainLoss: 1.401, trainAcc: 0.972, validLoss: 1.466, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 221 --> trainLoss: 1.403, trainAcc: 0.973, validLoss: 1.464, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 222 --> trainLoss: 1.400, trainAcc: 0.974, validLoss: 1.467, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 223 --> trainLoss: 1.403, trainAcc: 0.973, validLoss: 1.469, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 224 --> trainLoss: 1.402, trainAcc: 0.970, validLoss: 1.465, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 225 --> trainLoss: 1.404, trainAcc: 0.972, validLoss: 1.462, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 226 --> trainLoss: 1.401, trainAcc: 0.972, validLoss: 1.471, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 227 --> trainLoss: 1.398, trainAcc: 0.974, validLoss: 1.465, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 228 --> trainLoss: 1.398, trainAcc: 0.972, validLoss: 1.463, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 229 --> trainLoss: 1.398, trainAcc: 0.974, validLoss: 1.461, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 230 --> trainLoss: 1.395, trainAcc: 0.974, validLoss: 1.460, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 231 --> trainLoss: 1.395, trainAcc: 0.976, validLoss: 1.462, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 232 --> trainLoss: 1.396, trainAcc: 0.974, validLoss: 1.467, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 233 --> trainLoss: 1.397, trainAcc: 0.974, validLoss: 1.464, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 234 --> trainLoss: 1.393, trainAcc: 0.975, validLoss: 1.463, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 235 --> trainLoss: 1.395, trainAcc: 0.974, validLoss: 1.459, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 236 --> trainLoss: 1.391, trainAcc: 0.976, validLoss: 1.469, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 237 --> trainLoss: 1.395, trainAcc: 0.976, validLoss: 1.458, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 238 --> trainLoss: 1.394, trainAcc: 0.975, validLoss: 1.466, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 239 --> trainLoss: 1.396, trainAcc: 0.975, validLoss: 1.464, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 240 --> trainLoss: 1.392, trainAcc: 0.976, validLoss: 1.463, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 241 --> trainLoss: 1.391, trainAcc: 0.976, validLoss: 1.453, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 242 --> trainLoss: 1.394, trainAcc: 0.976, validLoss: 1.459, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 243 --> trainLoss: 1.395, trainAcc: 0.975, validLoss: 1.462, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 244 --> trainLoss: 1.392, trainAcc: 0.976, validLoss: 1.462, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 245 --> trainLoss: 1.394, trainAcc: 0.976, validLoss: 1.459, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 246 --> trainLoss: 1.394, trainAcc: 0.976, validLoss: 1.466, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 247 --> trainLoss: 1.393, trainAcc: 0.976, validLoss: 1.466, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 248 --> trainLoss: 1.392, trainAcc: 0.975, validLoss: 1.460, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 249 --> trainLoss: 1.393, trainAcc: 0.976, validLoss: 1.460, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 250 --> trainLoss: 1.392, trainAcc: 0.975, validLoss: 1.463, validAcc: 0.917\n",
            "Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(sLoader, threshold=0.05, verbose=False):\n",
        "    \"\"\"\n",
        "    @Inference: we compare the output confidence (entropy) at a branch with a certain threshold\n",
        "\n",
        "    Parameters:\n",
        "    sLoader (DataLoader): Iterable over the dataset, provides batches of (inputs, groundTruth).\n",
        "    threshold (float): Entropy threshold used to decide the stopping point for shortBranch.\n",
        "    verbose (bool): If True, prints entropy values when they are below the threshold.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the recording dictionary of accuracies, list of predicted labels, and overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Softmax layer initialization for converting outputs to probability distributions\n",
        "    softmaxLayer = nn.Softmax(dim=1)\n",
        "\n",
        "    # Initialize accuracy and list to hold predictions\n",
        "    acc = 0\n",
        "    predicted = []\n",
        "\n",
        "    # Dictionary to keep track of accuracy per branch (shortBranch: 0, longBranch: 1)\n",
        "    recorder = {x: [] for x in range(2)}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disables gradient calculations for inference, saving memory and computations\n",
        "    with torch.no_grad():\n",
        "        for inputs, gTruth in sLoader:\n",
        "            # Move input and ground truth data to GPU\n",
        "            inputs, gTruth = inputs.to('cuda'), gTruth.to('cuda')\n",
        "            batch_size = inputs.size()[0] # Retrieve your batch size\n",
        "            # Permute dimensions of inputs to fit model's expected input shape\n",
        "            inputs = inputs.permute(0, 2, 1)\n",
        "            # Process inputs through the base part of the model\n",
        "            x_baseModelconv1 = model.baseModelconv1(get_graph_feature(inputs, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv2 = model.baseModelconv2(get_graph_feature(x_baseModelconv1, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv3 = model.baseModelconv3(get_graph_feature(x_baseModelconv2, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x = torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3), dim=1)\n",
        "            # Iterate through each sample in the batch\n",
        "            for iSample in range(x.shape[0]):\n",
        "                # Max pooling to reduce dimensions followed by permute and squeeze to fit to branch\n",
        "                out1 = model.get_short_branch_output(x[iSample:iSample+1], 1)\n",
        "                # Apply softmax to get probabilities\n",
        "                y = softmaxLayer(out1)\n",
        "                # Calculate the entropy of the output probabilities\n",
        "                e = entropy(y.detach().cpu().numpy().squeeze(), base=10)\n",
        "                # Check if entropy is below the threshold\n",
        "                if e <= threshold:\n",
        "                    if verbose:\n",
        "                        print(e)  # Optionally print the entropy\n",
        "                    _, label = torch.max(out1, 1)\n",
        "                    predicted.append(label)\n",
        "                    if label == gTruth[iSample].item():\n",
        "                        recorder[0].append(1)\n",
        "                        acc += 1\n",
        "                    else:\n",
        "                        recorder[0].append(0)\n",
        "                    continue\n",
        "\n",
        "                out2 = model.get_long_branch_output(x_baseModelconv1[iSample:iSample+1], x_baseModelconv2[iSample:iSample+1], x_baseModelconv3[iSample:iSample+1], 1)\n",
        "                _, label = torch.max(out2, 1)\n",
        "                predicted.append(label)\n",
        "                if label == gTruth[iSample].item():\n",
        "                    acc += 1\n",
        "                    recorder[1].append(1)\n",
        "                else:\n",
        "                    recorder[1].append(0)\n",
        "\n",
        "        # Calculate the total accuracy by summing correct predictions divided by total predictions\n",
        "        acc = acc / sum([len(recorder[x]) for x in range(2)])\n",
        "\n",
        "    return recorder, predicted, acc"
      ],
      "metadata": {
        "id": "l2rDIN0H0j4W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testingSummary(recorder, nBranches=2, overall=True):\n",
        "    \"\"\"\n",
        "    Prints a summary of testing accuracy for each branch and overall if specified.\n",
        "\n",
        "    Parameters:\n",
        "    recorder (dict): Dictionary containing lists of 0s and 1s where 1 represents a correct prediction, indexed by branch number.\n",
        "    nBranches (int): Number of branches in the model.\n",
        "    overall (bool): If True, prints the overall weighted accuracy across all branches.\n",
        "\n",
        "    Outputs:\n",
        "    Prints the accuracy of each branch and optionally the overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Header for the summary output\n",
        "    print('Summary')\n",
        "    print(\"======================\")\n",
        "\n",
        "    # Initialize accumulators for overall accuracy calculation\n",
        "    overallAcc, acc = 0, 0\n",
        "\n",
        "    # Calculate the total number of samples across all branches\n",
        "    overallCount = sum([len(recorder[x]) for x in range(nBranches)])\n",
        "\n",
        "    # Iterate through each branch to calculate and display individual accuracies\n",
        "    for i in range(nBranches):\n",
        "        # Number of samples in the current branch\n",
        "        countSamples = len(recorder[i])\n",
        "\n",
        "        # Check if there are samples in the current branch\n",
        "        if countSamples != 0:\n",
        "            # Calculate the accuracy for this branch\n",
        "            acc = recorder[i].count(1) / len(recorder[i])\n",
        "            # Print the accuracy and the percentage of total samples this branch represents\n",
        "            print(\"Branch {}: Accuracy {:.2f}% with {:.2f}% of the samples\".format(i+1, acc*100, countSamples/overallCount*100))\n",
        "        else:\n",
        "            # Handle the case where a branch has no samples\n",
        "            print(\"Branch {}: Got 0% of the samples\".format(i+1))\n",
        "\n",
        "        # Accumulate weighted accuracy for overall calculation\n",
        "        overallAcc += acc * countSamples\n",
        "\n",
        "    # If overall accuracy is to be calculated, display it\n",
        "    if overall:\n",
        "        print(\"Overall Weighted Accuracy: {:.2f}%\".format(overallAcc/overallCount*100))\n",
        "    return(overallAcc/overallCount*100)"
      ],
      "metadata": {
        "id": "xV7xiet2PEdd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "id": "Yb9eylNEIahG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce59c22-dbde-479e-ae75-8c3de9b3c7ae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->ptflops)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->ptflops)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->ptflops)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->ptflops)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->ptflops)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->ptflops)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->ptflops)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->ptflops)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ptflops-0.7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from ptflops import get_model_complexity_info"
      ],
      "metadata": {
        "id": "P_FNtX2gIUZK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flopsconv1, paramsconv1 = get_model_complexity_info(model.baseModelconv1, (6, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv2, paramsconv2 = get_model_complexity_info(model.baseModelconv2, (128, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv3, paramsconv3 = get_model_complexity_info(model.baseModelconv3, (128, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs: {:2f} MMac'.format(5.9+85.85+171.7))"
      ],
      "metadata": {
        "id": "5yXon4ULIYBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac38e18-de43-4c17-df09-c057c1c0cff5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  512, 100.000% Params, 5.9 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(384, 75.000% Params, 3.93 MMac, 66.667% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 25.000% Params, 1.31 MMac, 22.222% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 11.111% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  8.32 k, 100.000% Params, 85.85 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(8.19 k, 98.462% Params, 83.89 MMac, 97.710% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 1.538% Params, 1.31 MMac, 1.527% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.763% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  16.64 k, 100.000% Params, 171.7 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(16.38 k, 98.462% Params, 167.77 MMac, 97.710% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(256, 1.538% Params, 2.62 MMac, 1.527% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.763% MACs, negative_slope=0.2)\n",
            ")\n",
            "FLOPs: 263.450000 MMac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flops, params = get_model_complexity_info(model.shortBranch, (512, ), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ],
      "metadata": {
        "id": "32I1XlZlJiD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906f9429-b359-4e8d-dd39-3ea93f0eae69"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  405.29 k, 100.000% Params, 406.06 KMac, 100.000% MACs, \n",
            "  (0): Linear(262.14 k, 64.681% Params, 262.14 KMac, 64.559% MACs, in_features=512, out_features=512, bias=False)\n",
            "  (1): BatchNorm1d(1.02 k, 0.253% Params, 1.02 KMac, 0.252% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.126% MACs, negative_slope=0.2)\n",
            "  (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (4): Linear(131.33 k, 32.404% Params, 131.33 KMac, 32.342% MACs, in_features=512, out_features=256, bias=True)\n",
            "  (5): BatchNorm1d(512, 0.126% Params, 512.0 Mac, 0.126% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.063% MACs, negative_slope=0.2)\n",
            "  (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (8): Linear(10.28 k, 2.536% Params, 10.28 KMac, 2.532% MACs, in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "FLOPs: 406.06 KMac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Short path FLOPs: {:2f} MMac'.format(263.45+0.40606))"
      ],
      "metadata": {
        "id": "jRModsL7LwxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e9c367-8b08-4aea-aeee-a74858a4fc14"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Short path FLOPs: 263.856060 MMac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flops, params = get_model_complexity_info(model, (3, 1024), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ],
      "metadata": {
        "id": "SyGwqyz0JYiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd0fecc-8938-4080-8205-ac4a6901dce1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm1d ptflops can affect your code!\n",
            "Warning: parameters of some of the modules were counted twice because of multiple links to the same modules. Extended per layer parameters num statistic could be unreliable.\n",
            "eeModel_E1(\n",
            "  2.22 M, 100.139% Params, 1.5 GMac, 84.515% MACs, \n",
            "  (bn1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(256, 0.012% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(512, 0.023% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn5): BatchNorm1d(2.05 k, 0.092% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (baseModelconv1): Sequential(\n",
            "    512, 0.023% Params, 5.9 MMac, 0.333% MACs, \n",
            "    (0): Conv2d(384, 0.017% Params, 3.93 MMac, 0.222% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv2): Sequential(\n",
            "    8.32 k, 0.376% Params, 85.85 MMac, 4.848% MACs, \n",
            "    (0): Conv2d(8.19 k, 0.370% Params, 83.89 MMac, 4.737% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv3): Sequential(\n",
            "    16.64 k, 0.751% Params, 171.7 MMac, 9.696% MACs, \n",
            "    (0): Conv2d(16.38 k, 0.740% Params, 167.77 MMac, 9.474% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, 0.012% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.074% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (shortBranch): Sequential(\n",
            "    405.29 k, 18.299% Params, 406.06 KMac, 0.023% MACs, \n",
            "    (0): Linear(262.14 k, 11.836% Params, 262.14 KMac, 0.015% MACs, in_features=512, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.046% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 5.929% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.023% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.464% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    66.05 k, 2.982% Params, 678.95 MMac, 38.341% MACs, \n",
            "    (0): Conv2d(65.54 k, 2.959% Params, 671.09 MMac, 37.897% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, 0.023% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 2.62 MMac, 0.148% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    526.34 k, 23.764% Params, 540.02 MMac, 30.495% MACs, \n",
            "    (0): Conv1d(524.29 k, 23.671% Params, 536.87 MMac, 30.318% MACs, 512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(2.05 k, 0.092% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.059% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (longBranch_fc): Sequential(\n",
            "    1.19 M, 53.806% Params, 1.19 MMac, 0.067% MACs, \n",
            "    (0): Linear(1.05 M, 47.343% Params, 1.05 MMac, 0.059% MACs, in_features=2048, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.046% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 5.929% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.023% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.464% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            ")\n",
            "FLOPs: 1.77 GMac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the total number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Parameters in the base model\n",
        "baseModelconv1_params = count_parameters(model.baseModelconv1)\n",
        "baseModelconv2_params = count_parameters(model.baseModelconv2)\n",
        "baseModelconv3_params = count_parameters(model.baseModelconv3)\n",
        "\n",
        "# Parameters in the short branch\n",
        "short_path_params = count_parameters(model.shortBranch)\n",
        "\n",
        "print(\"Parameters in Short Path:\", short_path_params+baseModelconv1_params+baseModelconv2_params+baseModelconv3_params)"
      ],
      "metadata": {
        "id": "7K_kBvvytzVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdf416a-97c1-4c4e-e67c-85c5fcea9a1d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters in Short Path: 430760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary(model.shortBranch))\n",
        "print(summary(model.baseModelconv1))\n",
        "print(summary(model.baseModelconv2))\n",
        "print(summary(model.baseModelconv3))"
      ],
      "metadata": {
        "id": "3kCXX2hrwNN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73f234f-5cbf-4e34-fe51-eb1d05aae8fe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Linear: 1-1                            262,144\n",
            "├─BatchNorm1d: 1-2                       1,024\n",
            "├─LeakyReLU: 1-3                         --\n",
            "├─Dropout: 1-4                           --\n",
            "├─Linear: 1-5                            131,328\n",
            "├─BatchNorm1d: 1-6                       512\n",
            "├─LeakyReLU: 1-7                         --\n",
            "├─Dropout: 1-8                           --\n",
            "├─Linear: 1-9                            10,280\n",
            "=================================================================\n",
            "Total params: 405,288\n",
            "Trainable params: 405,288\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            384\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 512\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            8,192\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 8,320\n",
            "Trainable params: 8,320\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            16,384\n",
            "├─BatchNorm2d: 1-2                       256\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 16,640\n",
            "Trainable params: 16,640\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False) # Loading test dataset"
      ],
      "metadata": {
        "id": "x0ln00bI0qZq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_times = []\n",
        "accuracies = []"
      ],
      "metadata": {
        "id": "Z6-w1P3aMzNT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "MxISoQfSjQbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be330827-cdf5-4c9a-8241-5086fb3bf0cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 7.582953 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Got 0% of the samples\n",
            "Branch 2: Accuracy 91.69% with 100.00% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "NhtT-ZIdk70V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4199b423-416b-40a5-b803-642d9b9b9641"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 7.843790 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 0.16% of the samples\n",
            "Branch 2: Accuracy 91.68% with 99.84% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "TQE-rELqk-PF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22dcbcc7-cb8c-4cb5-e9b7-827fbf1c69fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 6.970153 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 1.99% of the samples\n",
            "Branch 2: Accuracy 91.53% with 98.01% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "l0PwWILTk__D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e282e1d3-bb50-4700-f45d-e0108cd4353e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 6.853134 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.55% with 8.95% of the samples\n",
            "Branch 2: Accuracy 90.92% with 91.05% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "SUYayMiwlBpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a75c831-ee6b-4a6d-e62a-b66e31ece44a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 6.470110 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.82% with 22.61% of the samples\n",
            "Branch 2: Accuracy 89.32% with 77.39% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "G_9l0jzxlEND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ba3958-cf8e-45c1-9db9-c3b67ac837ca"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 5.881236 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.48% with 39.18% of the samples\n",
            "Branch 2: Accuracy 86.68% with 60.82% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "TduJVQ9YlF6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ab88b6-4627-449c-8dd4-8daf3eabd277"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 5.040505 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.68% with 61.59% of the samples\n",
            "Branch 2: Accuracy 80.70% with 38.41% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "kd_1UvQOlHhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d48b930-a566-4c6b-c7f6-70ac45f99ac5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 4.655256 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.20% with 72.16% of the samples\n",
            "Branch 2: Accuracy 75.69% with 27.84% of the samples\n",
            "Overall Weighted Accuracy: 91.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "UdMnwqQOlJMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4037c240-2ddb-4bab-f1de-d8243ccf1474"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 4.312475 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 97.25% with 79.70% of the samples\n",
            "Branch 2: Accuracy 72.26% with 20.30% of the samples\n",
            "Overall Weighted Accuracy: 92.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "Ewn8ofWPlKq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd320bf8-2ee5-496f-dd50-2c38b011abd9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 4.213577 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 96.09% with 85.05% of the samples\n",
            "Branch 2: Accuracy 70.73% with 14.95% of the samples\n",
            "Overall Weighted Accuracy: 92.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "iJLXHLaVC7e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31a18b2-6276-4c52-af58-db5d5a7a25e9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.941362 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 95.26% with 89.71% of the samples\n",
            "Branch 2: Accuracy 67.72% with 10.29% of the samples\n",
            "Overall Weighted Accuracy: 92.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "QHDKqmxZlMGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685ff2d6-b107-4790-c041-14778aa14750"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.941296 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 94.67% with 92.75% of the samples\n",
            "Branch 2: Accuracy 65.92% with 7.25% of the samples\n",
            "Overall Weighted Accuracy: 92.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "uM2caHq_lNoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21db1c7-0eeb-46b3-c18a-62cdfb4fd849"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.809446 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 93.90% with 95.62% of the samples\n",
            "Branch 2: Accuracy 62.04% with 4.38% of the samples\n",
            "Overall Weighted Accuracy: 92.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "S--mC_5slPqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d51f464-8584-4fef-d880-2e4e25c2bf80"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.744390 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 92.84% with 97.93% of the samples\n",
            "Branch 2: Accuracy 62.75% with 2.07% of the samples\n",
            "Overall Weighted Accuracy: 92.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "jqQAsnGtlR3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d842189-c761-46d2-9642-60a21e886aaf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.669982 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 92.03% with 99.68% of the samples\n",
            "Branch 2: Accuracy 62.50% with 0.32% of the samples\n",
            "Overall Weighted Accuracy: 91.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "W9UKRbLLlUuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67175230-fb2e-41c3-c441-49d8edb79c41"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.640225 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "xawSuhXHM1rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfc46f4-e634-4790-f471-92ccbaf8010d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.870219 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "-g0IZt8GM7Qc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb88ffc-1a03-422f-e443-6ef46ef77f21"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.768856 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "Fur5evB3M-ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5e43aa-50c9-4b63-a914-34a93aacea7a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.640730 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "5sQ6AJscNBEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7971f9-eb4a-4cf4-dbdd-7c577c75a8c3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.589949 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ],
      "metadata": {
        "id": "p7S0a1mgNDCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9222c2-8668-40c1-b818-d54b2ee2f7c1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 3.666322 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.77% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inference_times)\n",
        "print(accuracies)"
      ],
      "metadata": {
        "id": "cEFfCQeaZayA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46be1fe0-e56d-4a01-8ade-9603ed5f9fc7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.582953214645386, 7.843790292739868, 6.970153331756592, 6.853133678436279, 6.4701104164123535, 5.8812360763549805, 5.0405051708221436, 4.6552557945251465, 4.312475204467773, 4.213576555252075, 3.941361904144287, 3.941296339035034, 3.809446096420288, 3.7443900108337402, 3.669982433319092, 3.6402251720428467, 3.8702189922332764, 3.7688560485839844, 3.640730142593384, 3.589949369430542, 3.6663217544555664]\n",
            "[91.6936790923825, 91.6936790923825, 91.6936790923825, 91.6936790923825, 91.6936790923825, 91.6936790923825, 91.77471636952998, 91.93679092382496, 92.17990275526742, 92.30145867098865, 92.42301458670988, 92.58508914100486, 92.50405186385737, 92.22042139384116, 91.93679092382496, 91.77471636952998, 91.77471636952998, 91.77471636952998, 91.77471636952998, 91.77471636952998, 91.77471636952998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adjustText"
      ],
      "metadata": {
        "id": "G5WzXGEzbu4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7713f6-3dab-4041-d34f-67edd36f07f0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from adjustText import adjust_text\n",
        "entropy = [x/10 for x in range(0, 21)]\n",
        "# Creating the scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(inference_times, accuracies, c='blue')\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(entropy):\n",
        "    text = ax.annotate(str(txt), (inference_times[i], accuracies[i]))\n",
        "    texts.append(text)\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='black'))\n",
        "plt.figure(figsize=(50000, 50000))\n",
        "ax.set_xlabel('Inference Times')\n",
        "ax.set_ylabel('Accuracies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NLwWfowBNJBR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "c21ca2d1-deea-44b5-860a-7a3ee3732856"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 5e+06x5e+06 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}