{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XS_6buTBwPl"
      },
      "source": [
        "### **Import and Install Libraries. Download Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2WB_AlhDx9_",
        "outputId": "ba5980e0-b48b-4c18-fd1c-2033c0dd0597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rZLVYrPJeOk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "from scipy.stats import entropy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "import sklearn.metrics as metrics\n",
        "import copy\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UH_X_YHfYkK",
        "outputId": "93dc7b6c-b268-4731-aaeb-8deacb595e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-26 10:52:30--  https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435212151 (415M) [application/zip]\n",
            "Saving to: ‘modelnet40_ply_hdf5_2048.zip’\n",
            "\n",
            "modelnet40_ply_hdf5 100%[===================>] 415.05M  13.0MB/s    in 35s     \n",
            "\n",
            "2024-04-26 10:53:06 (11.8 MB/s) - ‘modelnet40_ply_hdf5_2048.zip’ saved [435212151/435212151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
        "!unzip -q modelnet40_ply_hdf5_2048.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ekUukrU6v2Kz"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore specific warnings related to multiprocessing and os.fork\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\".*os.fork.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fTRjk6Lp_cJW"
      },
      "outputs": [],
      "source": [
        "#Class for your arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.exp_name = 'exp'\n",
        "        self.model = 'dgcnn'\n",
        "        self.dataset = 'modelnet40'\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 16\n",
        "        self.epochs = 250\n",
        "        self.use_sgd = True\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.9\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.eval = False\n",
        "        self.num_points = 1024\n",
        "        self.dropout = 0.5\n",
        "        self.emb_dims = 1024\n",
        "        self.k = 10\n",
        "        self.model_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ERQ6I6HnfprZ"
      },
      "outputs": [],
      "source": [
        "#Method to retrieve your training and testing files\n",
        "def getDataFiles(list_filename):\n",
        "    print(list_filename)\n",
        "    return [line.rstrip() for line in open(list_filename)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8yn70xofrpU",
        "outputId": "9eddae00-a8d8-46d7-e735-4713ca955206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/modelnet40_ply_hdf5_2048/train_files.txt\n",
            "data/modelnet40_ply_hdf5_2048/test_files.txt\n"
          ]
        }
      ],
      "source": [
        "#Store your dataset in the folder 'data'\n",
        "import shutil\n",
        "os.mkdir('data')\n",
        "shutil.move('modelnet40_ply_hdf5_2048', 'data')\n",
        "TRAIN_FILES = getDataFiles( \\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/train_files.txt'))\n",
        "TEST_FILES = getDataFiles(\\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/test_files.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3sIrLnpFg5Gk"
      },
      "outputs": [],
      "source": [
        "def cal_loss(pred, gold, smoothing=True):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.2\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "    else:\n",
        "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7Te875Og7xc"
      },
      "outputs": [],
      "source": [
        "class IOStream():\n",
        "    \"\"\"\n",
        "    A utility class for outputting text to both console and a file. This class provides a method to concurrently print\n",
        "    information to the console and append it to a file. This can be particularly useful for logging purposes in\n",
        "    applications like long-running processes where monitoring and retaining output history is necessary.\n",
        "\n",
        "    Attributes:\n",
        "    f (file object): File object used to append text to the specified file.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initialize the IOStream by opening or creating a file for appending text.\n",
        "\n",
        "        Parameters:\n",
        "        path (str): The file path where text will be appended. If the file does not exist, it will be created.\n",
        "        \"\"\"\n",
        "        self.f = open(path, 'a')  # Open the file in append mode.\n",
        "\n",
        "    def cprint(self, text):\n",
        "        \"\"\"\n",
        "        Prints text to the console and appends it to the file initialized in this class instance.\n",
        "\n",
        "        Parameters:\n",
        "        text (str): The text to be printed and logged.\n",
        "        \"\"\"\n",
        "        print(text)  # Print text to console.\n",
        "        self.f.write(text + '\\n')  # Append text to file and add a newline.\n",
        "        self.f.flush()  # Flush the internal buffer, ensuring all file operations are completed immediately.\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Closes the file associated with this instance. It is important to call this method to free up system resources.\n",
        "        \"\"\"\n",
        "        self.f.close()  # Close the file to release resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH-3GRMgB4eu"
      },
      "source": [
        "### **Calculate 10 k-nearest neighbors based on the Euclidean distance $(x_1-x_2)^2$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jJz0UTK3h2pV"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    # print(idx[1,:,1].size, 'idx of knn')\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "soeA9B4Nh3cr"
      },
      "outputs": [],
      "source": [
        "def get_graph_feature(x, k=10, idx=None):\n",
        "    # print(x.shape, 'Input x to get_graph_feature')\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "    # print(idx)\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "    # print(idx[1,1,:], 'idx of get_graph_feature')\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36SyVuaCKTb"
      },
      "source": [
        "### **DGCNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JU0hruirh9Xt"
      },
      "outputs": [],
      "source": [
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=args.dropout)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=args.dropout)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j48wtIIvVID2"
      },
      "source": [
        "### **DGCNN EE0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZhsO2Y5HjpKN"
      },
      "outputs": [],
      "source": [
        "class eeModel_EE0(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(eeModel_EE0, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        ################################Base Model###################################\n",
        "        self.baseModelconv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                       self.bn1,\n",
        "                                       nn.LeakyReLU(negative_slope=0.2))\n",
        "        #############################################################################\n",
        "\n",
        "        #############################Short Branch####################################\n",
        "        self.shortBranch = nn.Sequential(nn.Linear(128, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ################################################################################\n",
        "\n",
        "        ####################################Long Branch#################################\n",
        "        self.longBranchboolean = True\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.longBranch = nn.Sequential(nn.Linear(args.emb_dims*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ####################################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x_baseModelconv1 = self.baseModelconv1(get_graph_feature(x, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_shortBranch, x_longBranch = self.get_short_branch_output(x_baseModelconv1, batch_size), self.get_long_branch_output(x_baseModelconv1, batch_size)\n",
        "        return x_shortBranch, x_longBranch\n",
        "\n",
        "    def get_short_branch_output(self, x_baseModel, batch_size):\n",
        "        x_shortBranch = self.shortBranch(torch.cat((F.adaptive_max_pool1d(x_baseModel, 1).view(batch_size, -1),\n",
        "                                                    F.adaptive_avg_pool1d(x_baseModel, 1).view(batch_size, -1)), 1))\n",
        "        return x_shortBranch\n",
        "\n",
        "    def get_long_branch_output(self, x_baseModelconv1, batch_size):\n",
        "        x2_longBranch = self.conv2(get_graph_feature(x_baseModelconv1, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x3_longBranch = self.conv3(get_graph_feature(x2_longBranch, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x4_longBranch = self.conv4(get_graph_feature(x3_longBranch, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_longBranch = self.conv5(torch.cat((x_baseModelconv1, x2_longBranch, x3_longBranch, x4_longBranch), dim=1))\n",
        "        x_longBranch = torch.cat((F.adaptive_max_pool1d(x_longBranch, 1).view(batch_size, -1),\n",
        "                                  F.adaptive_avg_pool1d(x_longBranch, 1).view(batch_size, -1)), 1)\n",
        "        x_longBranch = self.longBranch(x_longBranch)\n",
        "        return x_longBranch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4AgLkE_7e1NL"
      },
      "outputs": [],
      "source": [
        "def load_data(partition):\n",
        "    \"\"\"\n",
        "    Load pointcloud data and labels from HDF5 files based on the specified partition (train or test).\n",
        "    This function is designed to work within a filesystem structure expected for ModelNet40 dataset files,\n",
        "    aggregating data from multiple files into a single array for both data points and labels.\n",
        "\n",
        "    Parameters:\n",
        "    partition (str): Specifies which dataset partition to load. Expected values are 'train' or 'test'.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy arrays: one for the data (pointclouds) and one for the labels.\n",
        "    \"\"\"\n",
        "    # Define base directory relative to this script's location.\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(r'\\data\\modelnet40_ply_hdf5_2048'))\n",
        "    # Define data directory path combining base directory with the data subdirectory.\n",
        "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "\n",
        "    # Initialize lists to hold data and labels from all files.\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "\n",
        "    # Loop over each file matching the pattern for the specified partition.\n",
        "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', f'ply_data_{partition}*.h5')):\n",
        "        # Open the HDF5 file for reading.\n",
        "        f = h5py.File(h5_name)\n",
        "        # Load all data points as float32 and labels as int64 from the file.\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        # Ensure the file is closed after its contents are loaded.\n",
        "        f.close()\n",
        "\n",
        "        # Append the data and labels to their respective lists.\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "\n",
        "    # Concatenate all data and labels from the list into single numpy arrays.\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "\n",
        "    # Return the aggregated data and labels.\n",
        "    return all_data, all_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b4AH8w7Ke6Nt"
      },
      "outputs": [],
      "source": [
        "def translate_pointcloud(pointcloud):\n",
        "    \"\"\"\n",
        "    Apply a random translation to a pointcloud. This is done by first scaling the pointcloud with a random factor\n",
        "    and then adding a small random shift. This can be used as a data augmentation technique to make models robust\n",
        "    to variations in object position and scale.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, 3) where N is the number of points.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The translated pointcloud as a new numpy array of type 'float32'.\n",
        "    \"\"\"\n",
        "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])  # Random scaling factors.\n",
        "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])    # Random translation offsets.\n",
        "\n",
        "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')  # Apply scaling and translation\n",
        "    return translated_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nB31Q97vf4bN"
      },
      "outputs": [],
      "source": [
        "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):\n",
        "    \"\"\"\n",
        "    Apply Gaussian noise to a pointcloud. Each point's position is altered by adding a noise vector drawn from a\n",
        "    Gaussian distribution, clipped to a maximum magnitude to prevent excessive perturbation. This augmentation\n",
        "    promotes robustness to small variations or noise.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, C) where N is the number of points and C is the number of coordinates.\n",
        "    sigma (float): Standard deviation of the Gaussian noise.\n",
        "    clip (float): Maximum allowed value for noise applied to the point coordinates.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The jittered pointcloud.\n",
        "    \"\"\"\n",
        "    N, C = pointcloud.shape  # Number of points N and dimensions C in the pointcloud.\n",
        "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)  # Add clipped Gaussian noise.\n",
        "    return pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rGxrJjODf7iU"
      },
      "outputs": [],
      "source": [
        "class ModelNet40(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for ModelNet40, which includes methods for loading and preprocessing pointcloud data for training or testing.\n",
        "    Data augmentation (translation and shuffling) is applied to training data to improve model generalization.\n",
        "\n",
        "    Attributes:\n",
        "    num_points (int): Number of points per pointcloud to use.\n",
        "    partition (str): Dataset partition to use, either 'train' or 'test'.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points, partition='train'):\n",
        "        \"\"\"\n",
        "        Initialize the dataset object, loading data and labels according to the specified partition.\n",
        "\n",
        "        Parameters:\n",
        "        num_points (int): Number of points to sample from each pointcloud.\n",
        "        partition (str): Which dataset partition to use, 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        self.data, self.label = load_data(partition)  # Load dataset.\n",
        "        self.num_points = num_points  # Points per pointcloud.\n",
        "        self.partition = partition  # Dataset partition.\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Retrieve a pointcloud and its label, applying data augmentation if in training mode.\n",
        "\n",
        "        Parameters:\n",
        "        item (int): Index of the pointcloud to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Tuple containing the pointcloud and its label.\n",
        "        \"\"\"\n",
        "        pointcloud = self.data[item][:self.num_points]  # Get the subset of points.\n",
        "        label = self.label[item]\n",
        "        if self.partition == 'train':  # Conditionally apply augmentations.\n",
        "            pointcloud = translate_pointcloud(pointcloud)\n",
        "            np.random.shuffle(pointcloud)  # Shuffle points to remove any order bias.\n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of pointclouds in the dataset.\n",
        "\n",
        "        Returns:\n",
        "        int: The number of pointclouds.\n",
        "        \"\"\"\n",
        "        return self.data.shape[0]  # Number of pointclouds in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eaxTC3jlNufT"
      },
      "outputs": [],
      "source": [
        "# Dictionary for ModelNet40 classes. Helpful when printing confusion matrix. Note that ModelNet40 sorts its classes alphabetically\n",
        "label_dict = {\n",
        "    'airplane': 0,\n",
        "    'bathtub': 1,\n",
        "    'bed': 2,\n",
        "    'bench': 3,\n",
        "    'bookshelf': 4,\n",
        "    'bottle': 5,\n",
        "    'bowl': 6,\n",
        "    'car': 7,\n",
        "    'chair': 8,\n",
        "    'cone': 9,\n",
        "    'cup': 10,\n",
        "    'curtain': 11,\n",
        "    'desk': 12,\n",
        "    'door': 13,\n",
        "    'dresser': 14,\n",
        "    'flower_pot': 15,\n",
        "    'glass_box': 16,\n",
        "    'guitar': 17,\n",
        "    'keyboard': 18,\n",
        "    'lamp': 19,\n",
        "    'laptop': 20,\n",
        "    'mantel': 21,\n",
        "    'monitor': 22,\n",
        "    'night_stand': 23,\n",
        "    'person': 24,\n",
        "    'piano': 25,\n",
        "    'plant': 26,\n",
        "    'radio': 27,\n",
        "    'range_hood': 28,\n",
        "    'sink': 29,\n",
        "    'sofa': 30,\n",
        "    'stairs': 31,\n",
        "    'stool': 32,\n",
        "    'table': 33,\n",
        "    'tent': 34,\n",
        "    'toilet': 35,\n",
        "    'tv_stand': 36,\n",
        "    'vase': 37,\n",
        "    'wardrobe': 38,\n",
        "    'xbox': 39\n",
        "}\n",
        "modes = list(label_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMOAvhfCU2r"
      },
      "source": [
        "### **Training and Testing algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gYGrRCMWgBGG"
      },
      "outputs": [],
      "source": [
        "def train(args, io):\n",
        "    # 1. Determine the size of the original training dataset\n",
        "    total_train_samples = len(ModelNet40(partition='train', num_points=args.num_points))\n",
        "    train_size = int(0.75 * total_train_samples)  # 60% of the original training dataset\n",
        "    validation_size = total_train_samples - train_size  # Remaining samples for validation\n",
        "\n",
        "    # 2. Split the original training dataset\n",
        "    train_dataset, validation_dataset = random_split(ModelNet40(partition='train', num_points=args.num_points), [train_size, validation_size])\n",
        "\n",
        "    # 3. Create DataLoader for the training and validation datasets\n",
        "    train_loader = DataLoader(train_dataset, num_workers=2, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    validation_loader = DataLoader(validation_dataset, num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    # Test DataLoader remains unchanged\n",
        "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "    history = {\"1\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"2\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"T\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}}}\n",
        "    loss1_list = []\n",
        "    loss2_list = []\n",
        "    acc1_list = []\n",
        "    acc2_list = []\n",
        "    eStopThreshold, eStopCounter = 8, 0\n",
        "    device = \"cuda\" # Set up your NVIDIA GPU.\n",
        "    model = eeModel_EE0(args).to(device) #Initialize your model.\n",
        "    print(summary(model))## Print your model summary.\n",
        "    print(\"Let's use\", torch.cpu.device_count(), \"GPUs!\") ## Print how many GPUs are being used.\n",
        "\n",
        "    #Set up your optimizer and loss\n",
        "    if args.use_sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        loss1Total, loss2Total, totalLoss = 0, 0, 0\n",
        "        acc1Total, acc2Total, totalAcc = 0, 0, 0\n",
        "        loss1Total_v, loss2Total_v, valLoss = 0, 0, 0\n",
        "        acc1Total_v, acc2Total_v, valAcc = 0, 0, 0\n",
        "        train_loss = 0.0\n",
        "        loss = 0\n",
        "        bestAcc = 0\n",
        "        best_loss = 100\n",
        "        preValLoss = 100\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data, label in train_loader:\n",
        "            data, label = data.to(device), label.to(device).squeeze() # Send your input data and label to device e.g. GPU\n",
        "            data = data.permute(0, 2, 1) # Permute your data for subsequent operations\n",
        "            batch_size = data.size()[0] # Retrieve your batch size\n",
        "            opt.zero_grad() # Zero your optimizer\n",
        "            logits1, logits2 = model(data) # Compute unnormalized model outputs e.g. short branch and long branch outputs\n",
        "            loss1, loss2 = criterion(logits1, label), criterion(logits2, label) # Calculate your losses e.g. short branch and long branch losses\n",
        "            loss1_list.append(loss1.item()) # Append your short branch losses\n",
        "            loss2_list.append(loss2.item()) # Append your long branch losses\n",
        "            loss1Total += loss1.item() # Aggregate your short branch losses\n",
        "            loss2Total += loss2.item() # Aggregate your long branch losses\n",
        "            totalLoss += 0.5*loss1.item() + 0.5*loss2.item() # Average your loss\n",
        "            loss1.backward(retain_graph=True) # Backward propagate your short branch loss\n",
        "            loss2.backward(retain_graph=True) # Backward propagate your long branch loss\n",
        "            _, predicted1 = torch.max(logits1, 1) # Max pool your short branch predicitions\n",
        "            _, predicted2 = torch.max(logits2, 1) # Max pool your long branch predicitions\n",
        "            acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy()) # Calculate your short branch accuracy\n",
        "            acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy()) # Calculate your long branch accurac\n",
        "            acc1_list.append(acc1) # Append your short branch accuracies\n",
        "            acc2_list.append(acc2) # Append your long branch accuracies\n",
        "            acc1Total += acc1 # Aggregate your short branch accuracies\n",
        "            acc2Total += acc2 # Aggregate your long branch accuracies\n",
        "            totalAcc += 0.5*acc1+0.5*acc2 # Average your accuracy\n",
        "            opt.step() # Step your optimizer\n",
        "            count += batch_size # Recursively add number of prediciton counts\n",
        "        loss1Total = loss1Total/len(train_loader) # Normalize your short branch losses\n",
        "        loss2Total = loss2Total/len(train_loader) # Normalize your long branch losses\n",
        "        totalLoss = totalLoss/len(train_loader) # Normalize your total loss\n",
        "        acc1Total = acc1Total/len(train_loader) # Normalize your short branch accuracy\n",
        "        acc2Total = acc2Total/len(train_loader) # Normalize your long branch accuracy\n",
        "        totalAcc = totalAcc/len(train_loader) # Normalize your total accuracy\n",
        "        ############## Append to your history dictionaty################\n",
        "        history[\"1\"][\"train\"][\"loss\"].append(loss1Total)\n",
        "        history[\"1\"][\"train\"][\"accuracy\"].append(acc1Total)\n",
        "        history[\"2\"][\"train\"][\"loss\"].append(loss2Total)\n",
        "        history[\"2\"][\"train\"][\"accuracy\"].append(acc2Total)\n",
        "        history[\"T\"][\"train\"][\"loss\"].append(totalLoss)\n",
        "        history[\"T\"][\"train\"][\"accuracy\"].append(totalAcc)\n",
        "        ###############################################################\n",
        "        print(\"epoch {} --> trainLoss: {:0.3f}, trainAcc: {:0.3f}\" # Print your epoch, total normalized loss, total normalized accuracy.\n",
        "                  .format(epoch+1, totalLoss, totalAcc), end=\"\")\n",
        "\n",
        "        ####################### Validation is identical training####################\n",
        "        if validation_loader:\n",
        "          with torch.no_grad():\n",
        "            model.eval() # Set up your model for evaluation\n",
        "            for data, label in validation_loader:\n",
        "              data, label = data.to(device), label.to(device).squeeze()\n",
        "              data = data.permute(0, 2, 1)\n",
        "              batch_size = data.size()[0]\n",
        "              opt.zero_grad()\n",
        "              logits1, logits2 = model(data) ## ADD TWO LOGITS\n",
        "\n",
        "              loss1, loss2 = criterion(logits1, label.long()), criterion(logits2, label.long())\n",
        "              loss1Total_v += loss1.item()\n",
        "              loss2Total_v += loss2.item()\n",
        "              valLoss += 0.5*loss1.item() + 0.5*loss2.item()\n",
        "\n",
        "              _, predicted1 = torch.max(logits1, 1)\n",
        "              _, predicted2 = torch.max(logits2, 1)\n",
        "              acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy())\n",
        "              acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy())\n",
        "\n",
        "              acc1Total_v += acc1\n",
        "              acc2Total_v += acc2\n",
        "              valAcc += 0.5*acc1 + 0.5*acc2\n",
        "\n",
        "            loss1Total_v = loss1Total_v/len(validation_loader)\n",
        "            loss2Total_v = loss2Total_v/len(validation_loader)\n",
        "            valLoss = valLoss/len(validation_loader)\n",
        "            acc1Total_v = acc1Total_v/len(validation_loader)\n",
        "            acc2Total_v = acc2Total_v/len(validation_loader)\n",
        "            valAcc = valAcc/len(validation_loader)\n",
        "\n",
        "            history[\"1\"][\"validation\"][\"loss\"].append(loss1Total_v)\n",
        "            history[\"1\"][\"validation\"][\"accuracy\"].append(acc1Total_v)\n",
        "            history[\"2\"][\"validation\"][\"loss\"].append(loss2Total_v)\n",
        "            history[\"2\"][\"validation\"][\"accuracy\"].append(acc2Total_v)\n",
        "            history[\"T\"][\"validation\"][\"loss\"].append(valLoss)\n",
        "            history[\"T\"][\"validation\"][\"accuracy\"].append(valAcc)\n",
        "\n",
        "          print(\", validLoss: {:0.3f}, validAcc: {:0.3f}\"\n",
        "                  .format(valLoss, valAcc))\n",
        "#############Save best performing model if current test accuracy outperforms the recorded best accuracy#############\n",
        "          if valLoss <= best_loss:\n",
        "            # Save the model with the lowest validation loss.\n",
        "            best_loss = valLoss\n",
        "            torch.save(model.state_dict(), 'checkpoints/%s/models/model.pth' % args.exp_name)\n",
        "            print(\"Model Saved!\")\n",
        "#####################################################################################################################\n",
        "\n",
        "########################Stop training if validation loss is increasing#############################\n",
        "          if valLoss >= preValLoss:\n",
        "            eStopCounter += 1\n",
        "            if eStopCounter >= eStopThreshold:\n",
        "              print(\"Training Stopped!\")\n",
        "              break;\n",
        "          else:\n",
        "            eStopCounter = 0\n",
        "          preValLoss = valLoss\n",
        "        else:\n",
        "          print(\"\")\n",
        "#####################################################################################################\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oy1DG9OAlwYg"
      },
      "outputs": [],
      "source": [
        "train_demo = ModelNet40(1024)\n",
        "test_demo = ModelNet40(1024, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1wNYf788EJk2"
      },
      "outputs": [],
      "source": [
        "#Initialize your hyperparametr arguments\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N05X14SdBmwb",
        "outputId": "d5dc90d7-f92a-4836-aedc-31936fa93b27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if not os.path.exists('checkpoints'):\n",
        "  os.makedirs('checkpoints')\n",
        "if not os.path.exists('checkpoints/'+args.exp_name):\n",
        "  os.makedirs('checkpoints/'+args.exp_name)\n",
        "if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):\n",
        "  os.makedirs('checkpoints/'+args.exp_name+'/'+'models')\n",
        "os.system('cp main.py checkpoints'+'/'+args.exp_name+'/'+'main.py.backup')\n",
        "os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
        "os.system('cp util.py checkpoints' + '/' + args.exp_name + '/' + 'util.py.backup')\n",
        "os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jKeuCJWJ_Mr9"
      },
      "outputs": [],
      "source": [
        "io = IOStream('checkpoints/' + args.exp_name + '/run.log')\n",
        "args.no_cuda = False\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpAkmrEq0-y",
        "outputId": "1628f14f-6249-4b6f-8154-0d5875a8f0f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "eeModel_E0                               --\n",
            "├─BatchNorm2d: 1-1                       128\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─BatchNorm2d: 1-3                       256\n",
            "├─BatchNorm2d: 1-4                       512\n",
            "├─BatchNorm1d: 1-5                       2,048\n",
            "├─Sequential: 1-6                        128\n",
            "│    └─Conv2d: 2-1                       384\n",
            "│    └─BatchNorm2d: 2-2                  (recursive)\n",
            "│    └─LeakyReLU: 2-3                    --\n",
            "├─Sequential: 1-7                        --\n",
            "│    └─Linear: 2-4                       65,536\n",
            "│    └─BatchNorm1d: 2-5                  1,024\n",
            "│    └─LeakyReLU: 2-6                    --\n",
            "│    └─Dropout: 2-7                      --\n",
            "│    └─Linear: 2-8                       131,328\n",
            "│    └─BatchNorm1d: 2-9                  512\n",
            "│    └─LeakyReLU: 2-10                   --\n",
            "│    └─Dropout: 2-11                     --\n",
            "│    └─Linear: 2-12                      10,280\n",
            "├─Sequential: 1-8                        128\n",
            "│    └─Conv2d: 2-13                      8,192\n",
            "│    └─BatchNorm2d: 2-14                 (recursive)\n",
            "│    └─LeakyReLU: 2-15                   --\n",
            "├─Sequential: 1-9                        256\n",
            "│    └─Conv2d: 2-16                      16,384\n",
            "│    └─BatchNorm2d: 2-17                 (recursive)\n",
            "│    └─LeakyReLU: 2-18                   --\n",
            "├─Sequential: 1-10                       512\n",
            "│    └─Conv2d: 2-19                      65,536\n",
            "│    └─BatchNorm2d: 2-20                 (recursive)\n",
            "│    └─LeakyReLU: 2-21                   --\n",
            "├─Sequential: 1-11                       2,048\n",
            "│    └─Conv1d: 2-22                      524,288\n",
            "│    └─BatchNorm1d: 2-23                 (recursive)\n",
            "│    └─LeakyReLU: 2-24                   --\n",
            "├─Sequential: 1-12                       --\n",
            "│    └─Linear: 2-25                      1,048,576\n",
            "│    └─BatchNorm1d: 2-26                 1,024\n",
            "│    └─LeakyReLU: 2-27                   --\n",
            "│    └─Dropout: 2-28                     --\n",
            "│    └─Linear: 2-29                      131,328\n",
            "│    └─BatchNorm1d: 2-30                 512\n",
            "│    └─LeakyReLU: 2-31                   --\n",
            "│    └─Dropout: 2-32                     --\n",
            "│    └─Linear: 2-33                      10,280\n",
            "=================================================================\n",
            "Total params: 2,021,328\n",
            "Trainable params: 2,021,328\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 --> trainLoss: 2.946, trainAcc: 0.384, validLoss: 2.459, validAcc: 0.512\n",
            "Model Saved!\n",
            "epoch 2 --> trainLoss: 2.423, trainAcc: 0.540, validLoss: 2.272, validAcc: 0.617\n",
            "Model Saved!\n",
            "epoch 3 --> trainLoss: 2.293, trainAcc: 0.598, validLoss: 2.166, validAcc: 0.635\n",
            "Model Saved!\n",
            "epoch 4 --> trainLoss: 2.213, trainAcc: 0.632, validLoss: 2.123, validAcc: 0.665\n",
            "Model Saved!\n",
            "epoch 5 --> trainLoss: 2.162, trainAcc: 0.650, validLoss: 2.099, validAcc: 0.682\n",
            "Model Saved!\n",
            "epoch 6 --> trainLoss: 2.114, trainAcc: 0.672, validLoss: 2.032, validAcc: 0.700\n",
            "Model Saved!\n",
            "epoch 7 --> trainLoss: 2.088, trainAcc: 0.686, validLoss: 2.005, validAcc: 0.713\n",
            "Model Saved!\n",
            "epoch 8 --> trainLoss: 2.060, trainAcc: 0.702, validLoss: 1.972, validAcc: 0.719\n",
            "Model Saved!\n",
            "epoch 9 --> trainLoss: 2.029, trainAcc: 0.715, validLoss: 1.943, validAcc: 0.733\n",
            "Model Saved!\n",
            "epoch 10 --> trainLoss: 2.015, trainAcc: 0.719, validLoss: 1.907, validAcc: 0.767\n",
            "Model Saved!\n",
            "epoch 11 --> trainLoss: 1.996, trainAcc: 0.725, validLoss: 1.878, validAcc: 0.770\n",
            "Model Saved!\n",
            "epoch 12 --> trainLoss: 1.982, trainAcc: 0.731, validLoss: 1.929, validAcc: 0.740\n",
            "Model Saved!\n",
            "epoch 13 --> trainLoss: 1.971, trainAcc: 0.734, validLoss: 1.886, validAcc: 0.759\n",
            "Model Saved!\n",
            "epoch 14 --> trainLoss: 1.962, trainAcc: 0.738, validLoss: 1.881, validAcc: 0.756\n",
            "Model Saved!\n",
            "epoch 15 --> trainLoss: 1.941, trainAcc: 0.746, validLoss: 1.845, validAcc: 0.778\n",
            "Model Saved!\n",
            "epoch 16 --> trainLoss: 1.932, trainAcc: 0.752, validLoss: 1.841, validAcc: 0.775\n",
            "Model Saved!\n",
            "epoch 17 --> trainLoss: 1.927, trainAcc: 0.756, validLoss: 1.847, validAcc: 0.771\n",
            "Model Saved!\n",
            "epoch 18 --> trainLoss: 1.921, trainAcc: 0.757, validLoss: 1.916, validAcc: 0.746\n",
            "Model Saved!\n",
            "epoch 19 --> trainLoss: 1.916, trainAcc: 0.756, validLoss: 1.825, validAcc: 0.775\n",
            "Model Saved!\n",
            "epoch 20 --> trainLoss: 1.913, trainAcc: 0.758, validLoss: 1.844, validAcc: 0.780\n",
            "Model Saved!\n",
            "epoch 21 --> trainLoss: 1.895, trainAcc: 0.771, validLoss: 1.859, validAcc: 0.777\n",
            "Model Saved!\n",
            "epoch 22 --> trainLoss: 1.890, trainAcc: 0.769, validLoss: 1.835, validAcc: 0.774\n",
            "Model Saved!\n",
            "epoch 23 --> trainLoss: 1.887, trainAcc: 0.770, validLoss: 1.827, validAcc: 0.778\n",
            "Model Saved!\n",
            "epoch 24 --> trainLoss: 1.886, trainAcc: 0.772, validLoss: 1.831, validAcc: 0.785\n",
            "Model Saved!\n",
            "epoch 25 --> trainLoss: 1.872, trainAcc: 0.777, validLoss: 1.785, validAcc: 0.799\n",
            "Model Saved!\n",
            "epoch 26 --> trainLoss: 1.867, trainAcc: 0.779, validLoss: 1.831, validAcc: 0.787\n",
            "Model Saved!\n",
            "epoch 27 --> trainLoss: 1.868, trainAcc: 0.778, validLoss: 1.862, validAcc: 0.766\n",
            "Model Saved!\n",
            "epoch 28 --> trainLoss: 1.875, trainAcc: 0.774, validLoss: 1.867, validAcc: 0.770\n",
            "Model Saved!\n",
            "epoch 29 --> trainLoss: 1.860, trainAcc: 0.782, validLoss: 1.782, validAcc: 0.800\n",
            "Model Saved!\n",
            "epoch 30 --> trainLoss: 1.858, trainAcc: 0.784, validLoss: 1.796, validAcc: 0.803\n",
            "Model Saved!\n",
            "epoch 31 --> trainLoss: 1.850, trainAcc: 0.786, validLoss: 1.821, validAcc: 0.789\n",
            "Model Saved!\n",
            "epoch 32 --> trainLoss: 1.844, trainAcc: 0.791, validLoss: 1.868, validAcc: 0.766\n",
            "Model Saved!\n",
            "epoch 33 --> trainLoss: 1.845, trainAcc: 0.785, validLoss: 1.804, validAcc: 0.789\n",
            "Model Saved!\n",
            "epoch 34 --> trainLoss: 1.844, trainAcc: 0.792, validLoss: 1.788, validAcc: 0.789\n",
            "Model Saved!\n",
            "epoch 35 --> trainLoss: 1.830, trainAcc: 0.794, validLoss: 1.825, validAcc: 0.787\n",
            "Model Saved!\n",
            "epoch 36 --> trainLoss: 1.838, trainAcc: 0.794, validLoss: 1.853, validAcc: 0.773\n",
            "Model Saved!\n",
            "epoch 37 --> trainLoss: 1.834, trainAcc: 0.792, validLoss: 1.803, validAcc: 0.793\n",
            "Model Saved!\n",
            "epoch 38 --> trainLoss: 1.829, trainAcc: 0.796, validLoss: 1.776, validAcc: 0.803\n",
            "Model Saved!\n",
            "epoch 39 --> trainLoss: 1.828, trainAcc: 0.796, validLoss: 1.790, validAcc: 0.793\n",
            "Model Saved!\n",
            "epoch 40 --> trainLoss: 1.832, trainAcc: 0.794, validLoss: 1.802, validAcc: 0.794\n",
            "Model Saved!\n",
            "epoch 41 --> trainLoss: 1.817, trainAcc: 0.803, validLoss: 1.788, validAcc: 0.800\n",
            "Model Saved!\n",
            "epoch 42 --> trainLoss: 1.813, trainAcc: 0.801, validLoss: 1.882, validAcc: 0.757\n",
            "Model Saved!\n",
            "epoch 43 --> trainLoss: 1.826, trainAcc: 0.797, validLoss: 1.802, validAcc: 0.780\n",
            "Model Saved!\n",
            "epoch 44 --> trainLoss: 1.817, trainAcc: 0.801, validLoss: 1.772, validAcc: 0.800\n",
            "Model Saved!\n",
            "epoch 45 --> trainLoss: 1.812, trainAcc: 0.801, validLoss: 1.789, validAcc: 0.797\n",
            "Model Saved!\n",
            "epoch 46 --> trainLoss: 1.814, trainAcc: 0.802, validLoss: 1.770, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 47 --> trainLoss: 1.806, trainAcc: 0.805, validLoss: 1.775, validAcc: 0.808\n",
            "Model Saved!\n",
            "epoch 48 --> trainLoss: 1.802, trainAcc: 0.805, validLoss: 1.787, validAcc: 0.803\n",
            "Model Saved!\n",
            "epoch 49 --> trainLoss: 1.799, trainAcc: 0.808, validLoss: 1.776, validAcc: 0.792\n",
            "Model Saved!\n",
            "epoch 50 --> trainLoss: 1.805, trainAcc: 0.805, validLoss: 1.751, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 51 --> trainLoss: 1.790, trainAcc: 0.812, validLoss: 1.774, validAcc: 0.787\n",
            "Model Saved!\n",
            "epoch 52 --> trainLoss: 1.787, trainAcc: 0.813, validLoss: 1.754, validAcc: 0.811\n",
            "Model Saved!\n",
            "epoch 53 --> trainLoss: 1.800, trainAcc: 0.806, validLoss: 1.853, validAcc: 0.772\n",
            "Model Saved!\n",
            "epoch 54 --> trainLoss: 1.797, trainAcc: 0.809, validLoss: 1.798, validAcc: 0.791\n",
            "Model Saved!\n",
            "epoch 55 --> trainLoss: 1.798, trainAcc: 0.806, validLoss: 1.750, validAcc: 0.817\n",
            "Model Saved!\n",
            "epoch 56 --> trainLoss: 1.788, trainAcc: 0.814, validLoss: 1.805, validAcc: 0.789\n",
            "Model Saved!\n",
            "epoch 57 --> trainLoss: 1.787, trainAcc: 0.814, validLoss: 1.739, validAcc: 0.818\n",
            "Model Saved!\n",
            "epoch 58 --> trainLoss: 1.782, trainAcc: 0.816, validLoss: 1.820, validAcc: 0.784\n",
            "Model Saved!\n",
            "epoch 59 --> trainLoss: 1.769, trainAcc: 0.820, validLoss: 1.752, validAcc: 0.808\n",
            "Model Saved!\n",
            "epoch 60 --> trainLoss: 1.779, trainAcc: 0.815, validLoss: 1.768, validAcc: 0.796\n",
            "Model Saved!\n",
            "epoch 61 --> trainLoss: 1.784, trainAcc: 0.816, validLoss: 1.734, validAcc: 0.823\n",
            "Model Saved!\n",
            "epoch 62 --> trainLoss: 1.775, trainAcc: 0.821, validLoss: 1.740, validAcc: 0.812\n",
            "Model Saved!\n",
            "epoch 63 --> trainLoss: 1.776, trainAcc: 0.818, validLoss: 1.760, validAcc: 0.808\n",
            "Model Saved!\n",
            "epoch 64 --> trainLoss: 1.781, trainAcc: 0.813, validLoss: 1.755, validAcc: 0.813\n",
            "Model Saved!\n",
            "epoch 65 --> trainLoss: 1.770, trainAcc: 0.821, validLoss: 1.803, validAcc: 0.779\n",
            "Model Saved!\n",
            "epoch 66 --> trainLoss: 1.772, trainAcc: 0.820, validLoss: 1.722, validAcc: 0.823\n",
            "Model Saved!\n",
            "epoch 67 --> trainLoss: 1.761, trainAcc: 0.825, validLoss: 1.770, validAcc: 0.805\n",
            "Model Saved!\n",
            "epoch 68 --> trainLoss: 1.763, trainAcc: 0.824, validLoss: 1.761, validAcc: 0.817\n",
            "Model Saved!\n",
            "epoch 69 --> trainLoss: 1.761, trainAcc: 0.824, validLoss: 1.786, validAcc: 0.797\n",
            "Model Saved!\n",
            "epoch 70 --> trainLoss: 1.766, trainAcc: 0.823, validLoss: 1.784, validAcc: 0.799\n",
            "Model Saved!\n",
            "epoch 71 --> trainLoss: 1.754, trainAcc: 0.829, validLoss: 1.721, validAcc: 0.827\n",
            "Model Saved!\n",
            "epoch 72 --> trainLoss: 1.750, trainAcc: 0.830, validLoss: 1.797, validAcc: 0.802\n",
            "Model Saved!\n",
            "epoch 73 --> trainLoss: 1.763, trainAcc: 0.825, validLoss: 1.740, validAcc: 0.820\n",
            "Model Saved!\n",
            "epoch 74 --> trainLoss: 1.756, trainAcc: 0.827, validLoss: 1.728, validAcc: 0.820\n",
            "Model Saved!\n",
            "epoch 75 --> trainLoss: 1.758, trainAcc: 0.825, validLoss: 1.745, validAcc: 0.809\n",
            "Model Saved!\n",
            "epoch 76 --> trainLoss: 1.755, trainAcc: 0.826, validLoss: 1.770, validAcc: 0.810\n",
            "Model Saved!\n",
            "epoch 77 --> trainLoss: 1.749, trainAcc: 0.828, validLoss: 1.748, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 78 --> trainLoss: 1.742, trainAcc: 0.832, validLoss: 1.709, validAcc: 0.836\n",
            "Model Saved!\n",
            "epoch 79 --> trainLoss: 1.747, trainAcc: 0.828, validLoss: 1.751, validAcc: 0.819\n",
            "Model Saved!\n",
            "epoch 80 --> trainLoss: 1.745, trainAcc: 0.834, validLoss: 1.738, validAcc: 0.818\n",
            "Model Saved!\n",
            "epoch 81 --> trainLoss: 1.745, trainAcc: 0.831, validLoss: 1.733, validAcc: 0.822\n",
            "Model Saved!\n",
            "epoch 82 --> trainLoss: 1.735, trainAcc: 0.833, validLoss: 1.782, validAcc: 0.806\n",
            "Model Saved!\n",
            "epoch 83 --> trainLoss: 1.741, trainAcc: 0.832, validLoss: 1.733, validAcc: 0.825\n",
            "Model Saved!\n",
            "epoch 84 --> trainLoss: 1.743, trainAcc: 0.833, validLoss: 1.716, validAcc: 0.831\n",
            "Model Saved!\n",
            "epoch 85 --> trainLoss: 1.733, trainAcc: 0.835, validLoss: 1.691, validAcc: 0.836\n",
            "Model Saved!\n",
            "epoch 86 --> trainLoss: 1.731, trainAcc: 0.835, validLoss: 1.734, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 87 --> trainLoss: 1.732, trainAcc: 0.839, validLoss: 1.688, validAcc: 0.840\n",
            "Model Saved!\n",
            "epoch 88 --> trainLoss: 1.729, trainAcc: 0.836, validLoss: 1.687, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 89 --> trainLoss: 1.724, trainAcc: 0.842, validLoss: 1.697, validAcc: 0.835\n",
            "Model Saved!\n",
            "epoch 90 --> trainLoss: 1.730, trainAcc: 0.838, validLoss: 1.748, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 91 --> trainLoss: 1.728, trainAcc: 0.838, validLoss: 1.691, validAcc: 0.832\n",
            "Model Saved!\n",
            "epoch 92 --> trainLoss: 1.727, trainAcc: 0.839, validLoss: 1.714, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 93 --> trainLoss: 1.728, trainAcc: 0.838, validLoss: 1.697, validAcc: 0.842\n",
            "Model Saved!\n",
            "epoch 94 --> trainLoss: 1.721, trainAcc: 0.842, validLoss: 1.723, validAcc: 0.821\n",
            "Model Saved!\n",
            "epoch 95 --> trainLoss: 1.717, trainAcc: 0.845, validLoss: 1.721, validAcc: 0.818\n",
            "Model Saved!\n",
            "epoch 96 --> trainLoss: 1.725, trainAcc: 0.839, validLoss: 1.685, validAcc: 0.840\n",
            "Model Saved!\n",
            "epoch 97 --> trainLoss: 1.717, trainAcc: 0.842, validLoss: 1.690, validAcc: 0.824\n",
            "Model Saved!\n",
            "epoch 98 --> trainLoss: 1.712, trainAcc: 0.845, validLoss: 1.686, validAcc: 0.841\n",
            "Model Saved!\n",
            "epoch 99 --> trainLoss: 1.710, trainAcc: 0.847, validLoss: 1.713, validAcc: 0.832\n",
            "Model Saved!\n",
            "epoch 100 --> trainLoss: 1.707, trainAcc: 0.844, validLoss: 1.704, validAcc: 0.830\n",
            "Model Saved!\n",
            "epoch 101 --> trainLoss: 1.714, trainAcc: 0.842, validLoss: 1.765, validAcc: 0.811\n",
            "Model Saved!\n",
            "epoch 102 --> trainLoss: 1.703, trainAcc: 0.847, validLoss: 1.681, validAcc: 0.835\n",
            "Model Saved!\n",
            "epoch 103 --> trainLoss: 1.709, trainAcc: 0.848, validLoss: 1.695, validAcc: 0.831\n",
            "Model Saved!\n",
            "epoch 104 --> trainLoss: 1.717, trainAcc: 0.841, validLoss: 1.766, validAcc: 0.819\n",
            "Model Saved!\n",
            "epoch 105 --> trainLoss: 1.706, trainAcc: 0.849, validLoss: 1.777, validAcc: 0.801\n",
            "Model Saved!\n",
            "epoch 106 --> trainLoss: 1.707, trainAcc: 0.848, validLoss: 1.721, validAcc: 0.831\n",
            "Model Saved!\n",
            "epoch 107 --> trainLoss: 1.698, trainAcc: 0.851, validLoss: 1.682, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 108 --> trainLoss: 1.692, trainAcc: 0.852, validLoss: 1.700, validAcc: 0.834\n",
            "Model Saved!\n",
            "epoch 109 --> trainLoss: 1.699, trainAcc: 0.848, validLoss: 1.666, validAcc: 0.838\n",
            "Model Saved!\n",
            "epoch 110 --> trainLoss: 1.697, trainAcc: 0.853, validLoss: 1.677, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 111 --> trainLoss: 1.697, trainAcc: 0.851, validLoss: 1.674, validAcc: 0.840\n",
            "Model Saved!\n",
            "epoch 112 --> trainLoss: 1.687, trainAcc: 0.854, validLoss: 1.728, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 113 --> trainLoss: 1.692, trainAcc: 0.851, validLoss: 1.679, validAcc: 0.838\n",
            "Model Saved!\n",
            "epoch 114 --> trainLoss: 1.686, trainAcc: 0.856, validLoss: 1.694, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 115 --> trainLoss: 1.688, trainAcc: 0.853, validLoss: 1.690, validAcc: 0.828\n",
            "Model Saved!\n",
            "epoch 116 --> trainLoss: 1.686, trainAcc: 0.853, validLoss: 1.672, validAcc: 0.842\n",
            "Model Saved!\n",
            "epoch 117 --> trainLoss: 1.686, trainAcc: 0.855, validLoss: 1.701, validAcc: 0.825\n",
            "Model Saved!\n",
            "epoch 118 --> trainLoss: 1.683, trainAcc: 0.854, validLoss: 1.673, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 119 --> trainLoss: 1.682, trainAcc: 0.855, validLoss: 1.687, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 120 --> trainLoss: 1.681, trainAcc: 0.855, validLoss: 1.683, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 121 --> trainLoss: 1.675, trainAcc: 0.858, validLoss: 1.676, validAcc: 0.837\n",
            "Model Saved!\n",
            "epoch 122 --> trainLoss: 1.677, trainAcc: 0.858, validLoss: 1.703, validAcc: 0.826\n",
            "Model Saved!\n",
            "epoch 123 --> trainLoss: 1.679, trainAcc: 0.859, validLoss: 1.667, validAcc: 0.841\n",
            "Model Saved!\n",
            "epoch 124 --> trainLoss: 1.672, trainAcc: 0.864, validLoss: 1.667, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 125 --> trainLoss: 1.665, trainAcc: 0.868, validLoss: 1.679, validAcc: 0.845\n",
            "Model Saved!\n",
            "epoch 126 --> trainLoss: 1.673, trainAcc: 0.860, validLoss: 1.709, validAcc: 0.834\n",
            "Model Saved!\n",
            "epoch 127 --> trainLoss: 1.662, trainAcc: 0.867, validLoss: 1.688, validAcc: 0.841\n",
            "Model Saved!\n",
            "epoch 128 --> trainLoss: 1.673, trainAcc: 0.861, validLoss: 1.638, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 129 --> trainLoss: 1.665, trainAcc: 0.863, validLoss: 1.684, validAcc: 0.840\n",
            "Model Saved!\n",
            "epoch 130 --> trainLoss: 1.666, trainAcc: 0.865, validLoss: 1.662, validAcc: 0.847\n",
            "Model Saved!\n",
            "epoch 131 --> trainLoss: 1.663, trainAcc: 0.866, validLoss: 1.655, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 132 --> trainLoss: 1.656, trainAcc: 0.869, validLoss: 1.675, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 133 --> trainLoss: 1.657, trainAcc: 0.867, validLoss: 1.645, validAcc: 0.854\n",
            "Model Saved!\n",
            "epoch 134 --> trainLoss: 1.654, trainAcc: 0.869, validLoss: 1.650, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 135 --> trainLoss: 1.653, trainAcc: 0.870, validLoss: 1.656, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 136 --> trainLoss: 1.659, trainAcc: 0.867, validLoss: 1.644, validAcc: 0.852\n",
            "Model Saved!\n",
            "epoch 137 --> trainLoss: 1.656, trainAcc: 0.868, validLoss: 1.701, validAcc: 0.824\n",
            "Model Saved!\n",
            "epoch 138 --> trainLoss: 1.646, trainAcc: 0.869, validLoss: 1.648, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 139 --> trainLoss: 1.650, trainAcc: 0.870, validLoss: 1.644, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 140 --> trainLoss: 1.644, trainAcc: 0.870, validLoss: 1.654, validAcc: 0.847\n",
            "Model Saved!\n",
            "epoch 141 --> trainLoss: 1.642, trainAcc: 0.874, validLoss: 1.650, validAcc: 0.854\n",
            "Model Saved!\n",
            "epoch 142 --> trainLoss: 1.646, trainAcc: 0.871, validLoss: 1.647, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 143 --> trainLoss: 1.642, trainAcc: 0.874, validLoss: 1.644, validAcc: 0.853\n",
            "Model Saved!\n",
            "epoch 144 --> trainLoss: 1.637, trainAcc: 0.875, validLoss: 1.636, validAcc: 0.854\n",
            "Model Saved!\n",
            "epoch 145 --> trainLoss: 1.637, trainAcc: 0.876, validLoss: 1.642, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 146 --> trainLoss: 1.642, trainAcc: 0.875, validLoss: 1.640, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 147 --> trainLoss: 1.638, trainAcc: 0.876, validLoss: 1.655, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 148 --> trainLoss: 1.634, trainAcc: 0.878, validLoss: 1.664, validAcc: 0.839\n",
            "Model Saved!\n",
            "epoch 149 --> trainLoss: 1.631, trainAcc: 0.877, validLoss: 1.631, validAcc: 0.853\n",
            "Model Saved!\n",
            "epoch 150 --> trainLoss: 1.631, trainAcc: 0.880, validLoss: 1.637, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 151 --> trainLoss: 1.628, trainAcc: 0.879, validLoss: 1.626, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 152 --> trainLoss: 1.628, trainAcc: 0.879, validLoss: 1.641, validAcc: 0.856\n",
            "Model Saved!\n",
            "epoch 153 --> trainLoss: 1.630, trainAcc: 0.879, validLoss: 1.618, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 154 --> trainLoss: 1.624, trainAcc: 0.880, validLoss: 1.629, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 155 --> trainLoss: 1.618, trainAcc: 0.882, validLoss: 1.617, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 156 --> trainLoss: 1.618, trainAcc: 0.884, validLoss: 1.614, validAcc: 0.863\n",
            "Model Saved!\n",
            "epoch 157 --> trainLoss: 1.621, trainAcc: 0.881, validLoss: 1.634, validAcc: 0.853\n",
            "Model Saved!\n",
            "epoch 158 --> trainLoss: 1.622, trainAcc: 0.880, validLoss: 1.626, validAcc: 0.858\n",
            "Model Saved!\n",
            "epoch 159 --> trainLoss: 1.613, trainAcc: 0.884, validLoss: 1.657, validAcc: 0.845\n",
            "Model Saved!\n",
            "epoch 160 --> trainLoss: 1.617, trainAcc: 0.885, validLoss: 1.611, validAcc: 0.863\n",
            "Model Saved!\n",
            "epoch 161 --> trainLoss: 1.616, trainAcc: 0.886, validLoss: 1.600, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 162 --> trainLoss: 1.613, trainAcc: 0.885, validLoss: 1.617, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 163 --> trainLoss: 1.613, trainAcc: 0.887, validLoss: 1.629, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 164 --> trainLoss: 1.608, trainAcc: 0.887, validLoss: 1.609, validAcc: 0.865\n",
            "Model Saved!\n",
            "epoch 165 --> trainLoss: 1.608, trainAcc: 0.889, validLoss: 1.618, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 166 --> trainLoss: 1.604, trainAcc: 0.890, validLoss: 1.588, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 167 --> trainLoss: 1.602, trainAcc: 0.890, validLoss: 1.615, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 168 --> trainLoss: 1.601, trainAcc: 0.891, validLoss: 1.613, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 169 --> trainLoss: 1.599, trainAcc: 0.891, validLoss: 1.589, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 170 --> trainLoss: 1.608, trainAcc: 0.886, validLoss: 1.605, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 171 --> trainLoss: 1.600, trainAcc: 0.892, validLoss: 1.590, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 172 --> trainLoss: 1.594, trainAcc: 0.894, validLoss: 1.601, validAcc: 0.865\n",
            "Model Saved!\n",
            "epoch 173 --> trainLoss: 1.594, trainAcc: 0.893, validLoss: 1.609, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 174 --> trainLoss: 1.591, trainAcc: 0.895, validLoss: 1.585, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 175 --> trainLoss: 1.593, trainAcc: 0.896, validLoss: 1.588, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 176 --> trainLoss: 1.584, trainAcc: 0.897, validLoss: 1.595, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 177 --> trainLoss: 1.588, trainAcc: 0.896, validLoss: 1.610, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 178 --> trainLoss: 1.584, trainAcc: 0.897, validLoss: 1.576, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 179 --> trainLoss: 1.582, trainAcc: 0.899, validLoss: 1.583, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 180 --> trainLoss: 1.585, trainAcc: 0.899, validLoss: 1.576, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 181 --> trainLoss: 1.579, trainAcc: 0.900, validLoss: 1.567, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 182 --> trainLoss: 1.582, trainAcc: 0.898, validLoss: 1.571, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 183 --> trainLoss: 1.581, trainAcc: 0.898, validLoss: 1.585, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 184 --> trainLoss: 1.580, trainAcc: 0.897, validLoss: 1.574, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 185 --> trainLoss: 1.576, trainAcc: 0.901, validLoss: 1.591, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 186 --> trainLoss: 1.574, trainAcc: 0.905, validLoss: 1.581, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 187 --> trainLoss: 1.569, trainAcc: 0.902, validLoss: 1.588, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 188 --> trainLoss: 1.573, trainAcc: 0.901, validLoss: 1.585, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 189 --> trainLoss: 1.567, trainAcc: 0.904, validLoss: 1.576, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 190 --> trainLoss: 1.574, trainAcc: 0.901, validLoss: 1.575, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 191 --> trainLoss: 1.566, trainAcc: 0.903, validLoss: 1.567, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 192 --> trainLoss: 1.568, trainAcc: 0.904, validLoss: 1.570, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 193 --> trainLoss: 1.565, trainAcc: 0.902, validLoss: 1.572, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 194 --> trainLoss: 1.560, trainAcc: 0.907, validLoss: 1.577, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 195 --> trainLoss: 1.559, trainAcc: 0.907, validLoss: 1.571, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 196 --> trainLoss: 1.556, trainAcc: 0.908, validLoss: 1.570, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 197 --> trainLoss: 1.558, trainAcc: 0.907, validLoss: 1.576, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 198 --> trainLoss: 1.557, trainAcc: 0.908, validLoss: 1.564, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 199 --> trainLoss: 1.556, trainAcc: 0.909, validLoss: 1.558, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 200 --> trainLoss: 1.556, trainAcc: 0.908, validLoss: 1.569, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 201 --> trainLoss: 1.554, trainAcc: 0.910, validLoss: 1.561, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 202 --> trainLoss: 1.553, trainAcc: 0.908, validLoss: 1.567, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 203 --> trainLoss: 1.551, trainAcc: 0.911, validLoss: 1.563, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 204 --> trainLoss: 1.550, trainAcc: 0.910, validLoss: 1.556, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 205 --> trainLoss: 1.548, trainAcc: 0.911, validLoss: 1.553, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 206 --> trainLoss: 1.547, trainAcc: 0.912, validLoss: 1.561, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 207 --> trainLoss: 1.548, trainAcc: 0.912, validLoss: 1.562, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 208 --> trainLoss: 1.549, trainAcc: 0.911, validLoss: 1.553, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 209 --> trainLoss: 1.547, trainAcc: 0.911, validLoss: 1.557, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 210 --> trainLoss: 1.546, trainAcc: 0.913, validLoss: 1.556, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 211 --> trainLoss: 1.545, trainAcc: 0.911, validLoss: 1.556, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 212 --> trainLoss: 1.537, trainAcc: 0.917, validLoss: 1.551, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 213 --> trainLoss: 1.541, trainAcc: 0.914, validLoss: 1.556, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 214 --> trainLoss: 1.538, trainAcc: 0.914, validLoss: 1.550, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 215 --> trainLoss: 1.538, trainAcc: 0.915, validLoss: 1.549, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 216 --> trainLoss: 1.538, trainAcc: 0.914, validLoss: 1.539, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 217 --> trainLoss: 1.539, trainAcc: 0.916, validLoss: 1.543, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 218 --> trainLoss: 1.535, trainAcc: 0.915, validLoss: 1.543, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 219 --> trainLoss: 1.533, trainAcc: 0.915, validLoss: 1.550, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 220 --> trainLoss: 1.535, trainAcc: 0.920, validLoss: 1.545, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 221 --> trainLoss: 1.534, trainAcc: 0.918, validLoss: 1.551, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 222 --> trainLoss: 1.531, trainAcc: 0.917, validLoss: 1.542, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 223 --> trainLoss: 1.531, trainAcc: 0.918, validLoss: 1.546, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 224 --> trainLoss: 1.532, trainAcc: 0.916, validLoss: 1.549, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 225 --> trainLoss: 1.533, trainAcc: 0.917, validLoss: 1.547, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 226 --> trainLoss: 1.530, trainAcc: 0.919, validLoss: 1.544, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 227 --> trainLoss: 1.530, trainAcc: 0.919, validLoss: 1.547, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 228 --> trainLoss: 1.532, trainAcc: 0.917, validLoss: 1.540, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 229 --> trainLoss: 1.533, trainAcc: 0.916, validLoss: 1.545, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 230 --> trainLoss: 1.529, trainAcc: 0.919, validLoss: 1.541, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 231 --> trainLoss: 1.528, trainAcc: 0.918, validLoss: 1.545, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 232 --> trainLoss: 1.524, trainAcc: 0.919, validLoss: 1.541, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 233 --> trainLoss: 1.527, trainAcc: 0.917, validLoss: 1.545, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 234 --> trainLoss: 1.526, trainAcc: 0.921, validLoss: 1.539, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 235 --> trainLoss: 1.525, trainAcc: 0.924, validLoss: 1.535, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 236 --> trainLoss: 1.528, trainAcc: 0.920, validLoss: 1.538, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 237 --> trainLoss: 1.526, trainAcc: 0.919, validLoss: 1.536, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 238 --> trainLoss: 1.522, trainAcc: 0.923, validLoss: 1.533, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 239 --> trainLoss: 1.524, trainAcc: 0.920, validLoss: 1.540, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 240 --> trainLoss: 1.528, trainAcc: 0.920, validLoss: 1.536, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 241 --> trainLoss: 1.526, trainAcc: 0.920, validLoss: 1.537, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 242 --> trainLoss: 1.525, trainAcc: 0.919, validLoss: 1.537, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 243 --> trainLoss: 1.524, trainAcc: 0.918, validLoss: 1.537, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 244 --> trainLoss: 1.526, trainAcc: 0.920, validLoss: 1.537, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 245 --> trainLoss: 1.522, trainAcc: 0.917, validLoss: 1.535, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 246 --> trainLoss: 1.524, trainAcc: 0.921, validLoss: 1.535, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 247 --> trainLoss: 1.522, trainAcc: 0.923, validLoss: 1.539, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 248 --> trainLoss: 1.524, trainAcc: 0.922, validLoss: 1.535, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 249 --> trainLoss: 1.527, trainAcc: 0.919, validLoss: 1.536, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 250 --> trainLoss: 1.525, trainAcc: 0.918, validLoss: 1.542, validAcc: 0.891\n",
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "model, history = train(args, io)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "l2rDIN0H0j4W"
      },
      "outputs": [],
      "source": [
        "def infer(sLoader, threshold=0.05, verbose=False):\n",
        "    \"\"\"\n",
        "    @Inference: we compare the output confidence (entropy) at a branch with a certain threshold\n",
        "\n",
        "    Parameters:\n",
        "    sLoader (DataLoader): Iterable over the dataset, provides batches of (inputs, groundTruth).\n",
        "    threshold (float): Entropy threshold used to decide the stopping point for shortBranch.\n",
        "    verbose (bool): If True, prints entropy values when they are below the threshold.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the recording dictionary of accuracies, list of predicted labels, and overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Softmax layer initialization for converting outputs to probability distributions\n",
        "    softmaxLayer = nn.Softmax(dim=1)\n",
        "\n",
        "    # Initialize accuracy and list to hold predictions\n",
        "    acc = 0\n",
        "    predicted = []\n",
        "\n",
        "    # Dictionary to keep track of accuracy per branch (shortBranch: 0, longBranch: 1)\n",
        "    recorder = {x: [] for x in range(2)}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disables gradient calculations for inference, saving memory and computations\n",
        "    with torch.no_grad():\n",
        "        for inputs, gTruth in sLoader:\n",
        "            # Move input and ground truth data to GPU\n",
        "            inputs, gTruth = inputs.to('cuda'), gTruth.to('cuda')\n",
        "            batch_size = inputs.size()[0] # Retrieve your batch size\n",
        "            # Permute dimensions of inputs to fit model's expected input shape\n",
        "            inputs = inputs.permute(0, 2, 1)\n",
        "            # Process inputs through the base part of the model\n",
        "            x = model.baseModelconv1(get_graph_feature(inputs, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            # Iterate through each sample in the batch\n",
        "            for iSample in range(x.shape[0]):\n",
        "                # Process inputs through the short branch of the model\n",
        "                out1 = model.get_short_branch_output(x[iSample:iSample+1], 1)\n",
        "                # Apply softmax to get probabilities\n",
        "                y = softmaxLayer(out1)\n",
        "                # Calculate the entropy of the output probabilities\n",
        "                e = entropy(y.detach().cpu().numpy().squeeze(), base=10)\n",
        "                # Check if entropy is below the threshold\n",
        "                if e <= threshold:\n",
        "                    if verbose:\n",
        "                        print(e)  # Optionally print the entropy\n",
        "                    _, label = torch.max(out1, 1)\n",
        "                    predicted.append(label)\n",
        "                    if label == gTruth[iSample].item():\n",
        "                        recorder[0].append(1)\n",
        "                        acc += 1\n",
        "                    else:\n",
        "                        recorder[0].append(0)\n",
        "                    continue\n",
        "\n",
        "                out2 = model.get_long_branch_output(x[iSample:iSample+1], 1)\n",
        "                _, label = torch.max(out2, 1)\n",
        "                predicted.append(label)\n",
        "                if label == gTruth[iSample].item():\n",
        "                    acc += 1\n",
        "                    recorder[1].append(1)\n",
        "                else:\n",
        "                    recorder[1].append(0)\n",
        "\n",
        "        # Calculate the total accuracy by summing correct predictions divided by total predictions\n",
        "        acc = acc / sum([len(recorder[x]) for x in range(2)])\n",
        "\n",
        "    return recorder, predicted, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xV7xiet2PEdd"
      },
      "outputs": [],
      "source": [
        "def testingSummary(recorder, nBranches=2, overall=True):\n",
        "    \"\"\"\n",
        "    Prints a summary of testing accuracy for each branch and overall if specified.\n",
        "\n",
        "    Parameters:\n",
        "    recorder (dict): Dictionary containing lists of 0s and 1s where 1 represents a correct prediction, indexed by branch number.\n",
        "    nBranches (int): Number of branches in the model.\n",
        "    overall (bool): If True, prints the overall weighted accuracy across all branches.\n",
        "\n",
        "    Outputs:\n",
        "    Prints the accuracy of each branch and optionally the overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Header for the summary output\n",
        "    print('Summary')\n",
        "    print(\"======================\")\n",
        "\n",
        "    # Initialize accumulators for overall accuracy calculation\n",
        "    overallAcc, acc = 0, 0\n",
        "\n",
        "    # Calculate the total number of samples across all branches\n",
        "    overallCount = sum([len(recorder[x]) for x in range(nBranches)])\n",
        "\n",
        "    # Iterate through each branch to calculate and display individual accuracies\n",
        "    for i in range(nBranches):\n",
        "        # Number of samples in the current branch\n",
        "        countSamples = len(recorder[i])\n",
        "\n",
        "        # Check if there are samples in the current branch\n",
        "        if countSamples != 0:\n",
        "            # Calculate the accuracy for this branch\n",
        "            acc = recorder[i].count(1) / len(recorder[i])\n",
        "            # Print the accuracy and the percentage of total samples this branch represents\n",
        "            print(\"Branch {}: Accuracy {:.2f}% with {:.2f}% of the samples\".format(i+1, acc*100, countSamples/overallCount*100))\n",
        "        else:\n",
        "            # Handle the case where a branch has no samples\n",
        "            print(\"Branch {}: Got 0% of the samples\".format(i+1))\n",
        "\n",
        "        # Accumulate weighted accuracy for overall calculation\n",
        "        overallAcc += acc * countSamples\n",
        "\n",
        "    # If overall accuracy is to be calculated, display it\n",
        "    if overall:\n",
        "        print(\"Overall Weighted Accuracy: {:.2f}%\".format(overallAcc/overallCount*100))\n",
        "    return(overallAcc/overallCount*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9eylNEIahG",
        "outputId": "5c1c0390-160a-40a9-8971-2d3d49527ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->ptflops)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->ptflops)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->ptflops)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->ptflops)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->ptflops)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->ptflops)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->ptflops)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->ptflops)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ptflops-0.7.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "P_FNtX2gIUZK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from ptflops import get_model_complexity_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Calculate FLOPs of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yXon4ULIYBT",
        "outputId": "65109f7b-b7fc-449a-c1c9-67b82cbcc4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  512, 100.000% Params, 5.9 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(384, 75.000% Params, 3.93 MMac, 66.667% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 25.000% Params, 1.31 MMac, 22.222% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 11.111% MACs, negative_slope=0.2)\n",
            ")\n",
            "FLOPs: 5.900000 MMac\n"
          ]
        }
      ],
      "source": [
        "flopsconv1, paramsconv1 = get_model_complexity_info(model.baseModelconv1, (6, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs: {:2f} MMac'.format(5.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32I1XlZlJiD3",
        "outputId": "5badd1ec-ed71-4a05-a1f4-fa3479381f23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  208.68 k, 100.000% Params, 209.45 KMac, 100.000% MACs, \n",
            "  (0): Linear(65.54 k, 31.405% Params, 65.54 KMac, 31.290% MACs, in_features=128, out_features=512, bias=False)\n",
            "  (1): BatchNorm1d(1.02 k, 0.491% Params, 1.02 KMac, 0.489% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.244% MACs, negative_slope=0.2)\n",
            "  (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (4): Linear(131.33 k, 62.933% Params, 131.33 KMac, 62.702% MACs, in_features=512, out_features=256, bias=True)\n",
            "  (5): BatchNorm1d(512, 0.245% Params, 512.0 Mac, 0.244% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.122% MACs, negative_slope=0.2)\n",
            "  (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (8): Linear(10.28 k, 4.926% Params, 10.28 KMac, 4.908% MACs, in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "FLOPs: 209.45 KMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model.shortBranch, (128, ), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRModsL7LwxM",
        "outputId": "fad5ec86-dd49-43ea-b8b6-41e882f465b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short path FLOPs: 6.109450 MMac\n"
          ]
        }
      ],
      "source": [
        "print('Short path FLOPs: {:2f} MMac'.format(5.9+0.20945))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyGwqyz0JYiR",
        "outputId": "8773aa15-0844-4e07-af5a-8454128b5c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm1d ptflops can affect your code!\n",
            "Warning: parameters of some of the modules were counted twice because of multiple links to the same modules. Extended per layer parameters num statistic could be unreliable.\n",
            "eeModel_E0(\n",
            "  2.02 M, 100.152% Params, 1.5 GMac, 84.532% MACs, \n",
            "  (bn1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(256, 0.013% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(512, 0.025% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn5): BatchNorm1d(2.05 k, 0.101% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (baseModelconv1): Sequential(\n",
            "    512, 0.025% Params, 5.9 MMac, 0.333% MACs, \n",
            "    (0): Conv2d(384, 0.019% Params, 3.93 MMac, 0.222% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (shortBranch): Sequential(\n",
            "    208.68 k, 10.340% Params, 209.45 KMac, 0.012% MACs, \n",
            "    (0): Linear(65.54 k, 3.247% Params, 65.54 KMac, 0.004% MACs, in_features=128, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.051% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 6.507% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.025% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.509% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    8.32 k, 0.412% Params, 85.85 MMac, 4.850% MACs, \n",
            "    (0): Conv2d(8.19 k, 0.406% Params, 83.89 MMac, 4.739% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.006% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    16.64 k, 0.824% Params, 171.7 MMac, 9.700% MACs, \n",
            "    (0): Conv2d(16.38 k, 0.812% Params, 167.77 MMac, 9.477% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, 0.013% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.074% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    66.05 k, 3.273% Params, 678.95 MMac, 38.354% MACs, \n",
            "    (0): Conv2d(65.54 k, 3.247% Params, 671.09 MMac, 37.910% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, 0.025% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 2.62 MMac, 0.148% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    526.34 k, 26.079% Params, 540.02 MMac, 30.506% MACs, \n",
            "    (0): Conv1d(524.29 k, 25.977% Params, 536.87 MMac, 30.328% MACs, 512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(2.05 k, 0.101% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.059% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (longBranch): Sequential(\n",
            "    1.19 M, 59.047% Params, 1.19 MMac, 0.067% MACs, \n",
            "    (0): Linear(1.05 M, 51.955% Params, 1.05 MMac, 0.059% MACs, in_features=2048, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.051% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 6.507% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.025% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.509% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            ")\n",
            "FLOPs: 1.77 GMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model, (3, 1024), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Calculate number of parameters of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_kBvvytzVe",
        "outputId": "e8f7c795-e9fc-40cd-bb9e-96af76d8ebff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters in Short Path: 209192\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate the total number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Parameters in the base model\n",
        "baseModelconv1_params = count_parameters(model.baseModelconv1)\n",
        "\n",
        "# Parameters in the short branch\n",
        "short_path_params = count_parameters(model.shortBranch)\n",
        "\n",
        "print(\"Parameters in Short Path:\", short_path_params+baseModelconv1_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kCXX2hrwNN7",
        "outputId": "83bc6f67-8fbf-450d-cd61-780f869fe023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Linear: 1-1                            65,536\n",
            "├─BatchNorm1d: 1-2                       1,024\n",
            "├─LeakyReLU: 1-3                         --\n",
            "├─Dropout: 1-4                           --\n",
            "├─Linear: 1-5                            131,328\n",
            "├─BatchNorm1d: 1-6                       512\n",
            "├─LeakyReLU: 1-7                         --\n",
            "├─Dropout: 1-8                           --\n",
            "├─Linear: 1-9                            10,280\n",
            "=================================================================\n",
            "Total params: 208,680\n",
            "Trainable params: 208,680\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            384\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 512\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model.shortBranch))\n",
        "print(summary(model.baseModelconv1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Measure inference time and overall weighted accuracy with varying entropy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "x0ln00bI0qZq"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False) # Loading test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z6-w1P3aMzNT"
      },
      "outputs": [],
      "source": [
        "inference_times = []\n",
        "accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxISoQfSjQbG",
        "outputId": "e1d56303-090e-4b9a-bc0f-ba2112df15d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 10.457916 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Got 0% of the samples\n",
            "Branch 2: Accuracy 91.98% with 100.00% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhtT-ZIdk70V",
        "outputId": "504f4ba1-6bc8-4bfb-d19f-df83682532a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 10.588155 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 0.04% of the samples\n",
            "Branch 2: Accuracy 91.97% with 99.96% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQE-rELqk-PF",
        "outputId": "0c240965-5407-4f73-a361-3b756038ef7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 10.224608 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 0.32% of the samples\n",
            "Branch 2: Accuracy 91.95% with 99.68% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0PwWILTk__D",
        "outputId": "8bea46ce-7ade-483e-ccd6-c83baea0a2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 9.866599 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 1.78% of the samples\n",
            "Branch 2: Accuracy 91.83% with 98.22% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUYayMiwlBpN",
        "outputId": "7e034aa1-c791-46fc-f262-8ba085db6164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 9.340453 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.54% with 8.83% of the samples\n",
            "Branch 2: Accuracy 91.29% with 91.17% of the samples\n",
            "Overall Weighted Accuracy: 92.02%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_9l0jzxlEND",
        "outputId": "94afdeca-9d52-4bc6-ba89-582abb16710e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 8.362524 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 99.27% with 22.33% of the samples\n",
            "Branch 2: Accuracy 89.88% with 77.67% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TduJVQ9YlF6T",
        "outputId": "65eaa951-9d55-4e16-ab3e-bc239dd6b19b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 7.119032 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.93% with 38.01% of the samples\n",
            "Branch 2: Accuracy 87.71% with 61.99% of the samples\n",
            "Overall Weighted Accuracy: 91.98%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd_1UvQOlHhc",
        "outputId": "6fc1f22e-fe0b-450d-bc28-a635e588d1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.295465 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.18% with 48.99% of the samples\n",
            "Branch 2: Accuracy 85.54% with 51.01% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdMnwqQOlJMD",
        "outputId": "1761da63-f8c2-47ea-b5be-495a726c83cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.780920 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 97.75% with 59.36% of the samples\n",
            "Branch 2: Accuracy 83.05% with 40.64% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewn8ofWPlKq6",
        "outputId": "953274e4-9569-4b87-f27f-35dd853e2dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.908690 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 96.11% with 67.75% of the samples\n",
            "Branch 2: Accuracy 81.66% with 32.25% of the samples\n",
            "Overall Weighted Accuracy: 91.45%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLXHLaVC7e7",
        "outputId": "8621305c-915e-441c-9960-f67291911673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.345482 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 94.31% with 76.26% of the samples\n",
            "Branch 2: Accuracy 79.52% with 23.74% of the samples\n",
            "Overall Weighted Accuracy: 90.80%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHDKqmxZlMGj",
        "outputId": "00ec885c-4204-4a25-fe3e-991e5302a9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.564259 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 92.01% with 84.72% of the samples\n",
            "Branch 2: Accuracy 77.19% with 15.28% of the samples\n",
            "Overall Weighted Accuracy: 89.75%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM2caHq_lNoY",
        "outputId": "69460124-d46c-4241-c048-873277fe3cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 3.220934 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 90.69% with 90.48% of the samples\n",
            "Branch 2: Accuracy 76.17% with 9.52% of the samples\n",
            "Overall Weighted Accuracy: 89.30%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S--mC_5slPqo",
        "outputId": "32e7314e-1129-4277-c03b-820bc0482ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.860422 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 88.58% with 96.19% of the samples\n",
            "Branch 2: Accuracy 78.72% with 3.81% of the samples\n",
            "Overall Weighted Accuracy: 88.21%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqQAsnGtlR3n",
        "outputId": "cc248342-50bd-44c3-dd3c-7ac191f69e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.520681 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 87.07% with 99.35% of the samples\n",
            "Branch 2: Accuracy 68.75% with 0.65% of the samples\n",
            "Overall Weighted Accuracy: 86.95%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9UKRbLLlUuV",
        "outputId": "60bd5d83-085d-4ad1-dd29-2b71f9e6543f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.514884 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.66% with 99.96% of the samples\n",
            "Branch 2: Accuracy 0.00% with 0.04% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xawSuhXHM1rA",
        "outputId": "bc1aac96-84ff-44bb-e98e-9512d43ba5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.519719 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.63% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g0IZt8GM7Qc",
        "outputId": "8eae5037-b944-48ae-dc81-ccf44326efb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.526888 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.63% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fur5evB3M-ln",
        "outputId": "38cff88a-5c91-4c64-bd56-10c929eeba5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.466304 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.63% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ6AJscNBEb",
        "outputId": "0a5d37ed-0a6f-4e0e-bb3a-6df6949dc5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.487118 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.63% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7S0a1mgNDCh",
        "outputId": "9c3ea922-b7af-4e45-aa9f-5dde45d34a28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 2.463903 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 86.63% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 86.63%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEFfCQeaZayA",
        "outputId": "6e305c50-cc3d-45ad-a8f1-3c628e67b850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10.457915782928467, 10.588154792785645, 10.224608421325684, 9.86659860610962, 9.340453147888184, 8.362524271011353, 7.119032144546509, 6.295464515686035, 5.7809202671051025, 4.908689975738525, 4.345482349395752, 3.5642588138580322, 3.2209343910217285, 2.860422134399414, 2.5206809043884277, 2.514883518218994, 2.519719123840332, 2.526888370513916, 2.466303586959839, 2.4871175289154053, 2.4639031887054443]\n",
            "[91.9773095623987, 91.9773095623987, 91.9773095623987, 91.9773095623987, 92.01782820097245, 91.9773095623987, 91.9773095623987, 91.73419773095624, 91.77471636952998, 91.45056726094003, 90.80226904376013, 89.74878444084278, 89.3030794165316, 88.20907617504052, 86.95299837925445, 86.6288492706645, 86.6288492706645, 86.6288492706645, 86.6288492706645, 86.6288492706645, 86.6288492706645]\n"
          ]
        }
      ],
      "source": [
        "print(inference_times)\n",
        "print(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5WzXGEzbu4o",
        "outputId": "1986587f-3efa-4e5b-d5ba-5724400cc76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "NLwWfowBNJBR",
        "outputId": "82424efa-5772-4f9a-f2c1-c66b949a57b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 5e+06x5e+06 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from adjustText import adjust_text\n",
        "entropies = [x/10 for x in range(0, 21)]\n",
        "# Creating the scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(inference_times, accuracies, c='blue')\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(entropies):\n",
        "    text = ax.annotate(str(txt), (inference_times[i], accuracies[i]))\n",
        "    texts.append(text)\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='black'))\n",
        "plt.figure(figsize=(50000, 50000))\n",
        "ax.set_xlabel('Inference Times')\n",
        "ax.set_ylabel('Accuracies')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
