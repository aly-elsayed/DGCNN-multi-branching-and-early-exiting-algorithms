{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XS_6buTBwPl"
      },
      "source": [
        "### **Import and Install Libraries. Download Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2WB_AlhDx9_",
        "outputId": "c834b03d-e9e9-4324-c597-a3dab85bf7d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZLVYrPJeOk2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "from scipy.stats import entropy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "import sklearn.metrics as metrics\n",
        "import copy\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UH_X_YHfYkK",
        "outputId": "337dece1-50f9-4f83-df8f-1b8138555769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-26 08:11:45--  https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435212151 (415M) [application/zip]\n",
            "Saving to: ‘modelnet40_ply_hdf5_2048.zip’\n",
            "\n",
            "modelnet40_ply_hdf5 100%[===================>] 415.05M  12.9MB/s    in 28s     \n",
            "\n",
            "2024-04-26 08:12:14 (14.7 MB/s) - ‘modelnet40_ply_hdf5_2048.zip’ saved [435212151/435212151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
        "!unzip -q modelnet40_ply_hdf5_2048.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekUukrU6v2Kz"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore specific warnings related to multiprocessing and os.fork\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\".*os.fork.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTRjk6Lp_cJW"
      },
      "outputs": [],
      "source": [
        "#Class for your arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.exp_name = 'exp'\n",
        "        self.model = 'dgcnn'\n",
        "        self.dataset = 'modelnet40'\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 16\n",
        "        self.epochs = 250\n",
        "        self.use_sgd = True\n",
        "        self.lr = 0.001\n",
        "        self.momentum = 0.9\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.eval = False\n",
        "        self.num_points = 1024\n",
        "        self.dropout = 0.5\n",
        "        self.emb_dims = 1024\n",
        "        self.k = 10\n",
        "        self.model_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERQ6I6HnfprZ"
      },
      "outputs": [],
      "source": [
        "#Method to retrieve your training and testing files\n",
        "def getDataFiles(list_filename):\n",
        "    print(list_filename)\n",
        "    return [line.rstrip() for line in open(list_filename)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8yn70xofrpU",
        "outputId": "e8a8ad75-c8a6-4b4e-d8d3-1bfa24793862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/modelnet40_ply_hdf5_2048/train_files.txt\n",
            "data/modelnet40_ply_hdf5_2048/test_files.txt\n"
          ]
        }
      ],
      "source": [
        "#Store your dataset in the folder 'data'\n",
        "import shutil\n",
        "os.mkdir('data')\n",
        "shutil.move('modelnet40_ply_hdf5_2048', 'data')\n",
        "TRAIN_FILES = getDataFiles( \\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/train_files.txt'))\n",
        "TEST_FILES = getDataFiles(\\\n",
        "    os.path.join('data/modelnet40_ply_hdf5_2048/test_files.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sIrLnpFg5Gk"
      },
      "outputs": [],
      "source": [
        "def cal_loss(pred, gold, smoothing=True):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.2\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "    else:\n",
        "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7Te875Og7xc"
      },
      "outputs": [],
      "source": [
        "class IOStream():\n",
        "    \"\"\"\n",
        "    A utility class for outputting text to both console and a file. This class provides a method to concurrently print\n",
        "    information to the console and append it to a file. This can be particularly useful for logging purposes in\n",
        "    applications like long-running processes where monitoring and retaining output history is necessary.\n",
        "\n",
        "    Attributes:\n",
        "    f (file object): File object used to append text to the specified file.\n",
        "    \"\"\"\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initialize the IOStream by opening or creating a file for appending text.\n",
        "\n",
        "        Parameters:\n",
        "        path (str): The file path where text will be appended. If the file does not exist, it will be created.\n",
        "        \"\"\"\n",
        "        self.f = open(path, 'a')  # Open the file in append mode.\n",
        "\n",
        "    def cprint(self, text):\n",
        "        \"\"\"\n",
        "        Prints text to the console and appends it to the file initialized in this class instance.\n",
        "\n",
        "        Parameters:\n",
        "        text (str): The text to be printed and logged.\n",
        "        \"\"\"\n",
        "        print(text)  # Print text to console.\n",
        "        self.f.write(text + '\\n')  # Append text to file and add a newline.\n",
        "        self.f.flush()  # Flush the internal buffer, ensuring all file operations are completed immediately.\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Closes the file associated with this instance. It is important to call this method to free up system resources.\n",
        "        \"\"\"\n",
        "        self.f.close()  # Close the file to release resources.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH-3GRMgB4eu"
      },
      "source": [
        "### **Calculate 10 k-nearest neighbors based on the Euclidean distance $(x_1-x_2)^2$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJz0UTK3h2pV"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    # print(idx[1,:,1].size, 'idx of knn')\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soeA9B4Nh3cr"
      },
      "outputs": [],
      "source": [
        "def get_graph_feature(x, k=10, idx=None):\n",
        "    # print(x.shape, 'Input x to get_graph_feature')\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "    # print(idx)\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "    # print(idx[1,1,:], 'idx of get_graph_feature')\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36SyVuaCKTb"
      },
      "source": [
        "### **DGCNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU0hruirh9Xt"
      },
      "outputs": [],
      "source": [
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=args.dropout)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=args.dropout)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j48wtIIvVID2"
      },
      "source": [
        "### **DGCNN EE3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhsO2Y5HjpKN"
      },
      "outputs": [],
      "source": [
        "class eeModel_EE3(nn.Module):\n",
        "    def __init__(self, args, output_channels=40):\n",
        "        super(eeModel_EE3, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "        self.k = args.k\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(args.emb_dims)\n",
        "\n",
        "        ################################Base Model###################################\n",
        "        self.baseModelconv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                       self.bn1,\n",
        "                                       nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.baseModelconv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        #############################################################################\n",
        "\n",
        "        #############################Short Branch####################################\n",
        "        self.shortBranch = nn.Sequential(nn.Linear(512*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ################################################################################\n",
        "\n",
        "        ####################################Long Branch#################################\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.longBranch_fc = nn.Sequential(nn.Linear(args.emb_dims*2, 512, bias=False),\n",
        "                                         nn.BatchNorm1d(512),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(512, 256),\n",
        "                                         nn.BatchNorm1d(256),\n",
        "                                         nn.LeakyReLU(negative_slope=0.2),\n",
        "                                         nn.Dropout(p=args.dropout),\n",
        "                                         nn.Linear(256, output_channels))\n",
        "        ####################################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x_baseModelconv1 = self.baseModelconv1(get_graph_feature(x, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv2 = self.baseModelconv2(get_graph_feature(x_baseModelconv1, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv3 = self.baseModelconv3(get_graph_feature(x_baseModelconv2, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModelconv4 = self.baseModelconv4(get_graph_feature(x_baseModelconv3, k=self.k)).max(dim=-1, keepdim=False)[0]\n",
        "        x_baseModel = torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x_baseModelconv4), dim=1)\n",
        "        x_shortBranch, x_longBranch = self.get_short_branch_output(x_baseModel, batch_size), self.get_long_branch_output(x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x_baseModelconv4, batch_size)\n",
        "        return x_shortBranch, x_longBranch\n",
        "\n",
        "    def get_short_branch_output(self, x_baseModel, batch_size):\n",
        "        x_shortBranch = self.shortBranch(torch.cat((F.adaptive_max_pool1d(x_baseModel, 1).view(batch_size, -1),\n",
        "                                                    F.adaptive_avg_pool1d(x_baseModel, 1).view(batch_size, -1)), 1))\n",
        "        return x_shortBranch\n",
        "\n",
        "    def get_long_branch_output(self, x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x_baseModelconv4, batch_size):\n",
        "        x_longBranch = self.conv5(torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x_baseModelconv4), dim=1))\n",
        "        x_longBranch = torch.cat((F.adaptive_max_pool1d(x_longBranch, 1).view(batch_size, -1),\n",
        "                                  F.adaptive_avg_pool1d(x_longBranch, 1).view(batch_size, -1)), 1)\n",
        "        x_longBranch = self.longBranch_fc(x_longBranch)\n",
        "        return x_longBranch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AgLkE_7e1NL"
      },
      "outputs": [],
      "source": [
        "def load_data(partition):\n",
        "    \"\"\"\n",
        "    Load pointcloud data and labels from HDF5 files based on the specified partition (train or test).\n",
        "    This function is designed to work within a filesystem structure expected for ModelNet40 dataset files,\n",
        "    aggregating data from multiple files into a single array for both data points and labels.\n",
        "\n",
        "    Parameters:\n",
        "    partition (str): Specifies which dataset partition to load. Expected values are 'train' or 'test'.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy arrays: one for the data (pointclouds) and one for the labels.\n",
        "    \"\"\"\n",
        "    # Define base directory relative to this script's location.\n",
        "    BASE_DIR = os.path.dirname(os.path.abspath(r'\\data\\modelnet40_ply_hdf5_2048'))\n",
        "    # Define data directory path combining base directory with the data subdirectory.\n",
        "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "\n",
        "    # Initialize lists to hold data and labels from all files.\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "\n",
        "    # Loop over each file matching the pattern for the specified partition.\n",
        "    for h5_name in glob.glob(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048', f'ply_data_{partition}*.h5')):\n",
        "        # Open the HDF5 file for reading.\n",
        "        f = h5py.File(h5_name)\n",
        "        # Load all data points as float32 and labels as int64 from the file.\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        # Ensure the file is closed after its contents are loaded.\n",
        "        f.close()\n",
        "\n",
        "        # Append the data and labels to their respective lists.\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "\n",
        "    # Concatenate all data and labels from the list into single numpy arrays.\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "\n",
        "    # Return the aggregated data and labels.\n",
        "    return all_data, all_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4AH8w7Ke6Nt"
      },
      "outputs": [],
      "source": [
        "def translate_pointcloud(pointcloud):\n",
        "    \"\"\"\n",
        "    Apply a random translation to a pointcloud. This is done by first scaling the pointcloud with a random factor\n",
        "    and then adding a small random shift. This can be used as a data augmentation technique to make models robust\n",
        "    to variations in object position and scale.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, 3) where N is the number of points.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The translated pointcloud as a new numpy array of type 'float32'.\n",
        "    \"\"\"\n",
        "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])  # Random scaling factors.\n",
        "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])    # Random translation offsets.\n",
        "\n",
        "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')  # Apply scaling and translation\n",
        "    return translated_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB31Q97vf4bN"
      },
      "outputs": [],
      "source": [
        "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):\n",
        "    \"\"\"\n",
        "    Apply Gaussian noise to a pointcloud. Each point's position is altered by adding a noise vector drawn from a\n",
        "    Gaussian distribution, clipped to a maximum magnitude to prevent excessive perturbation. This augmentation\n",
        "    promotes robustness to small variations or noise.\n",
        "\n",
        "    Parameters:\n",
        "    pointcloud (np.array): A numpy array of shape (N, C) where N is the number of points and C is the number of coordinates.\n",
        "    sigma (float): Standard deviation of the Gaussian noise.\n",
        "    clip (float): Maximum allowed value for noise applied to the point coordinates.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The jittered pointcloud.\n",
        "    \"\"\"\n",
        "    N, C = pointcloud.shape  # Number of points N and dimensions C in the pointcloud.\n",
        "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)  # Add clipped Gaussian noise.\n",
        "    return pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGxrJjODf7iU"
      },
      "outputs": [],
      "source": [
        "class ModelNet40(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for ModelNet40, which includes methods for loading and preprocessing pointcloud data for training or testing.\n",
        "    Data augmentation (translation and shuffling) is applied to training data to improve model generalization.\n",
        "\n",
        "    Attributes:\n",
        "    num_points (int): Number of points per pointcloud to use.\n",
        "    partition (str): Dataset partition to use, either 'train' or 'test'.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points, partition='train'):\n",
        "        \"\"\"\n",
        "        Initialize the dataset object, loading data and labels according to the specified partition.\n",
        "\n",
        "        Parameters:\n",
        "        num_points (int): Number of points to sample from each pointcloud.\n",
        "        partition (str): Which dataset partition to use, 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        self.data, self.label = load_data(partition)  # Load dataset.\n",
        "        self.num_points = num_points  # Points per pointcloud.\n",
        "        self.partition = partition  # Dataset partition.\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Retrieve a pointcloud and its label, applying data augmentation if in training mode.\n",
        "\n",
        "        Parameters:\n",
        "        item (int): Index of the pointcloud to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        tuple: Tuple containing the pointcloud and its label.\n",
        "        \"\"\"\n",
        "        pointcloud = self.data[item][:self.num_points]  # Get the subset of points.\n",
        "        label = self.label[item]\n",
        "        if self.partition == 'train':  # Conditionally apply augmentations.\n",
        "            pointcloud = translate_pointcloud(pointcloud)\n",
        "            np.random.shuffle(pointcloud)  # Shuffle points to remove any order bias.\n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the total number of pointclouds in the dataset.\n",
        "\n",
        "        Returns:\n",
        "        int: The number of pointclouds.\n",
        "        \"\"\"\n",
        "        return self.data.shape[0]  # Number of pointclouds in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaxTC3jlNufT"
      },
      "outputs": [],
      "source": [
        "# Dictionary for ModelNet40 classes. Helpful when printing confusion matrix. Note that ModelNet40 sorts its classes alphabetically\n",
        "label_dict = {\n",
        "    'airplane': 0,\n",
        "    'bathtub': 1,\n",
        "    'bed': 2,\n",
        "    'bench': 3,\n",
        "    'bookshelf': 4,\n",
        "    'bottle': 5,\n",
        "    'bowl': 6,\n",
        "    'car': 7,\n",
        "    'chair': 8,\n",
        "    'cone': 9,\n",
        "    'cup': 10,\n",
        "    'curtain': 11,\n",
        "    'desk': 12,\n",
        "    'door': 13,\n",
        "    'dresser': 14,\n",
        "    'flower_pot': 15,\n",
        "    'glass_box': 16,\n",
        "    'guitar': 17,\n",
        "    'keyboard': 18,\n",
        "    'lamp': 19,\n",
        "    'laptop': 20,\n",
        "    'mantel': 21,\n",
        "    'monitor': 22,\n",
        "    'night_stand': 23,\n",
        "    'person': 24,\n",
        "    'piano': 25,\n",
        "    'plant': 26,\n",
        "    'radio': 27,\n",
        "    'range_hood': 28,\n",
        "    'sink': 29,\n",
        "    'sofa': 30,\n",
        "    'stairs': 31,\n",
        "    'stool': 32,\n",
        "    'table': 33,\n",
        "    'tent': 34,\n",
        "    'toilet': 35,\n",
        "    'tv_stand': 36,\n",
        "    'vase': 37,\n",
        "    'wardrobe': 38,\n",
        "    'xbox': 39\n",
        "}\n",
        "modes = list(label_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMOAvhfCU2r"
      },
      "source": [
        "### **Training and Testing algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYGrRCMWgBGG"
      },
      "outputs": [],
      "source": [
        "def train(args, io):\n",
        "    # 1. Determine the size of the original training dataset\n",
        "    total_train_samples = len(ModelNet40(partition='train', num_points=args.num_points))\n",
        "    train_size = int(0.75 * total_train_samples)  # 60% of the original training dataset\n",
        "    validation_size = total_train_samples - train_size  # Remaining samples for validation\n",
        "\n",
        "    # 2. Split the original training dataset\n",
        "    train_dataset, validation_dataset = random_split(ModelNet40(partition='train', num_points=args.num_points), [train_size, validation_size])\n",
        "\n",
        "    # 3. Create DataLoader for the training and validation datasets\n",
        "    train_loader = DataLoader(train_dataset, num_workers=2, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    validation_loader = DataLoader(validation_dataset, num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    # Test DataLoader remains unchanged\n",
        "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "    history = {\"1\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"2\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}},\n",
        "              \"T\": {\"train\": {\"loss\": [], \"accuracy\": []}, \"validation\":{\"loss\": [], \"accuracy\": []}}}\n",
        "    loss1_list = []\n",
        "    loss2_list = []\n",
        "    acc1_list = []\n",
        "    acc2_list = []\n",
        "    eStopThreshold, eStopCounter = 8, 0\n",
        "    device = \"cuda\" # Set up your NVIDIA GPU.\n",
        "    model = eeModel_EE3(args).to(device) #Initialize your model.\n",
        "    print(summary(model))## Print your model summary.\n",
        "    print(\"Let's use\", torch.cpu.device_count(), \"GPUs!\") ## Print how many GPUs are being used.\n",
        "\n",
        "    #Set up your optimizer and loss\n",
        "    if args.use_sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        loss1Total, loss2Total, totalLoss = 0, 0, 0\n",
        "        acc1Total, acc2Total, totalAcc = 0, 0, 0\n",
        "        loss1Total_v, loss2Total_v, valLoss = 0, 0, 0\n",
        "        acc1Total_v, acc2Total_v, valAcc = 0, 0, 0\n",
        "        train_loss = 0.0\n",
        "        loss = 0\n",
        "        bestAcc = 0\n",
        "        best_loss = 100\n",
        "        preValLoss = 100\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data, label in train_loader:\n",
        "            data, label = data.to(device), label.to(device).squeeze() # Send your input data and label to device e.g. GPU\n",
        "            data = data.permute(0, 2, 1) # Permute your data for subsequent operations\n",
        "            batch_size = data.size()[0] # Retrieve your batch size\n",
        "            opt.zero_grad() # Zero your optimizer\n",
        "            logits1, logits2 = model(data) # Compute unnormalized model outputs e.g. short branch and long branch outputs\n",
        "            loss1, loss2 = criterion(logits1, label), criterion(logits2, label) # Calculate your losses e.g. short branch and long branch losses\n",
        "            loss1_list.append(loss1.item()) # Append your short branch losses\n",
        "            loss2_list.append(loss2.item()) # Append your long branch losses\n",
        "            loss1Total += loss1.item() # Aggregate your short branch losses\n",
        "            loss2Total += loss2.item() # Aggregate your long branch losses\n",
        "            totalLoss += 0.5*loss1.item() + 0.5*loss2.item() # Average your loss\n",
        "            loss1.backward(retain_graph=True) # Backward propagate your short branch loss\n",
        "            loss2.backward(retain_graph=True) # Backward propagate your long branch loss\n",
        "            _, predicted1 = torch.max(logits1, 1) # Max pool your short branch predicitions\n",
        "            _, predicted2 = torch.max(logits2, 1) # Max pool your long branch predicitions\n",
        "            acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy()) # Calculate your short branch accuracy\n",
        "            acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy()) # Calculate your long branch accurac\n",
        "            acc1_list.append(acc1) # Append your short branch accuracies\n",
        "            acc2_list.append(acc2) # Append your long branch accuracies\n",
        "            acc1Total += acc1 # Aggregate your short branch accuracies\n",
        "            acc2Total += acc2 # Aggregate your long branch accuracies\n",
        "            totalAcc += 0.5*acc1+0.5*acc2 # Average your accuracy\n",
        "            opt.step() # Step your optimizer\n",
        "            count += batch_size # Recursively add number of prediciton counts\n",
        "        loss1Total = loss1Total/len(train_loader) # Normalize your short branch losses\n",
        "        loss2Total = loss2Total/len(train_loader) # Normalize your long branch losses\n",
        "        totalLoss = totalLoss/len(train_loader) # Normalize your total loss\n",
        "        acc1Total = acc1Total/len(train_loader) # Normalize your short branch accuracy\n",
        "        acc2Total = acc2Total/len(train_loader) # Normalize your long branch accuracy\n",
        "        totalAcc = totalAcc/len(train_loader) # Normalize your total accuracy\n",
        "        ############## Append to your history dictionaty################\n",
        "        history[\"1\"][\"train\"][\"loss\"].append(loss1Total)\n",
        "        history[\"1\"][\"train\"][\"accuracy\"].append(acc1Total)\n",
        "        history[\"2\"][\"train\"][\"loss\"].append(loss2Total)\n",
        "        history[\"2\"][\"train\"][\"accuracy\"].append(acc2Total)\n",
        "        history[\"T\"][\"train\"][\"loss\"].append(totalLoss)\n",
        "        history[\"T\"][\"train\"][\"accuracy\"].append(totalAcc)\n",
        "        ###############################################################\n",
        "        print(\"epoch {} --> trainLoss: {:0.3f}, trainAcc: {:0.3f}\" # Print your epoch, total normalized loss, total normalized accuracy.\n",
        "                  .format(epoch+1, totalLoss, totalAcc), end=\"\")\n",
        "\n",
        "        ####################### Validation is identical training####################\n",
        "        if validation_loader:\n",
        "          with torch.no_grad():\n",
        "            model.eval() # Set up your model for evaluation\n",
        "            for data, label in validation_loader:\n",
        "              data, label = data.to(device), label.to(device).squeeze()\n",
        "              data = data.permute(0, 2, 1)\n",
        "              batch_size = data.size()[0]\n",
        "              opt.zero_grad()\n",
        "              logits1, logits2 = model(data) ## ADD TWO LOGITS\n",
        "\n",
        "              loss1, loss2 = criterion(logits1, label.long()), criterion(logits2, label.long())\n",
        "              loss1Total_v += loss1.item()\n",
        "              loss2Total_v += loss2.item()\n",
        "              valLoss += 0.5*loss1.item() + 0.5*loss2.item()\n",
        "\n",
        "              _, predicted1 = torch.max(logits1, 1)\n",
        "              _, predicted2 = torch.max(logits2, 1)\n",
        "              acc1 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted1.detach().cpu().numpy())\n",
        "              acc2 = metrics.accuracy_score(label.detach().cpu().numpy(), predicted2.detach().cpu().numpy())\n",
        "\n",
        "              acc1Total_v += acc1\n",
        "              acc2Total_v += acc2\n",
        "              valAcc += 0.5*acc1 + 0.5*acc2\n",
        "\n",
        "            loss1Total_v = loss1Total_v/len(validation_loader)\n",
        "            loss2Total_v = loss2Total_v/len(validation_loader)\n",
        "            valLoss = valLoss/len(validation_loader)\n",
        "            acc1Total_v = acc1Total_v/len(validation_loader)\n",
        "            acc2Total_v = acc2Total_v/len(validation_loader)\n",
        "            valAcc = valAcc/len(validation_loader)\n",
        "\n",
        "            history[\"1\"][\"validation\"][\"loss\"].append(loss1Total_v)\n",
        "            history[\"1\"][\"validation\"][\"accuracy\"].append(acc1Total_v)\n",
        "            history[\"2\"][\"validation\"][\"loss\"].append(loss2Total_v)\n",
        "            history[\"2\"][\"validation\"][\"accuracy\"].append(acc2Total_v)\n",
        "            history[\"T\"][\"validation\"][\"loss\"].append(valLoss)\n",
        "            history[\"T\"][\"validation\"][\"accuracy\"].append(valAcc)\n",
        "\n",
        "          print(\", validLoss: {:0.3f}, validAcc: {:0.3f}\"\n",
        "                  .format(valLoss, valAcc))\n",
        "#############Save best performing model if current test accuracy outperforms the recorded best accuracy#############\n",
        "          if valLoss <= best_loss:\n",
        "            # Save the model with the lowest validation loss.\n",
        "            best_loss = valLoss\n",
        "            torch.save(model.state_dict(), 'checkpoints/%s/models/model.pth' % args.exp_name)\n",
        "            print(\"Model Saved!\")\n",
        "#####################################################################################################################\n",
        "\n",
        "########################Stop training if validation loss is increasing#############################\n",
        "          if valLoss >= preValLoss:\n",
        "            eStopCounter += 1\n",
        "            if eStopCounter >= eStopThreshold:\n",
        "              print(\"Training Stopped!\")\n",
        "              break;\n",
        "          else:\n",
        "            eStopCounter = 0\n",
        "          preValLoss = valLoss\n",
        "        else:\n",
        "          print(\"\")\n",
        "#####################################################################################################\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy1DG9OAlwYg"
      },
      "outputs": [],
      "source": [
        "train_demo = ModelNet40(1024)\n",
        "test_demo = ModelNet40(1024, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wNYf788EJk2"
      },
      "outputs": [],
      "source": [
        "#Initialize your hyperparametr arguments\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N05X14SdBmwb",
        "outputId": "25eac9ef-6410-4019-ad79-2358ceda57d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if not os.path.exists('checkpoints'):\n",
        "  os.makedirs('checkpoints')\n",
        "if not os.path.exists('checkpoints/'+args.exp_name):\n",
        "  os.makedirs('checkpoints/'+args.exp_name)\n",
        "if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):\n",
        "  os.makedirs('checkpoints/'+args.exp_name+'/'+'models')\n",
        "os.system('cp main.py checkpoints'+'/'+args.exp_name+'/'+'main.py.backup')\n",
        "os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
        "os.system('cp util.py checkpoints' + '/' + args.exp_name + '/' + 'util.py.backup')\n",
        "os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKeuCJWJ_Mr9"
      },
      "outputs": [],
      "source": [
        "io = IOStream('checkpoints/' + args.exp_name + '/run.log')\n",
        "args.no_cuda = False\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpAkmrEq0-y",
        "outputId": "6530a29f-320f-44c4-e356-09588f11eb0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "eeModel_E1                               --\n",
            "├─BatchNorm2d: 1-1                       128\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─BatchNorm2d: 1-3                       256\n",
            "├─BatchNorm2d: 1-4                       512\n",
            "├─BatchNorm1d: 1-5                       2,048\n",
            "├─Sequential: 1-6                        128\n",
            "│    └─Conv2d: 2-1                       384\n",
            "│    └─BatchNorm2d: 2-2                  (recursive)\n",
            "│    └─LeakyReLU: 2-3                    --\n",
            "├─Sequential: 1-7                        128\n",
            "│    └─Conv2d: 2-4                       8,192\n",
            "│    └─BatchNorm2d: 2-5                  (recursive)\n",
            "│    └─LeakyReLU: 2-6                    --\n",
            "├─Sequential: 1-8                        256\n",
            "│    └─Conv2d: 2-7                       16,384\n",
            "│    └─BatchNorm2d: 2-8                  (recursive)\n",
            "│    └─LeakyReLU: 2-9                    --\n",
            "├─Sequential: 1-9                        512\n",
            "│    └─Conv2d: 2-10                      65,536\n",
            "│    └─BatchNorm2d: 2-11                 (recursive)\n",
            "│    └─LeakyReLU: 2-12                   --\n",
            "├─Sequential: 1-10                       --\n",
            "│    └─Linear: 2-13                      524,288\n",
            "│    └─BatchNorm1d: 2-14                 1,024\n",
            "│    └─LeakyReLU: 2-15                   --\n",
            "│    └─Dropout: 2-16                     --\n",
            "│    └─Linear: 2-17                      131,328\n",
            "│    └─BatchNorm1d: 2-18                 512\n",
            "│    └─LeakyReLU: 2-19                   --\n",
            "│    └─Dropout: 2-20                     --\n",
            "│    └─Linear: 2-21                      10,280\n",
            "├─Sequential: 1-11                       2,048\n",
            "│    └─Conv1d: 2-22                      524,288\n",
            "│    └─BatchNorm1d: 2-23                 (recursive)\n",
            "│    └─LeakyReLU: 2-24                   --\n",
            "├─Sequential: 1-12                       --\n",
            "│    └─Linear: 2-25                      1,048,576\n",
            "│    └─BatchNorm1d: 2-26                 1,024\n",
            "│    └─LeakyReLU: 2-27                   --\n",
            "│    └─Dropout: 2-28                     --\n",
            "│    └─Linear: 2-29                      131,328\n",
            "│    └─BatchNorm1d: 2-30                 512\n",
            "│    └─LeakyReLU: 2-31                   --\n",
            "│    └─Dropout: 2-32                     --\n",
            "│    └─Linear: 2-33                      10,280\n",
            "=================================================================\n",
            "Total params: 2,480,080\n",
            "Trainable params: 2,480,080\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 --> trainLoss: 2.979, trainAcc: 0.369, validLoss: 2.502, validAcc: 0.503\n",
            "Model Saved!\n",
            "epoch 2 --> trainLoss: 2.383, trainAcc: 0.564, validLoss: 2.168, validAcc: 0.651\n",
            "Model Saved!\n",
            "epoch 3 --> trainLoss: 2.228, trainAcc: 0.625, validLoss: 2.123, validAcc: 0.678\n",
            "Model Saved!\n",
            "epoch 4 --> trainLoss: 2.117, trainAcc: 0.674, validLoss: 2.011, validAcc: 0.708\n",
            "Model Saved!\n",
            "epoch 5 --> trainLoss: 2.047, trainAcc: 0.699, validLoss: 2.047, validAcc: 0.682\n",
            "Model Saved!\n",
            "epoch 6 --> trainLoss: 2.005, trainAcc: 0.723, validLoss: 1.893, validAcc: 0.762\n",
            "Model Saved!\n",
            "epoch 7 --> trainLoss: 1.962, trainAcc: 0.742, validLoss: 1.856, validAcc: 0.779\n",
            "Model Saved!\n",
            "epoch 8 --> trainLoss: 1.928, trainAcc: 0.756, validLoss: 1.858, validAcc: 0.791\n",
            "Model Saved!\n",
            "epoch 9 --> trainLoss: 1.894, trainAcc: 0.769, validLoss: 1.884, validAcc: 0.768\n",
            "Model Saved!\n",
            "epoch 10 --> trainLoss: 1.870, trainAcc: 0.778, validLoss: 1.853, validAcc: 0.760\n",
            "Model Saved!\n",
            "epoch 11 --> trainLoss: 1.853, trainAcc: 0.787, validLoss: 1.785, validAcc: 0.806\n",
            "Model Saved!\n",
            "epoch 12 --> trainLoss: 1.826, trainAcc: 0.801, validLoss: 1.759, validAcc: 0.812\n",
            "Model Saved!\n",
            "epoch 13 --> trainLoss: 1.817, trainAcc: 0.801, validLoss: 1.741, validAcc: 0.815\n",
            "Model Saved!\n",
            "epoch 14 --> trainLoss: 1.798, trainAcc: 0.812, validLoss: 1.783, validAcc: 0.806\n",
            "Model Saved!\n",
            "epoch 15 --> trainLoss: 1.790, trainAcc: 0.813, validLoss: 1.759, validAcc: 0.818\n",
            "Model Saved!\n",
            "epoch 16 --> trainLoss: 1.787, trainAcc: 0.813, validLoss: 1.782, validAcc: 0.817\n",
            "Model Saved!\n",
            "epoch 17 --> trainLoss: 1.773, trainAcc: 0.822, validLoss: 1.722, validAcc: 0.820\n",
            "Model Saved!\n",
            "epoch 18 --> trainLoss: 1.758, trainAcc: 0.826, validLoss: 1.701, validAcc: 0.836\n",
            "Model Saved!\n",
            "epoch 19 --> trainLoss: 1.748, trainAcc: 0.835, validLoss: 1.665, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 20 --> trainLoss: 1.734, trainAcc: 0.838, validLoss: 1.690, validAcc: 0.848\n",
            "Model Saved!\n",
            "epoch 21 --> trainLoss: 1.733, trainAcc: 0.842, validLoss: 1.698, validAcc: 0.835\n",
            "Model Saved!\n",
            "epoch 22 --> trainLoss: 1.716, trainAcc: 0.848, validLoss: 1.767, validAcc: 0.813\n",
            "Model Saved!\n",
            "epoch 23 --> trainLoss: 1.728, trainAcc: 0.838, validLoss: 1.675, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 24 --> trainLoss: 1.710, trainAcc: 0.850, validLoss: 1.657, validAcc: 0.850\n",
            "Model Saved!\n",
            "epoch 25 --> trainLoss: 1.714, trainAcc: 0.848, validLoss: 1.656, validAcc: 0.851\n",
            "Model Saved!\n",
            "epoch 26 --> trainLoss: 1.702, trainAcc: 0.853, validLoss: 1.643, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 27 --> trainLoss: 1.692, trainAcc: 0.855, validLoss: 1.632, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 28 --> trainLoss: 1.696, trainAcc: 0.852, validLoss: 1.685, validAcc: 0.834\n",
            "Model Saved!\n",
            "epoch 29 --> trainLoss: 1.690, trainAcc: 0.859, validLoss: 1.720, validAcc: 0.831\n",
            "Model Saved!\n",
            "epoch 30 --> trainLoss: 1.684, trainAcc: 0.860, validLoss: 1.635, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 31 --> trainLoss: 1.685, trainAcc: 0.859, validLoss: 1.630, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 32 --> trainLoss: 1.673, trainAcc: 0.864, validLoss: 1.643, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 33 --> trainLoss: 1.674, trainAcc: 0.863, validLoss: 1.657, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 34 --> trainLoss: 1.669, trainAcc: 0.867, validLoss: 1.659, validAcc: 0.849\n",
            "Model Saved!\n",
            "epoch 35 --> trainLoss: 1.667, trainAcc: 0.867, validLoss: 1.627, validAcc: 0.870\n",
            "Model Saved!\n",
            "epoch 36 --> trainLoss: 1.662, trainAcc: 0.869, validLoss: 1.670, validAcc: 0.843\n",
            "Model Saved!\n",
            "epoch 37 --> trainLoss: 1.655, trainAcc: 0.871, validLoss: 1.612, validAcc: 0.871\n",
            "Model Saved!\n",
            "epoch 38 --> trainLoss: 1.657, trainAcc: 0.869, validLoss: 1.591, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 39 --> trainLoss: 1.649, trainAcc: 0.872, validLoss: 1.632, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 40 --> trainLoss: 1.646, trainAcc: 0.876, validLoss: 1.609, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 41 --> trainLoss: 1.652, trainAcc: 0.874, validLoss: 1.606, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 42 --> trainLoss: 1.637, trainAcc: 0.882, validLoss: 1.622, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 43 --> trainLoss: 1.632, trainAcc: 0.882, validLoss: 1.628, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 44 --> trainLoss: 1.628, trainAcc: 0.884, validLoss: 1.631, validAcc: 0.860\n",
            "Model Saved!\n",
            "epoch 45 --> trainLoss: 1.626, trainAcc: 0.883, validLoss: 1.637, validAcc: 0.857\n",
            "Model Saved!\n",
            "epoch 46 --> trainLoss: 1.630, trainAcc: 0.883, validLoss: 1.604, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 47 --> trainLoss: 1.635, trainAcc: 0.879, validLoss: 1.637, validAcc: 0.861\n",
            "Model Saved!\n",
            "epoch 48 --> trainLoss: 1.625, trainAcc: 0.886, validLoss: 1.599, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 49 --> trainLoss: 1.621, trainAcc: 0.889, validLoss: 1.639, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 50 --> trainLoss: 1.625, trainAcc: 0.885, validLoss: 1.621, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 51 --> trainLoss: 1.619, trainAcc: 0.885, validLoss: 1.618, validAcc: 0.872\n",
            "Model Saved!\n",
            "epoch 52 --> trainLoss: 1.610, trainAcc: 0.889, validLoss: 1.623, validAcc: 0.862\n",
            "Model Saved!\n",
            "epoch 53 --> trainLoss: 1.617, trainAcc: 0.886, validLoss: 1.590, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 54 --> trainLoss: 1.609, trainAcc: 0.892, validLoss: 1.691, validAcc: 0.844\n",
            "Model Saved!\n",
            "epoch 55 --> trainLoss: 1.613, trainAcc: 0.887, validLoss: 1.586, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 56 --> trainLoss: 1.606, trainAcc: 0.893, validLoss: 1.608, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 57 --> trainLoss: 1.603, trainAcc: 0.895, validLoss: 1.605, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 58 --> trainLoss: 1.602, trainAcc: 0.895, validLoss: 1.572, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 59 --> trainLoss: 1.598, trainAcc: 0.895, validLoss: 1.582, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 60 --> trainLoss: 1.595, trainAcc: 0.896, validLoss: 1.610, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 61 --> trainLoss: 1.598, trainAcc: 0.893, validLoss: 1.606, validAcc: 0.871\n",
            "Model Saved!\n",
            "epoch 62 --> trainLoss: 1.594, trainAcc: 0.899, validLoss: 1.627, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 63 --> trainLoss: 1.595, trainAcc: 0.897, validLoss: 1.622, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 64 --> trainLoss: 1.587, trainAcc: 0.899, validLoss: 1.667, validAcc: 0.859\n",
            "Model Saved!\n",
            "epoch 65 --> trainLoss: 1.592, trainAcc: 0.899, validLoss: 1.590, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 66 --> trainLoss: 1.588, trainAcc: 0.899, validLoss: 1.620, validAcc: 0.866\n",
            "Model Saved!\n",
            "epoch 67 --> trainLoss: 1.581, trainAcc: 0.902, validLoss: 1.618, validAcc: 0.868\n",
            "Model Saved!\n",
            "epoch 68 --> trainLoss: 1.582, trainAcc: 0.902, validLoss: 1.594, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 69 --> trainLoss: 1.585, trainAcc: 0.900, validLoss: 1.584, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 70 --> trainLoss: 1.576, trainAcc: 0.907, validLoss: 1.572, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 71 --> trainLoss: 1.574, trainAcc: 0.907, validLoss: 1.593, validAcc: 0.877\n",
            "Model Saved!\n",
            "epoch 72 --> trainLoss: 1.585, trainAcc: 0.899, validLoss: 1.625, validAcc: 0.864\n",
            "Model Saved!\n",
            "epoch 73 --> trainLoss: 1.572, trainAcc: 0.909, validLoss: 1.591, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 74 --> trainLoss: 1.572, trainAcc: 0.906, validLoss: 1.612, validAcc: 0.884\n",
            "Model Saved!\n",
            "epoch 75 --> trainLoss: 1.572, trainAcc: 0.909, validLoss: 1.592, validAcc: 0.875\n",
            "Model Saved!\n",
            "epoch 76 --> trainLoss: 1.569, trainAcc: 0.907, validLoss: 1.611, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 77 --> trainLoss: 1.562, trainAcc: 0.911, validLoss: 1.582, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 78 --> trainLoss: 1.565, trainAcc: 0.912, validLoss: 1.620, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 79 --> trainLoss: 1.563, trainAcc: 0.909, validLoss: 1.601, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 80 --> trainLoss: 1.565, trainAcc: 0.910, validLoss: 1.572, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 81 --> trainLoss: 1.556, trainAcc: 0.915, validLoss: 1.583, validAcc: 0.874\n",
            "Model Saved!\n",
            "epoch 82 --> trainLoss: 1.574, trainAcc: 0.907, validLoss: 1.546, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 83 --> trainLoss: 1.554, trainAcc: 0.916, validLoss: 1.598, validAcc: 0.867\n",
            "Model Saved!\n",
            "epoch 84 --> trainLoss: 1.554, trainAcc: 0.910, validLoss: 1.582, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 85 --> trainLoss: 1.547, trainAcc: 0.916, validLoss: 1.576, validAcc: 0.876\n",
            "Model Saved!\n",
            "epoch 86 --> trainLoss: 1.552, trainAcc: 0.916, validLoss: 1.572, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 87 --> trainLoss: 1.547, trainAcc: 0.915, validLoss: 1.594, validAcc: 0.879\n",
            "Model Saved!\n",
            "epoch 88 --> trainLoss: 1.547, trainAcc: 0.917, validLoss: 1.572, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 89 --> trainLoss: 1.545, trainAcc: 0.917, validLoss: 1.576, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 90 --> trainLoss: 1.542, trainAcc: 0.919, validLoss: 1.550, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 91 --> trainLoss: 1.541, trainAcc: 0.920, validLoss: 1.587, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 92 --> trainLoss: 1.546, trainAcc: 0.916, validLoss: 1.581, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 93 --> trainLoss: 1.540, trainAcc: 0.920, validLoss: 1.573, validAcc: 0.882\n",
            "Model Saved!\n",
            "epoch 94 --> trainLoss: 1.542, trainAcc: 0.919, validLoss: 1.582, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 95 --> trainLoss: 1.539, trainAcc: 0.921, validLoss: 1.560, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 96 --> trainLoss: 1.537, trainAcc: 0.920, validLoss: 1.540, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 97 --> trainLoss: 1.531, trainAcc: 0.921, validLoss: 1.574, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 98 --> trainLoss: 1.532, trainAcc: 0.923, validLoss: 1.577, validAcc: 0.881\n",
            "Model Saved!\n",
            "epoch 99 --> trainLoss: 1.529, trainAcc: 0.924, validLoss: 1.566, validAcc: 0.883\n",
            "Model Saved!\n",
            "epoch 100 --> trainLoss: 1.532, trainAcc: 0.924, validLoss: 1.558, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 101 --> trainLoss: 1.531, trainAcc: 0.922, validLoss: 1.554, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 102 --> trainLoss: 1.518, trainAcc: 0.929, validLoss: 1.632, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 103 --> trainLoss: 1.531, trainAcc: 0.925, validLoss: 1.545, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 104 --> trainLoss: 1.527, trainAcc: 0.924, validLoss: 1.549, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 105 --> trainLoss: 1.524, trainAcc: 0.927, validLoss: 1.545, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 106 --> trainLoss: 1.518, trainAcc: 0.927, validLoss: 1.564, validAcc: 0.885\n",
            "Model Saved!\n",
            "epoch 107 --> trainLoss: 1.519, trainAcc: 0.926, validLoss: 1.536, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 108 --> trainLoss: 1.515, trainAcc: 0.929, validLoss: 1.549, validAcc: 0.891\n",
            "Model Saved!\n",
            "epoch 109 --> trainLoss: 1.516, trainAcc: 0.929, validLoss: 1.555, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 110 --> trainLoss: 1.514, trainAcc: 0.930, validLoss: 1.574, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 111 --> trainLoss: 1.516, trainAcc: 0.930, validLoss: 1.592, validAcc: 0.878\n",
            "Model Saved!\n",
            "epoch 112 --> trainLoss: 1.515, trainAcc: 0.930, validLoss: 1.581, validAcc: 0.869\n",
            "Model Saved!\n",
            "epoch 113 --> trainLoss: 1.515, trainAcc: 0.928, validLoss: 1.530, validAcc: 0.897\n",
            "Model Saved!\n",
            "epoch 114 --> trainLoss: 1.511, trainAcc: 0.930, validLoss: 1.520, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 115 --> trainLoss: 1.505, trainAcc: 0.933, validLoss: 1.563, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 116 --> trainLoss: 1.503, trainAcc: 0.937, validLoss: 1.567, validAcc: 0.886\n",
            "Model Saved!\n",
            "epoch 117 --> trainLoss: 1.498, trainAcc: 0.939, validLoss: 1.530, validAcc: 0.892\n",
            "Model Saved!\n",
            "epoch 118 --> trainLoss: 1.499, trainAcc: 0.937, validLoss: 1.554, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 119 --> trainLoss: 1.497, trainAcc: 0.936, validLoss: 1.539, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 120 --> trainLoss: 1.499, trainAcc: 0.935, validLoss: 1.532, validAcc: 0.894\n",
            "Model Saved!\n",
            "epoch 121 --> trainLoss: 1.498, trainAcc: 0.936, validLoss: 1.582, validAcc: 0.873\n",
            "Model Saved!\n",
            "epoch 122 --> trainLoss: 1.494, trainAcc: 0.938, validLoss: 1.533, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 123 --> trainLoss: 1.495, trainAcc: 0.939, validLoss: 1.537, validAcc: 0.888\n",
            "Model Saved!\n",
            "epoch 124 --> trainLoss: 1.496, trainAcc: 0.938, validLoss: 1.550, validAcc: 0.889\n",
            "Model Saved!\n",
            "epoch 125 --> trainLoss: 1.494, trainAcc: 0.938, validLoss: 1.544, validAcc: 0.887\n",
            "Model Saved!\n",
            "epoch 126 --> trainLoss: 1.493, trainAcc: 0.937, validLoss: 1.514, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 127 --> trainLoss: 1.485, trainAcc: 0.942, validLoss: 1.515, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 128 --> trainLoss: 1.487, trainAcc: 0.939, validLoss: 1.524, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 129 --> trainLoss: 1.487, trainAcc: 0.941, validLoss: 1.541, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 130 --> trainLoss: 1.479, trainAcc: 0.945, validLoss: 1.523, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 131 --> trainLoss: 1.481, trainAcc: 0.943, validLoss: 1.530, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 132 --> trainLoss: 1.481, trainAcc: 0.944, validLoss: 1.534, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 133 --> trainLoss: 1.475, trainAcc: 0.945, validLoss: 1.529, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 134 --> trainLoss: 1.479, trainAcc: 0.944, validLoss: 1.527, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 135 --> trainLoss: 1.476, trainAcc: 0.945, validLoss: 1.514, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 136 --> trainLoss: 1.477, trainAcc: 0.945, validLoss: 1.540, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 137 --> trainLoss: 1.472, trainAcc: 0.947, validLoss: 1.529, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 138 --> trainLoss: 1.474, trainAcc: 0.945, validLoss: 1.537, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 139 --> trainLoss: 1.473, trainAcc: 0.945, validLoss: 1.518, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 140 --> trainLoss: 1.470, trainAcc: 0.947, validLoss: 1.514, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 141 --> trainLoss: 1.464, trainAcc: 0.950, validLoss: 1.522, validAcc: 0.896\n",
            "Model Saved!\n",
            "epoch 142 --> trainLoss: 1.461, trainAcc: 0.950, validLoss: 1.517, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 143 --> trainLoss: 1.460, trainAcc: 0.952, validLoss: 1.564, validAcc: 0.880\n",
            "Model Saved!\n",
            "epoch 144 --> trainLoss: 1.460, trainAcc: 0.951, validLoss: 1.510, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 145 --> trainLoss: 1.456, trainAcc: 0.952, validLoss: 1.547, validAcc: 0.890\n",
            "Model Saved!\n",
            "epoch 146 --> trainLoss: 1.457, trainAcc: 0.952, validLoss: 1.540, validAcc: 0.893\n",
            "Model Saved!\n",
            "epoch 147 --> trainLoss: 1.459, trainAcc: 0.952, validLoss: 1.510, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 148 --> trainLoss: 1.452, trainAcc: 0.955, validLoss: 1.516, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 149 --> trainLoss: 1.453, trainAcc: 0.955, validLoss: 1.512, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 150 --> trainLoss: 1.456, trainAcc: 0.953, validLoss: 1.536, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 151 --> trainLoss: 1.450, trainAcc: 0.956, validLoss: 1.499, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 152 --> trainLoss: 1.445, trainAcc: 0.958, validLoss: 1.513, validAcc: 0.902\n",
            "Model Saved!\n",
            "epoch 153 --> trainLoss: 1.446, trainAcc: 0.957, validLoss: 1.509, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 154 --> trainLoss: 1.445, trainAcc: 0.957, validLoss: 1.499, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 155 --> trainLoss: 1.440, trainAcc: 0.958, validLoss: 1.533, validAcc: 0.895\n",
            "Model Saved!\n",
            "epoch 156 --> trainLoss: 1.446, trainAcc: 0.957, validLoss: 1.516, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 157 --> trainLoss: 1.442, trainAcc: 0.957, validLoss: 1.506, validAcc: 0.900\n",
            "Model Saved!\n",
            "epoch 158 --> trainLoss: 1.441, trainAcc: 0.961, validLoss: 1.493, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 159 --> trainLoss: 1.437, trainAcc: 0.960, validLoss: 1.503, validAcc: 0.899\n",
            "Model Saved!\n",
            "epoch 160 --> trainLoss: 1.435, trainAcc: 0.960, validLoss: 1.504, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 161 --> trainLoss: 1.430, trainAcc: 0.964, validLoss: 1.507, validAcc: 0.898\n",
            "Model Saved!\n",
            "epoch 162 --> trainLoss: 1.436, trainAcc: 0.961, validLoss: 1.481, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 163 --> trainLoss: 1.432, trainAcc: 0.963, validLoss: 1.483, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 164 --> trainLoss: 1.430, trainAcc: 0.963, validLoss: 1.501, validAcc: 0.905\n",
            "Model Saved!\n",
            "epoch 165 --> trainLoss: 1.430, trainAcc: 0.963, validLoss: 1.491, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 166 --> trainLoss: 1.429, trainAcc: 0.962, validLoss: 1.498, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 167 --> trainLoss: 1.426, trainAcc: 0.966, validLoss: 1.484, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 168 --> trainLoss: 1.424, trainAcc: 0.964, validLoss: 1.490, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 169 --> trainLoss: 1.420, trainAcc: 0.969, validLoss: 1.517, validAcc: 0.901\n",
            "Model Saved!\n",
            "epoch 170 --> trainLoss: 1.422, trainAcc: 0.966, validLoss: 1.490, validAcc: 0.904\n",
            "Model Saved!\n",
            "epoch 171 --> trainLoss: 1.415, trainAcc: 0.969, validLoss: 1.478, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 172 --> trainLoss: 1.420, trainAcc: 0.966, validLoss: 1.494, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 173 --> trainLoss: 1.417, trainAcc: 0.969, validLoss: 1.476, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 174 --> trainLoss: 1.416, trainAcc: 0.969, validLoss: 1.494, validAcc: 0.907\n",
            "Model Saved!\n",
            "epoch 175 --> trainLoss: 1.416, trainAcc: 0.968, validLoss: 1.492, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 176 --> trainLoss: 1.412, trainAcc: 0.970, validLoss: 1.484, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 177 --> trainLoss: 1.407, trainAcc: 0.972, validLoss: 1.480, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 178 --> trainLoss: 1.409, trainAcc: 0.971, validLoss: 1.482, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 179 --> trainLoss: 1.409, trainAcc: 0.970, validLoss: 1.476, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 180 --> trainLoss: 1.408, trainAcc: 0.972, validLoss: 1.477, validAcc: 0.908\n",
            "Model Saved!\n",
            "epoch 181 --> trainLoss: 1.405, trainAcc: 0.973, validLoss: 1.483, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 182 --> trainLoss: 1.406, trainAcc: 0.972, validLoss: 1.474, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 183 --> trainLoss: 1.406, trainAcc: 0.972, validLoss: 1.491, validAcc: 0.903\n",
            "Model Saved!\n",
            "epoch 184 --> trainLoss: 1.403, trainAcc: 0.974, validLoss: 1.473, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 185 --> trainLoss: 1.400, trainAcc: 0.976, validLoss: 1.482, validAcc: 0.906\n",
            "Model Saved!\n",
            "epoch 186 --> trainLoss: 1.393, trainAcc: 0.976, validLoss: 1.479, validAcc: 0.909\n",
            "Model Saved!\n",
            "epoch 187 --> trainLoss: 1.398, trainAcc: 0.974, validLoss: 1.475, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 188 --> trainLoss: 1.397, trainAcc: 0.976, validLoss: 1.479, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 189 --> trainLoss: 1.393, trainAcc: 0.976, validLoss: 1.481, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 190 --> trainLoss: 1.394, trainAcc: 0.977, validLoss: 1.466, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 191 --> trainLoss: 1.391, trainAcc: 0.978, validLoss: 1.472, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 192 --> trainLoss: 1.391, trainAcc: 0.977, validLoss: 1.482, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 193 --> trainLoss: 1.388, trainAcc: 0.979, validLoss: 1.472, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 194 --> trainLoss: 1.391, trainAcc: 0.977, validLoss: 1.470, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 195 --> trainLoss: 1.386, trainAcc: 0.980, validLoss: 1.466, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 196 --> trainLoss: 1.388, trainAcc: 0.978, validLoss: 1.471, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 197 --> trainLoss: 1.387, trainAcc: 0.979, validLoss: 1.472, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 198 --> trainLoss: 1.384, trainAcc: 0.979, validLoss: 1.474, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 199 --> trainLoss: 1.386, trainAcc: 0.980, validLoss: 1.475, validAcc: 0.910\n",
            "Model Saved!\n",
            "epoch 200 --> trainLoss: 1.383, trainAcc: 0.979, validLoss: 1.472, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 201 --> trainLoss: 1.384, trainAcc: 0.980, validLoss: 1.463, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 202 --> trainLoss: 1.383, trainAcc: 0.980, validLoss: 1.465, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 203 --> trainLoss: 1.381, trainAcc: 0.981, validLoss: 1.466, validAcc: 0.911\n",
            "Model Saved!\n",
            "epoch 204 --> trainLoss: 1.376, trainAcc: 0.982, validLoss: 1.465, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 205 --> trainLoss: 1.377, trainAcc: 0.981, validLoss: 1.461, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 206 --> trainLoss: 1.378, trainAcc: 0.980, validLoss: 1.465, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 207 --> trainLoss: 1.376, trainAcc: 0.982, validLoss: 1.464, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 208 --> trainLoss: 1.375, trainAcc: 0.983, validLoss: 1.465, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 209 --> trainLoss: 1.376, trainAcc: 0.982, validLoss: 1.465, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 210 --> trainLoss: 1.376, trainAcc: 0.982, validLoss: 1.465, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 211 --> trainLoss: 1.374, trainAcc: 0.983, validLoss: 1.464, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 212 --> trainLoss: 1.370, trainAcc: 0.984, validLoss: 1.464, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 213 --> trainLoss: 1.370, trainAcc: 0.986, validLoss: 1.465, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 214 --> trainLoss: 1.374, trainAcc: 0.983, validLoss: 1.463, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 215 --> trainLoss: 1.370, trainAcc: 0.984, validLoss: 1.459, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 216 --> trainLoss: 1.368, trainAcc: 0.985, validLoss: 1.459, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 217 --> trainLoss: 1.366, trainAcc: 0.987, validLoss: 1.462, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 218 --> trainLoss: 1.370, trainAcc: 0.984, validLoss: 1.459, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 219 --> trainLoss: 1.367, trainAcc: 0.987, validLoss: 1.461, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 220 --> trainLoss: 1.366, trainAcc: 0.987, validLoss: 1.465, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 221 --> trainLoss: 1.365, trainAcc: 0.985, validLoss: 1.463, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 222 --> trainLoss: 1.366, trainAcc: 0.987, validLoss: 1.456, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 223 --> trainLoss: 1.365, trainAcc: 0.985, validLoss: 1.457, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 224 --> trainLoss: 1.364, trainAcc: 0.986, validLoss: 1.464, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 225 --> trainLoss: 1.363, trainAcc: 0.985, validLoss: 1.459, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 226 --> trainLoss: 1.362, trainAcc: 0.988, validLoss: 1.456, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 227 --> trainLoss: 1.363, trainAcc: 0.987, validLoss: 1.458, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 228 --> trainLoss: 1.364, trainAcc: 0.987, validLoss: 1.460, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 229 --> trainLoss: 1.362, trainAcc: 0.987, validLoss: 1.455, validAcc: 0.919\n",
            "Model Saved!\n",
            "epoch 230 --> trainLoss: 1.362, trainAcc: 0.988, validLoss: 1.459, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 231 --> trainLoss: 1.363, trainAcc: 0.987, validLoss: 1.457, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 232 --> trainLoss: 1.362, trainAcc: 0.987, validLoss: 1.457, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 233 --> trainLoss: 1.362, trainAcc: 0.986, validLoss: 1.461, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 234 --> trainLoss: 1.361, trainAcc: 0.987, validLoss: 1.455, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 235 --> trainLoss: 1.363, trainAcc: 0.986, validLoss: 1.457, validAcc: 0.918\n",
            "Model Saved!\n",
            "epoch 236 --> trainLoss: 1.358, trainAcc: 0.988, validLoss: 1.465, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 237 --> trainLoss: 1.360, trainAcc: 0.988, validLoss: 1.462, validAcc: 0.912\n",
            "Model Saved!\n",
            "epoch 238 --> trainLoss: 1.360, trainAcc: 0.987, validLoss: 1.452, validAcc: 0.920\n",
            "Model Saved!\n",
            "epoch 239 --> trainLoss: 1.359, trainAcc: 0.987, validLoss: 1.458, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 240 --> trainLoss: 1.358, trainAcc: 0.988, validLoss: 1.459, validAcc: 0.914\n",
            "Model Saved!\n",
            "epoch 241 --> trainLoss: 1.358, trainAcc: 0.989, validLoss: 1.461, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 242 --> trainLoss: 1.357, trainAcc: 0.989, validLoss: 1.458, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 243 --> trainLoss: 1.359, trainAcc: 0.988, validLoss: 1.460, validAcc: 0.915\n",
            "Model Saved!\n",
            "epoch 244 --> trainLoss: 1.357, trainAcc: 0.990, validLoss: 1.465, validAcc: 0.916\n",
            "Model Saved!\n",
            "epoch 245 --> trainLoss: 1.357, trainAcc: 0.990, validLoss: 1.464, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 246 --> trainLoss: 1.358, trainAcc: 0.988, validLoss: 1.457, validAcc: 0.921\n",
            "Model Saved!\n",
            "epoch 247 --> trainLoss: 1.359, trainAcc: 0.988, validLoss: 1.460, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 248 --> trainLoss: 1.355, trainAcc: 0.989, validLoss: 1.455, validAcc: 0.917\n",
            "Model Saved!\n",
            "epoch 249 --> trainLoss: 1.360, trainAcc: 0.987, validLoss: 1.458, validAcc: 0.913\n",
            "Model Saved!\n",
            "epoch 250 --> trainLoss: 1.357, trainAcc: 0.990, validLoss: 1.463, validAcc: 0.914\n",
            "Model Saved!\n"
          ]
        }
      ],
      "source": [
        "model, history = train(args, io)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2rDIN0H0j4W"
      },
      "outputs": [],
      "source": [
        "def infer(sLoader, threshold=0.05, verbose=False):\n",
        "    \"\"\"\n",
        "    @Inference: we compare the output confidence (entropy) at a branch with a certain threshold\n",
        "\n",
        "    Parameters:\n",
        "    sLoader (DataLoader): Iterable over the dataset, provides batches of (inputs, groundTruth).\n",
        "    threshold (float): Entropy threshold used to decide the stopping point for shortBranch.\n",
        "    verbose (bool): If True, prints entropy values when they are below the threshold.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the recording dictionary of accuracies, list of predicted labels, and overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Softmax layer initialization for converting outputs to probability distributions\n",
        "    softmaxLayer = nn.Softmax(dim=1)\n",
        "\n",
        "    # Initialize accuracy and list to hold predictions\n",
        "    acc = 0\n",
        "    predicted = []\n",
        "\n",
        "    # Dictionary to keep track of accuracy per branch (shortBranch: 0, longBranch: 1)\n",
        "    recorder = {x: [] for x in range(2)}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disables gradient calculations for inference, saving memory and computations\n",
        "    with torch.no_grad():\n",
        "        for inputs, gTruth in sLoader:\n",
        "            # Move input and ground truth data to GPU\n",
        "            inputs, gTruth = inputs.to('cuda'), gTruth.to('cuda')\n",
        "            batch_size = inputs.size()[0] # Retrieve your batch size\n",
        "            # Permute dimensions of inputs to fit model's expected input shape\n",
        "            inputs = inputs.permute(0, 2, 1)\n",
        "            # Process inputs through the base part of the model\n",
        "            x_baseModelconv1 = model.baseModelconv1(get_graph_feature(inputs, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv2 = model.baseModelconv2(get_graph_feature(x_baseModelconv1, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv3 = model.baseModelconv3(get_graph_feature(x_baseModelconv2, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x_baseModelconv4 = model.baseModelconv4(get_graph_feature(x_baseModelconv3, k=args.k)).max(dim=-1, keepdim=False)[0]\n",
        "            x = torch.cat((x_baseModelconv1, x_baseModelconv2, x_baseModelconv3, x_baseModelconv4), dim=1)\n",
        "            # Iterate through each sample in the batch\n",
        "            for iSample in range(x.shape[0]):\n",
        "                # Process inputs through the short branch of the model\n",
        "                out1 = model.get_short_branch_output(x[iSample:iSample+1], 1)\n",
        "                # Apply softmax to get probabilities\n",
        "                y = softmaxLayer(out1)\n",
        "                # Calculate the entropy of the output probabilities\n",
        "                e = entropy(y.detach().cpu().numpy().squeeze(), base=10)\n",
        "                # Check if entropy is below the threshold\n",
        "                if e <= threshold:\n",
        "                    if verbose:\n",
        "                        print(e)  # Optionally print the entropy\n",
        "                    _, label = torch.max(out1, 1)\n",
        "                    predicted.append(label)\n",
        "                    if label == gTruth[iSample].item():\n",
        "                        recorder[0].append(1)\n",
        "                        acc += 1\n",
        "                    else:\n",
        "                        recorder[0].append(0)\n",
        "                    continue\n",
        "\n",
        "                out2 = model.get_long_branch_output(x_baseModelconv1[iSample:iSample+1], x_baseModelconv2[iSample:iSample+1], x_baseModelconv3[iSample:iSample+1],\n",
        "                                                    x_baseModelconv4[iSample:iSample+1], 1)\n",
        "                _, label = torch.max(out2, 1)\n",
        "                predicted.append(label)\n",
        "                if label == gTruth[iSample].item():\n",
        "                    acc += 1\n",
        "                    recorder[1].append(1)\n",
        "                else:\n",
        "                    recorder[1].append(0)\n",
        "\n",
        "        # Calculate the total accuracy by summing correct predictions divided by total predictions\n",
        "        acc = acc / sum([len(recorder[x]) for x in range(2)])\n",
        "\n",
        "    return recorder, predicted, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV7xiet2PEdd"
      },
      "outputs": [],
      "source": [
        "def testingSummary(recorder, nBranches=2, overall=True):\n",
        "    \"\"\"\n",
        "    Prints a summary of testing accuracy for each branch and overall if specified.\n",
        "\n",
        "    Parameters:\n",
        "    recorder (dict): Dictionary containing lists of 0s and 1s where 1 represents a correct prediction, indexed by branch number.\n",
        "    nBranches (int): Number of branches in the model.\n",
        "    overall (bool): If True, prints the overall weighted accuracy across all branches.\n",
        "\n",
        "    Outputs:\n",
        "    Prints the accuracy of each branch and optionally the overall accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Header for the summary output\n",
        "    print('Summary')\n",
        "    print(\"======================\")\n",
        "\n",
        "    # Initialize accumulators for overall accuracy calculation\n",
        "    overallAcc, acc = 0, 0\n",
        "\n",
        "    # Calculate the total number of samples across all branches\n",
        "    overallCount = sum([len(recorder[x]) for x in range(nBranches)])\n",
        "\n",
        "    # Iterate through each branch to calculate and display individual accuracies\n",
        "    for i in range(nBranches):\n",
        "        # Number of samples in the current branch\n",
        "        countSamples = len(recorder[i])\n",
        "\n",
        "        # Check if there are samples in the current branch\n",
        "        if countSamples != 0:\n",
        "            # Calculate the accuracy for this branch\n",
        "            acc = recorder[i].count(1) / len(recorder[i])\n",
        "            # Print the accuracy and the percentage of total samples this branch represents\n",
        "            print(\"Branch {}: Accuracy {:.2f}% with {:.2f}% of the samples\".format(i+1, acc*100, countSamples/overallCount*100))\n",
        "        else:\n",
        "            # Handle the case where a branch has no samples\n",
        "            print(\"Branch {}: Got 0% of the samples\".format(i+1))\n",
        "\n",
        "        # Accumulate weighted accuracy for overall calculation\n",
        "        overallAcc += acc * countSamples\n",
        "\n",
        "    # If overall accuracy is to be calculated, display it\n",
        "    if overall:\n",
        "        print(\"Overall Weighted Accuracy: {:.2f}%\".format(overallAcc/overallCount*100))\n",
        "    return(overallAcc/overallCount*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9eylNEIahG",
        "outputId": "91c75ef4-e378-4498-89fc-14386da3366c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->ptflops)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->ptflops)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->ptflops)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->ptflops)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->ptflops)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->ptflops)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->ptflops)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->ptflops)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->ptflops)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ptflops-0.7.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ptflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_FNtX2gIUZK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from ptflops import get_model_complexity_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3rS3E8E8U03"
      },
      "source": [
        "### **Calculate FLOPs of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yXon4ULIYBT",
        "outputId": "95670529-c2cc-4415-a76c-5cfccfd25b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  512, 100.000% Params, 5.9 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(384, 75.000% Params, 3.93 MMac, 66.667% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 25.000% Params, 1.31 MMac, 22.222% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 11.111% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  8.32 k, 100.000% Params, 85.85 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(8.19 k, 98.462% Params, 83.89 MMac, 97.710% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(128, 1.538% Params, 1.31 MMac, 1.527% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.763% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  16.64 k, 100.000% Params, 171.7 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(16.38 k, 98.462% Params, 167.77 MMac, 97.710% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(256, 1.538% Params, 2.62 MMac, 1.527% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.763% MACs, negative_slope=0.2)\n",
            ")\n",
            "Sequential(\n",
            "  66.05 k, 100.000% Params, 678.95 MMac, 100.000% MACs, \n",
            "  (0): Conv2d(65.54 k, 99.225% Params, 671.09 MMac, 98.842% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (1): BatchNorm2d(512, 0.775% Params, 5.24 MMac, 0.772% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 2.62 MMac, 0.386% MACs, negative_slope=0.2)\n",
            ")\n",
            "FLOPs: 942.400000 MMac\n"
          ]
        }
      ],
      "source": [
        "flopsconv1, paramsconv1 = get_model_complexity_info(model.baseModelconv1, (6, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv2, paramsconv2 = get_model_complexity_info(model.baseModelconv2, (128, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv3, paramsconv3 = get_model_complexity_info(model.baseModelconv3, (128, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "flopsconv4, paramsconv4 = get_model_complexity_info(model.baseModelconv4, (256, 1024, 10), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs: {:2f} MMac'.format(5.9+85.85+171.7+678.95))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32I1XlZlJiD3",
        "outputId": "8baecfe2-2fcf-4e02-97ff-6a4ff8b3616d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  667.43 k, 100.000% Params, 668.2 KMac, 100.000% MACs, \n",
            "  (0): Linear(524.29 k, 78.553% Params, 524.29 KMac, 78.463% MACs, in_features=1024, out_features=512, bias=False)\n",
            "  (1): BatchNorm1d(1.02 k, 0.153% Params, 1.02 KMac, 0.153% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.077% MACs, negative_slope=0.2)\n",
            "  (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (4): Linear(131.33 k, 19.677% Params, 131.33 KMac, 19.654% MACs, in_features=512, out_features=256, bias=True)\n",
            "  (5): BatchNorm1d(512, 0.077% Params, 512.0 Mac, 0.077% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.038% MACs, negative_slope=0.2)\n",
            "  (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "  (8): Linear(10.28 k, 1.540% Params, 10.28 KMac, 1.538% MACs, in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "FLOPs: 668.2 KMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model.shortBranch, (1024, ), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRModsL7LwxM",
        "outputId": "409b3c45-427d-4a9b-c935-7ca0cdb9ea3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short path FLOPs: 943.068200 MMac\n"
          ]
        }
      ],
      "source": [
        "print('Short path FLOPs: {:2f} MMac'.format(942.4+0.6682))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyGwqyz0JYiR",
        "outputId": "431e021e-357c-4a51-de4f-92a9743fd9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
            "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm1d ptflops can affect your code!\n",
            "Warning: parameters of some of the modules were counted twice because of multiple links to the same modules. Extended per layer parameters num statistic could be unreliable.\n",
            "eeModel_E1(\n",
            "  2.48 M, 100.124% Params, 1.5 GMac, 84.493% MACs, \n",
            "  (bn1): BatchNorm2d(128, 0.005% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, 0.005% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(256, 0.010% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(512, 0.021% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn5): BatchNorm1d(2.05 k, 0.083% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (baseModelconv1): Sequential(\n",
            "    512, 0.021% Params, 5.9 MMac, 0.333% MACs, \n",
            "    (0): Conv2d(384, 0.016% Params, 3.93 MMac, 0.222% MACs, 6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.005% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv2): Sequential(\n",
            "    8.32 k, 0.336% Params, 85.85 MMac, 4.846% MACs, \n",
            "    (0): Conv2d(8.19 k, 0.331% Params, 83.89 MMac, 4.735% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.005% Params, 1.31 MMac, 0.074% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 655.36 KMac, 0.037% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv3): Sequential(\n",
            "    16.64 k, 0.672% Params, 171.7 MMac, 9.692% MACs, \n",
            "    (0): Conv2d(16.38 k, 0.661% Params, 167.77 MMac, 9.470% MACs, 128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, 0.010% Params, 2.62 MMac, 0.148% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.31 MMac, 0.074% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (baseModelconv4): Sequential(\n",
            "    66.05 k, 2.666% Params, 678.95 MMac, 38.324% MACs, \n",
            "    (0): Conv2d(65.54 k, 2.646% Params, 671.09 MMac, 37.880% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, 0.021% Params, 5.24 MMac, 0.296% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 2.62 MMac, 0.148% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (shortBranch): Sequential(\n",
            "    667.43 k, 26.945% Params, 668.2 KMac, 0.038% MACs, \n",
            "    (0): Linear(524.29 k, 21.166% Params, 524.29 KMac, 0.030% MACs, in_features=1024, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.041% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 5.302% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.021% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.415% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    526.34 k, 21.249% Params, 540.02 MMac, 30.482% MACs, \n",
            "    (0): Conv1d(524.29 k, 21.166% Params, 536.87 MMac, 30.304% MACs, 512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(2.05 k, 0.083% Params, 2.1 MMac, 0.118% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.059% MACs, negative_slope=0.2)\n",
            "  )\n",
            "  (longBranch_fc): Sequential(\n",
            "    1.19 M, 48.111% Params, 1.19 MMac, 0.067% MACs, \n",
            "    (0): Linear(1.05 M, 42.332% Params, 1.05 MMac, 0.059% MACs, in_features=2048, out_features=512, bias=False)\n",
            "    (1): BatchNorm1d(1.02 k, 0.041% Params, 1.02 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(0, 0.000% Params, 512.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (4): Linear(131.33 k, 5.302% Params, 131.33 KMac, 0.007% MACs, in_features=512, out_features=256, bias=True)\n",
            "    (5): BatchNorm1d(512, 0.021% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(0, 0.000% Params, 256.0 Mac, 0.000% MACs, negative_slope=0.2)\n",
            "    (7): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
            "    (8): Linear(10.28 k, 0.415% Params, 10.28 KMac, 0.001% MACs, in_features=256, out_features=40, bias=True)\n",
            "  )\n",
            ")\n",
            "FLOPs: 1.77 GMac\n"
          ]
        }
      ],
      "source": [
        "flops, params = get_model_complexity_info(model, (3, 1024), as_strings=True, print_per_layer_stat=True)\n",
        "print('FLOPs:', flops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUa8u_jd8uYa"
      },
      "source": [
        "### **Calculate number of parameters of short path e.g. base model and short branch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_kBvvytzVe",
        "outputId": "4270fa32-c088-4df5-9c64-840dc6172223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters in Short Path: 758952\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate the total number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Parameters in the base model\n",
        "baseModelconv1_params = count_parameters(model.baseModelconv1)\n",
        "baseModelconv2_params = count_parameters(model.baseModelconv2)\n",
        "baseModelconv3_params = count_parameters(model.baseModelconv3)\n",
        "baseModelconv4_params = count_parameters(model.baseModelconv4)\n",
        "\n",
        "# Parameters in the short branch\n",
        "short_path_params = count_parameters(model.shortBranch)\n",
        "\n",
        "print(\"Parameters in Short Path:\", short_path_params+baseModelconv1_params+baseModelconv2_params+baseModelconv3_params+baseModelconv4_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kCXX2hrwNN7",
        "outputId": "75f4a503-9209-4edc-8d2d-a38d14021cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Linear: 1-1                            524,288\n",
            "├─BatchNorm1d: 1-2                       1,024\n",
            "├─LeakyReLU: 1-3                         --\n",
            "├─Dropout: 1-4                           --\n",
            "├─Linear: 1-5                            131,328\n",
            "├─BatchNorm1d: 1-6                       512\n",
            "├─LeakyReLU: 1-7                         --\n",
            "├─Dropout: 1-8                           --\n",
            "├─Linear: 1-9                            10,280\n",
            "=================================================================\n",
            "Total params: 667,432\n",
            "Trainable params: 667,432\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            384\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 512\n",
            "Trainable params: 512\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            8,192\n",
            "├─BatchNorm2d: 1-2                       128\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 8,320\n",
            "Trainable params: 8,320\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            16,384\n",
            "├─BatchNorm2d: 1-2                       256\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 16,640\n",
            "Trainable params: 16,640\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "Sequential                               --\n",
            "├─Conv2d: 1-1                            65,536\n",
            "├─BatchNorm2d: 1-2                       512\n",
            "├─LeakyReLU: 1-3                         --\n",
            "=================================================================\n",
            "Total params: 66,048\n",
            "Trainable params: 66,048\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model.shortBranch))\n",
        "print(summary(model.baseModelconv1))\n",
        "print(summary(model.baseModelconv2))\n",
        "print(summary(model.baseModelconv3))\n",
        "print(summary(model.baseModelconv4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_-S5fX281Ty"
      },
      "source": [
        "### **Measure inference time and overall weighted accuracy with varying entropy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ln00bI0qZq"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=2, batch_size=args.test_batch_size, shuffle=True, drop_last=False) # Loading test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6-w1P3aMzNT"
      },
      "outputs": [],
      "source": [
        "inference_times = []\n",
        "accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxISoQfSjQbG",
        "outputId": "e7e97159-8a89-4f2d-deb6-d820fb9a08eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.624068 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Got 0% of the samples\n",
            "Branch 2: Accuracy 91.73% with 100.00% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhtT-ZIdk70V",
        "outputId": "cc55c61a-8b0b-48f0-def8-de90d9e1a06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.707659 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 100.00% with 0.08% of the samples\n",
            "Branch 2: Accuracy 91.73% with 99.92% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQE-rELqk-PF",
        "outputId": "43baaa63-db09-41fd-8ae1-2d28f9d1d2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.430598 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 97.44% with 1.58% of the samples\n",
            "Branch 2: Accuracy 91.64% with 98.42% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0PwWILTk__D",
        "outputId": "22e4ab96-5365-4901-bb30-22159ad3513d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.394887 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.37% with 7.46% of the samples\n",
            "Branch 2: Accuracy 91.20% with 92.54% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUYayMiwlBpN",
        "outputId": "a558d1bd-7426-4361-fbc2-953ee87f05b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 6.026758 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.61% with 20.34% of the samples\n",
            "Branch 2: Accuracy 89.98% with 79.66% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_9l0jzxlEND",
        "outputId": "bb641d45-9627-4f9f-86be-4b4f2817f56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.774827 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.39% with 40.32% of the samples\n",
            "Branch 2: Accuracy 87.10% with 59.68% of the samples\n",
            "Overall Weighted Accuracy: 91.65%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TduJVQ9YlF6T",
        "outputId": "1dba6c49-a974-4178-b98a-b3e03a86ac66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.346191 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 98.34% with 63.57% of the samples\n",
            "Branch 2: Accuracy 80.09% with 36.43% of the samples\n",
            "Overall Weighted Accuracy: 91.69%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd_1UvQOlHhc",
        "outputId": "2debbda9-aec1-4a11-c844-cb0e3d31a7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.171610 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 97.64% with 73.87% of the samples\n",
            "Branch 2: Accuracy 74.73% with 26.13% of the samples\n",
            "Overall Weighted Accuracy: 91.65%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdMnwqQOlJMD",
        "outputId": "9d4695d2-09c2-4b39-82c6-7b62446d146e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 5.037962 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 96.84% with 80.67% of the samples\n",
            "Branch 2: Accuracy 70.65% with 19.33% of the samples\n",
            "Overall Weighted Accuracy: 91.77%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewn8ofWPlKq6",
        "outputId": "292d088f-9108-41d6-9f62-d60250d56dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.985382 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 95.91% with 85.13% of the samples\n",
            "Branch 2: Accuracy 67.85% with 14.87% of the samples\n",
            "Overall Weighted Accuracy: 91.73%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=0.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLXHLaVC7e7",
        "outputId": "579c35ff-141d-4f45-bda6-f78e59e56438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.911268 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 94.87% with 90.03% of the samples\n",
            "Branch 2: Accuracy 62.20% with 9.97% of the samples\n",
            "Overall Weighted Accuracy: 91.61%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHDKqmxZlMGj",
        "outputId": "5231004b-5348-4bed-fcd2-d091a8bc5ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.854633 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 94.20% with 92.91% of the samples\n",
            "Branch 2: Accuracy 63.43% with 7.09% of the samples\n",
            "Overall Weighted Accuracy: 92.02%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.1, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM2caHq_lNoY",
        "outputId": "a99f05df-a8ee-4573-9a7b-86ff3cad9a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.796500 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 93.56% with 95.58% of the samples\n",
            "Branch 2: Accuracy 56.88% with 4.42% of the samples\n",
            "Overall Weighted Accuracy: 91.94%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S--mC_5slPqo",
        "outputId": "157d2c22-1334-412b-85fd-7fbb355f59ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.844496 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 92.83% with 97.77% of the samples\n",
            "Branch 2: Accuracy 47.27% with 2.23% of the samples\n",
            "Overall Weighted Accuracy: 91.82%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.3, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqQAsnGtlR3n",
        "outputId": "347496b2-bd07-46fe-9488-4b041fe34eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.760534 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.89% with 99.47% of the samples\n",
            "Branch 2: Accuracy 38.46% with 0.53% of the samples\n",
            "Overall Weighted Accuracy: 91.61%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.4, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9UKRbLLlUuV",
        "outputId": "f861cb64-37b2-470f-cbd3-de13d4c129cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.685637 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.5, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xawSuhXHM1rA",
        "outputId": "1e2425dc-e304-404b-b7be-1f1ea1d42480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.654280 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.6, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g0IZt8GM7Qc",
        "outputId": "d783136b-6703-4b84-ed95-06306c65170d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.696738 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.7, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fur5evB3M-ln",
        "outputId": "c6daa222-5b10-408f-fa44-d5b4570ff070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.709223 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.8, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ6AJscNBEb",
        "outputId": "7be3fb30-666d-49f7-df0b-603f56781b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.727679 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=1.9, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7S0a1mgNDCh",
        "outputId": "5045a3ab-1e0d-45ab-d17e-1072609f2f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time: 4.773438 seconds\n",
            "Summary\n",
            "======================\n",
            "Branch 1: Accuracy 91.49% with 100.00% of the samples\n",
            "Branch 2: Got 0% of the samples\n",
            "Overall Weighted Accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "inference_time = 0\n",
        "start_time = time.time()\n",
        "eeRecorder_V0, preds_V0, acc_V0 = infer(test_loader, threshold=2, verbose=False)\n",
        "inference_time = time.time() - start_time\n",
        "inference_times.append(inference_time)\n",
        "print('Inference Time: {:3f} seconds'.format(inference_time))\n",
        "accuracy = testingSummary(eeRecorder_V0, nBranches=2, overall=True)\n",
        "accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEFfCQeaZayA",
        "outputId": "bc0940df-de60-4710-c3b1-97087eef5deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6.62406849861145, 6.7076592445373535, 6.43059778213501, 6.39488673210144, 6.026757717132568, 5.774826526641846, 5.346190929412842, 5.171609878540039, 5.037962436676025, 4.985381841659546, 4.9112677574157715, 4.854632616043091, 4.796500205993652, 4.844495534896851, 4.760533809661865, 4.6856369972229, 4.654279947280884, 4.69673752784729, 4.709223031997681, 4.7276787757873535, 4.773437738418579]\n",
            "[91.73419773095624, 91.73419773095624, 91.73419773095624, 91.73419773095624, 91.73419773095624, 91.65316045380875, 91.6936790923825, 91.65316045380875, 91.77471636952998, 91.73419773095624, 91.61264181523501, 92.01782820097245, 91.93679092382496, 91.81523500810373, 91.61264181523501, 91.49108589951378, 91.49108589951378, 91.49108589951378, 91.49108589951378, 91.49108589951378, 91.49108589951378]\n"
          ]
        }
      ],
      "source": [
        "print(inference_times)\n",
        "print(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5WzXGEzbu4o",
        "outputId": "e54d7704-4656-46d8-f0d7-0b64fc44141b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-1.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "NLwWfowBNJBR",
        "outputId": "c0a98332-bc37-4b57-e7fa-69616738b44c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT+klEQVR4nO3de1hU1f4/8PcwchmRS6jAcBGQVDANUZNATU2UyOPRyBuWIF5OFzxhlCV5TUu0vJ70SJlXzPSohB41iUhUkkJF+nmLREEQQfOo3FSEYf3+4MvkyIAMtxmY9+t55sm99tprf/bM5uzPWXvttSVCCAEiIiIiPWKg7QCIiIiImhsTICIiItI7TICIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgIiIiEjvtNF2ALqooqIC169fh5mZGSQSibbDISIiojoQQqCoqAh2dnYwMKi9j4cJkBrXr1+Ho6OjtsMgIiKiesjJyYGDg0OtdZgAqWFmZgag8gs0NzfXcjRERERUF4WFhXB0dFRex2vDBEiNqtte5ubmTICIiIhamLoMX+EgaKqzY8eOYeTIkbCzs4NEIkFsbGyt9fPy8jBx4kR07doVBgYGmDlzZrPESURE9CRMgKjOSkpK4OHhgXXr1tWpfmlpKTp27Ii5c+fCw8OjiaMjIiKqO94Cozrz9/eHv79/nes7OztjzZo1AIBNmzY1VVhEREQaYw8QERER6R0mQERERKR3mAARERGR3mECRERERHqHCRARERHpHT4FRnVWXFyMjIwM5XJmZibS0tJgZWWFTp06ISIiArm5udi2bZuyTlpamnLbP//8E2lpaTAyMkL37t2bO3wiIiIliRBCaDsIXVNYWAgLCwsUFBTo9UzQCgVw/DiQlwfI5YBCkQhf3yHV6gUHB2PLli2YPHkysrKykJiYqFynbjZOJycnZGVlNWHkRESkjzS5frMHiNSKiQHCwoBr1/4qc3AYjL17BQIC1G+zZcuWamXMr4mISBdxDBBVExMDjBmjmvwAQG5uZXlMjHbiIiIiaixMgEiFQlHZ86Ou46aqbObMynpEREQtFRMgUnH8ePWen0cJAeTkVNYjIiJqqZgAkYq8vMatR0REpIuYAJEKubxx6xEREekiJkCkYuBAwMEBUPP0OoDKckfHynpEREQtFRMgUiGVAmvWVP778SSoann16sp6RERELRUTIKomIADYswewt1ctd3CoLK9pHiAiIqKWghMhkloBAcCoUaozQQ8cyJ4fIiJqHZgAUY2kUmDwYG1HQURE1Ph4C4yIiIj0jtYToKKiIsycORNOTk6QyWTw8fHByZMnAQBlZWX48MMP0bNnT5iamsLOzg5BQUG4fv36E9tdt24dnJ2dYWJiAi8vL6SkpDT1oRAREVELofUEaNq0aYiPj0d0dDTOnj2L4cOHw9fXF7m5ubh37x5SU1Mxb948pKamIiYmBunp6fj73/9ea5u7du1CeHg4FixYgNTUVHh4eMDPzw83b95spqMiIiIiXSYRWnxd9/3792FmZoZ9+/ZhxIgRyvI+ffrA398fn3zySbVtTp48iX79+uHq1avo1KmT2na9vLzw3HPPYe3atQCAiooKODo64p///Cdmz55drX5paSlKS0uVy4WFhXB0dERBQQHMzc0bephERETUDAoLC2FhYVGn67dWe4DKy8uhUChgYmKiUi6TyZCUlKR2m4KCAkgkElhaWqpd//DhQ5w+fRq+vr7KMgMDA/j6+iI5OVntNpGRkbCwsFB+HB0d63dARERE1CJoNQEyMzODt7c3Fi9ejOvXr0OhUGD79u1ITk5GnpqXTT148AAffvghAgMDa8zsbt26BYVCARsbG5VyGxsb5Ofnq90mIiICBQUFyk9OTk7DD46IiIh0ltbHAEVHR0MIAXt7exgbG+Nf//oXAgMDYWCgGlpZWRnGjRsHIQTWr1/fqDEYGxvD3Nxc5UNEREStl9YTIFdXVxw9ehTFxcXIyclBSkoKysrK0LlzZ2WdquTn6tWriI+PrzVB6dChA6RSKW7cuKFSfuPGDdja2jbZcRAREVHLofUEqIqpqSnkcjnu3LmDuLg4jBo1CsBfyc+lS5fw448/on379rW2Y2RkhD59+iAhIUFZVlFRgYSEBHh7ezfpMRAREVHLoPWZoOPi4iCEQLdu3ZCRkYFZs2bBzc0NISEhKCsrw5gxY5CamooDBw5AoVAox/FYWVnByMgIADB06FC88sormDFjBgAgPDwcwcHB6Nu3L/r164fVq1ejpKQEISEhWjtOIiIi0h1aT4AKCgoQERGBa9euwcrKCq+++io+/fRTGBoaIisrC/v37wcA9OrVS2W7I0eOYPD/vafh8uXLuHXrlnLd+PHj8eeff2L+/PnIz89Hr169cPjw4WoDo4mIiEg/aXUeIF2lyTwCREREpBtazDxARERERNrABIiIiIj0DhMgIiIi0jtMgIiIiEjvMAEiIiIivcMEiIiIiPQOEyAiIiLSO0yAiIiISO8wASIiIiK9wwSIiIiI9A4TICIiItI7TICIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgIiIiEjvMAEiIiIivcMEiIiIiPQOEyA9dezYMYwcORJ2dnaQSCSIjY2ttX5MTAyGDRuGjh07wtzcHN7e3oiLi2ueYImIiBoZEyA9VVJSAg8PD6xbt65O9Y8dO4Zhw4bh0KFDOH36NIYMGYKRI0fizJkzTRwpERFR45MIIYS2g9A1hYWFsLCwQEFBAczNzbUdTpOTSCT47rvvMHr0aI22e+aZZzB+/HjMnz+/aQIjIiLSgCbXb/YAUb1UVFSgqKgIVlZW2g6FiIhIY0yAqF6WL1+O4uJijBs3TtuhEBERaayNtgOglmfHjh34+OOPsW/fPlhbW2s7HCIiIo0xASKN7Ny5E9OmTcPu3bvh6+ur7XCIiIjqhbfAqM6+/fZbhISE4Ntvv8WIESO0HQ4REVG9sQdITxUXFyMjI0O5nJmZibS0NFhZWaFTp06IiIhAbm4utm3bBqDytldwcDDWrFkDLy8v5OfnAwBkMhksLCy0cgxERET1xR4gPXXq1Cl4enrC09MTABAeHg5PT0/lI+15eXnIzs5W1v/qq69QXl6O0NBQyOVy5ScsLEwr8RMRETUE5wFSozXOA6RQAMePA3l5gFwODBwISKXajoqIiKjxaHL95i0wPRATA4SFAdeu/VXm4ACsWQMEBGgvLiIiIm3hLbBWLiYGGDNGNfkBgNzcyvKYGO3ERUREpE1MgFoxhaKy50fdTc6qspkzK+sRERHpEyZArdjx49V7fh4lBJCTU1mPiIhInzABasXy8hq3HhERUWvBBKgVk8sbtx4REVFrwQSoFRs4sPJpL4lE/XqJBHB0rKxHRESkT5gAtWJSaeWj7kD1JKhqefVqzgdERET6hwlQKxcQAOzZA9jbq5Y7OFSWcx4gIiLSR5wIUQ8EBACjRnEmaCIioipMgPSEVAoMHqztKIiIiHQDb4ERERGR3mECRERERHqHCRARERHpHSZAREREpHeYABEREZHeYQJEREREeocJEBEREekdJkBERESkd5gAERERkd5hAkRERER6hwkQERER6R0mQERERKR3tJoAFRUVYebMmXBycoJMJoOPjw9OnjypXB8TE4Phw4ejffv2kEgkSEtLe2KbZWVlWLRoEVxdXWFiYgIPDw8cPny4CY+CiIiIWhqtJkDTpk1DfHw8oqOjcfbsWQwfPhy+vr7Izc0FAJSUlGDAgAFYtmxZnducO3cuvvzyS3zxxRe4cOEC3nzzTbzyyis4c+ZMUx0GERERtTASIYTQxo7v378PMzMz7Nu3DyNGjFCW9+nTB/7+/vjkk0+UZVlZWXBxccGZM2fQq1evWtu1s7PDnDlzEBoaqix79dVXIZPJsH379jrFVlhYCAsLCxQUFMDc3FyzAyMiIiKt0OT63aaZYqqmvLwcCoUCJiYmKuUymQxJSUn1bre0tFTjNktLS1FaWqpcLiwsrPf+iYiISPdp7RaYmZkZvL29sXjxYly/fh0KhQLbt29HcnIy8vLy6t2un58fVq5ciUuXLqGiogLx8fGIiYmptc3IyEhYWFgoP46OjvXePxEREek+rY4Bio6OhhAC9vb2MDY2xr/+9S8EBgbCwKD+Ya1ZswZdunSBm5sbjIyMMGPGDISEhNTaZkREBAoKCpSfnJyceu+fiIiIdJ9WEyBXV1ccPXoUxcXFyMnJQUpKCsrKytC5c+d6t9mxY0fExsaipKQEV69exe+//4527drV2qaxsTHMzc1VPkRERNR66cQ8QKamppDL5bhz5w7i4uIwatSoBrdpYmICe3t7lJeXY+/evY3SJhEREbUOWhsEDQBxcXEQQqBbt27IyMjArFmz4ObmhpCQEADA7du3kZ2djevXrwMA0tPTAQC2trawtbUFAAQFBcHe3h6RkZEAgF9//RW5ubno1asXcnNzsXDhQlRUVOCDDz7QwhESERGRLtJqD1BBQQFCQ0Ph5uaGoKAgDBgwAHFxcTA0NAQA7N+/H56ensrH5CdMmABPT09ERUUp28jOzlYZ4PzgwQPMnTsX3bt3xyuvvAJ7e3skJSXB0tKyWY+NiIiIdJfW5gHSZZwHiIiIqOXR5PqtE2OAiIiIiJoTEyAiIiLSO0yAiIiISO8wASIiIiK9wwSIiIiI9A4TICIiItI7TICIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgIiIiEjvMAEiIiIivcMEiIiIiPQOEyAiIiLSO0yAiIiISO8wASIiIiK9wwSIiIiI9A4TICIiItI7TICIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgIiIiEjvMAEiIiIivcMEiIiIiPQOEyAiIiLSO0yAiIiISO8wASIiIiK9wwSIiIiI9A4TICIiItI7TICIiIhI7zABIiIiIr3DBIiIiIj0DhMgeqJjx45h5MiRsLOzg0QiQWxsbK31k5KS0L9/f7Rv3x4ymQxubm5YtWpV8wRLRERUB220HQDpvpKSEnh4eGDKlCkICAh4Yn1TU1PMmDEDzz77LExNTZGUlIQ33ngDpqam+Mc//tEMERMREdVOIoQQ2g5C1xQWFsLCwgIFBQUwNzfXdjg6RSKR4LvvvsPo0aM12i4gIACmpqaIjo5umsCIiEjvaXL95i0wanJnzpzBiRMnMGjQIG2HQkREBIC3wKgJOTg44M8//0R5eTkWLlyIadOmaTskIiIiAEyAqAkdP34cxcXF+OWXXzB79mw8/fTTCAwM1HZYRERETICo6bi4uAAAevbsiRs3bmDhwoVMgIiISCdwDBA1i4qKCpSWlmo7DCIiIgDsAaI6KC4uRkZGhnI5MzMTaWlpsLKyQqdOnRAREYHc3Fxs27YNALBu3Tp06tQJbm5uACrnEVq+fDneeecdrcRPRET0OCZAVI1CARw/DuTlAXI5oFCcgq/vEOX68PBwAEBwcDC2bNmCvLw8ZGdnK9dXVFQgIiICmZmZaNOmDVxdXbFs2TK88cYbzX4sRERE6nAeIDX0eR6gmBggLAy4du2vMgcHYM0aoA5zIBIREWkN5wGieomJAcaMUU1+ACA3t7I8JkY7cRERETU2JkAEoPK2V1gYoK4/sKps5szKekRERC0dEyACUDnm5/Gen0cJAeTkVNYjIiJq6ZgAEYDKAc+NWY+IiEiXMQEiAJVPezVmPSIiIl3GBIgAAAMHVj7tJZGoXy+RAI6OlfWIiIhaOiZABACQSisfdQeqJ0FVy6tXV9YjIiJq6RolAbp7925jNENaFhAA7NkD2Nurljs4VJZzHiAiImotNE6Ali1bhl27dimXx40bh/bt28Pe3h6//fZbowZHzS8gAMjKAo4cAXbsqPxvZiaTHyIial00ToCioqLg6OgIAIiPj0d8fDy+//57+Pv7Y9asWRq1VVRUhJkzZ8LJyQkymQw+Pj44efKkcn1MTAyGDx+O9u3bQyKRIC0trU7trl69Gt26dYNMJoOjoyPeffddPHjwQKPY9JlUCgweDAQGVv6Xt72IiKi10fhdYPn5+coE6MCBAxg3bhyGDx8OZ2dneHl5adTWtGnTcO7cOURHR8POzg7bt2+Hr68vLly4AHt7e5SUlGDAgAEYN24cpk+fXqc2d+zYgdmzZ2PTpk3w8fHBH3/8gcmTJ0MikWDlypWaHi4RERG1QhonQE899RRycnLg6OiIw4cP45NPPgEACCGg0GCa4Pv372Pv3r3Yt28fXnjhBQDAwoUL8d///hfr16/HJ598gkmTJgEAsrKy6tzuiRMn0L9/f0ycOBEA4OzsjMDAQPz66691boOIiIhaN41vgQUEBGDixIkYNmwY/ve//8Hf3x8AcObMGTz99NN1bqe8vBwKhQImJiYq5TKZDElJSZqGpeTj44PTp08jJSUFAHDlyhUcOnQIL7/8co3blJaWorCwUOVDRERErZfGPUCrVq2Cs7MzcnJy8Nlnn6Fdu3YAgLy8PLz99tt1bsfMzAze3t5YvHgx3N3dYWNjg2+//RbJyckaJVKPmzhxIm7duoUBAwZACIHy8nK8+eab+Oijj2rcJjIyEh9//HG990lEREQti0QIda+/bB6XL1/GlClTcOzYMUilUvTu3Rtdu3bF6dOncfHiRWW9rKwsuLi44MyZM+jVq1etbSYmJmLChAn45JNP4OXlhYyMDISFhWH69OmYN2+e2m1KS0tRWlqqXC4sLISjoyMKCgpgbm7eKMdKRERETauwsBAWFhZ1un7Xax6g6OhoDBgwAHZ2drh69SqAyiev9u3bp1E7rq6uOHr0KIqLi5GTk4OUlBSUlZWhc+fO9QkLADBv3jxMmjQJ06ZNQ8+ePfHKK69gyZIliIyMREVFhdptjI2NYW5urvKhlmvdunVwdnaGiYkJvLy8lLdDa8KnBomI9I/GCdD69esRHh4Of39/3L17Vznw2dLSEqtXr65XEKamppDL5bhz5w7i4uIwatSoerUDAPfu3YOBgephSf/vOW4tdnZRM9m1axfCw8OxYMECpKamwsPDA35+frh586ba+lVPDS5YsAAXL17Exo0bsWvXrlpvmRIRUcuncQL0xRdfYMOGDZgzZ44ysQCAvn374uzZsxq1FRcXh8OHDyMzMxPx8fEYMmQI3NzcEBISAgC4ffs20tLScOHCBQBAeno60tLSkJ+fr2wjKCgIERERyuWRI0di/fr12Llzp7LdefPmYeTIkSrxUuu0cuVKTJ8+HSEhIejevTuioqLQtm1bbNq0SW39R58adHZ2xvDhwxEYGPjEXiMiImrZNE6AMjMz4enpWa3c2NgYJSUlGrVVUFCA0NBQuLm5ISgoCAMGDEBcXBwMDQ0BAPv374enpydGjBgBAJgwYQI8PT0RFRWlbCM7Oxt5eXnK5blz5+K9997D3Llz0b17d0ydOhV+fn748ssvNT1UamEePnyI06dPw9fXV1lmYGAAX19fJCcnq92mPk8NEhFRy6fxU2AuLi5IS0uDk5OTSvnhw4fh7u6uUVvjxo3DuHHjalw/efJkTJ48udY2EhMTVZbbtGmDBQsWYMGCBRrFQi3frVu3oFAoYGNjo1JuY2OD33//Xe029XlqkIiIWj6NE6Dw8HCEhobiwYMHEEIgJSUF3377LSIjI/H11183RYxETSYxMRFLlizBv//9b5WnBhcvXlzjU4NERNTyaZwATZs2DTKZDHPnzsW9e/cwceJE2NnZYc2aNZgwYUJTxEhUJx06dIBUKsWNGzdUym/cuAFbW1u12zz61CAA9OzZEyUlJfjHP/6BOXPmVBtQT0RErUO9/tf9tddew6VLl1BcXIz8/Hxcu3YNU6dObezYiDRiZGSEPn36ICEhQVlWUVGBhIQEeHt7q92GTw0SEeknjXuAHtW2bVu0bdu2sWIharDw8HAEBwejb9++6NevH1avXo2SkhLlk4VBQUGwt7dHZGQkgMqnBleuXAlPT0/lLTA+NUhE1PrVKQHq3bs3EhIS8NRTT8HT0xMSiaTGuqmpqY0WHFFtFArg+HEgLw+Qy4GBA4Hx48fjzz//xPz585Gfn49evXrh8OHDyoHR2dnZKj0+c+fOhUQiwdy5c5Gbm4uOHTti5MiR+PTTT7V1WERE1Azq9CqMjz/+GLNmzULbtm2f+M6s1vD0lSZTaZN2xMQAYWHAtWt/lTk4AGvWAAEB2ouLiIi0R5Prt1bfBaarmADptpgYYMwY4PEzt6pjcs8eJkFERPqoSd8FdvLkSfz666/Vyn/99VecOnVK0+aINKJQVPb8qEvbq8pmzqysR0REVBONE6DQ0FDk5ORUK8/NzUVoaGijBEVUk+PHVW97PU4IICensh4REVFNNE6ALly4gN69e1cr9/T0VL6zi6ipPPLWk0apR0RE+knjBMjY2LjaRHMAkJeXhzZtGvRUPdETyeWNW4+IiPSTxgnQ8OHDERERgYKCAmXZ3bt38dFHH2HYsGGNGhzR4wYOrHzaq6aZGCQSwNGxsh4REVFNNE6Ali9fjpycHDg5OWHIkCEYMmQIXFxckJ+fjxUrVjRFjERKUmnlo+5A9SSoann16sp6RERENanXY/AlJSX45ptv8Ntvv0Emk+HZZ59FYGAgDA0NmyLGZsfH4HWfunmAHB0rkx8+Ak9EpJ84D1ADMQFqGdTNBM2eHyIi/dWk8wBVuXDhAg4fPoz9+/erfIiai1QKDB4MBAZW/pfJDxHpinXr1sHZ2RkmJibw8vJCSkpKjXVjYmLQt29fWFpawtTUFL169UJ0dHQzRqufNH5s68qVK3jllVdw9uxZSCQS5Ruzq94PpuAMdEREpMd27dqF8PBwREVFwcvLC6tXr4afnx/S09NhbW1drb6VlRXmzJkDNzc3GBkZ4cCBAwgJCYG1tTX8/Py0cAT6QeMeoLCwMLi4uODmzZto27Ytzp8/j2PHjqFv375ITExsghCJiIhajpUrV2L69OkICQlB9+7dERUVhbZt22LTpk1q6w8ePBivvPIK3N3d4erqirCwMDz77LNISkpq5sj1i8YJUHJyMhYtWoQOHTrAwMAABgYGGDBgACIjI/HOO+80RYxEREQtwsOHD3H69Gn4+voqywwMDODr64vk5OQnbi+EQEJCAtLT0/HCCy80Zah6T+NbYAqFAmZmZgCADh064Pr16+jWrRucnJyQnp7e6AESERG1FLdu3YJCoYCNjY1KuY2NDX7//fcatysoKIC9vT1KS0shlUrx73//m3PrNTGNe4B69OiB3377DQDg5eWFzz77DD///DMWLVqEzp07N3qARERErZ2ZmRnS0tJw8uRJfPrppwgPD9epYSWaDOoGgN27d8PNzQ0mJibo2bMnDh061EyR1p3GCdDcuXNRUVEBAFi0aBEyMzMxcOBAHDp0CP/6178aPUAiItItml4Mq+zcuRMSiQSjR49u2gC1qEOHDpBKpdVeGXXjxg3Y2trWuJ2BgQGefvpp9OrVC++99x7GjBmDyMjIpg63TqoGdS9YsACpqanw8PCAn58fbt68qbb+iRMnEBgYiKlTp+LMmTMYPXo0Ro8ejXPnztW4D03OqfPnz+PVV1+Fs7MzJBIJVq9eXa/j0jgB8vPzQ8D/zTT39NNP4/fff8etW7dw8+ZNvPjii/UKgoiIWgZNL4ZVsrKy8P7772NgK39PjZGREfr06YOEhARlWUVFBRISEuDt7V3ndioqKlBaWtoUIWpM00Hda9aswUsvvYRZs2bB3d0dixcvRu/evbF27Vq19TU9p+7du4fOnTtj6dKltSaVT6JRAlRWVoY2bdpUy+KsrKyUj8ETEVHrpenFEKgcO/raa6/h448/1ouhEuHh4diwYQO2bt2Kixcv4q233kJJSQlCQkIAAEFBQYiIiFDWj4yMRHx8PK5cuYKLFy9ixYoViI6Oxuuvv66tQ1Cqz6Du5ORklfpAZedJTfU1Paeee+45fP7555gwYQKMjY3reWQaDoI2NDREp06dONcPEZEeqroYPnrxrssTTosWLYK1tTWmTp2K48ePN0eoWjV+/Hj8+eefmD9/PvLz89GrVy8cPnxYOTA6OzsbBgZ/9T+UlJTg7bffxrVr1yCTyeDm5obt27dj/Pjx2joEpfoM6s7Pz1dbPz8/v1rd+p5TjUHjW2Bz5szBRx99hNu3bzdFPERqaXJ/uKysDIsWLYKrqytMTEzg4eGBw4cPN2O0RK1TbRdDdRc3AEhKSsLGjRuxYcOG5ghRZ8yYMQNXr15FaWkpfv31V3h5eSnXJSYmYsuWLcrlTz75BJcuXcL9+/dx+/ZtnDhxQieSn+ZQn3OqsWj8GPzatWuRkZEBOzs7ODk5wdTUVGV9ampqowVHBGg+q+rcuXOxfft2bNiwAW5uboiLi8Mrr7yCEydOwNPTUwtHQKSfioqKMGnSJGzYsAEdOnTQdjhUD/UZ1G1ra6vxIHBt0DgBas2j90k3PXp/GACioqJw8OBBbNq0CbNnz65WPzo6GnPmzMHLL78MAHjrrbfw448/YsWKFdi+fXuzxk7Ummh6Mbx8+TKysrIwcuRIZVnVU8Rt2rRBeno6XF1dmzZoapBHB3VXXf+rBnXPmDFD7Tbe3t5ISEjAzJkzlWXx8fFqB4HX96m5xqBxArRgwYKmiINIrfrcHy4tLYWJiYlKmUwm47TyRA2k6cXQzc0NZ8+eVSmbO3cuioqKsGbNGjg6OjZH2NRA4eHhCA4ORt++fdGvXz+sXr262qBue3t75WP7YWFhGDRoEFasWIERI0Zg586dOHXqFL766qtqbdcnwWosGidARM2pPgPw/Pz8sHLlSrzwwgtwdXVFQkICYmJiOHifqBFocjE0MTFBjx49VLa3tLQEgGrlrd369euxdetWHDt2DEZGRtoORyOaDur28fHBjh07MHfuXHz00Ufo0qULYmNja/zNNU2wHj58iAsXLij/nZubi7S0NLRr107tsIiaaJwAGRgY1PrIOy8y1BAKBXD8OJCXB8jlQH16x9esWYPp06fDzc0NEokErq6uCAkJqfUxXSKq7vG/x4EDNb8Y6ruq7zA0NBRCCBQWlqBDB6Nq6x/9jqVSLQZcg7femoEePWYo4+zb96916masHjt2LMaOHau2rcePecwYzc6p69evq4znXL58OZYvX45BgwZh//79dT8ooaHY2FiVz+7du8VHH30k7O3txddff61pczqpoKBAABAFBQXaDkWv7N0rhIODEMBfH3v7UmFgIBXfffedSt2goCDx97//vdb27t+/L65duyYqKirEBx98ILp3796E0RO1Lur+Hh0cKsupblS/w10CWKTyHbaU77h6nLnC3l5Rrzib+pg1uX5rnADV5JtvvnniBamlYALU/PbuFUIiUf2jAKrK+gl//xnKugqFQtjb24vIyMg6tf3w4UPh6uoqIiIimip8olaltr9HiUT3LtC66Enf4axZDf+O165dK5ycnISxsbHo16+f+PXXX2us+9VXX4kBAwYIS0tLYWlpKYYOHVpr/ZqPY5UAIIDdGp8LzXFeaSUBunz5sjA1NW2s5rSKCVDzKi+v/v8IVD87BWAsNm3aIi5cuCD+8Y9/CEtLS5Gfny+EEGLSpEli9uzZyvZ++eUXsXfvXnH58mVx7Ngx8eKLLwoXFxdx584dLR0hUcvxpL9HiUQIR8fKeqReXb5DqbRh3/HOnTuFkZGR2LRpkzh//ryYPn26sLS0FDdu3FBbf+LEiWLdunXizJkz4uLFi2Ly5MnCwsJCXLt2TcPjeOn/EqCzGp0LzXVeNXsCdO/ePREWFia6du3aGM1pHROg5nXkSG3JT9XnC2Fj00kYGRmJfv36iV9++UW5/aBBg0RwcLByOTExUbi7uwtjY2PRvn17MWnSJJGbm9v8B0bUAtXt77GyHqlX1++w5s8NAbwpVq06Iu7du6d2H/369ROhoaHKZYVCIezs7OrcM15eXi7MzMzE1q1bNTyOe/8Xn2bnQnOdV5pcvzUeBP3UU0+pDIIWQqCoqAht27blHCtUL3l5dak1A6tWzUBgYPU1jw/AGzRokPIJASLSTN3+HuteTx81/LtZDCAK774bhXffBT7++GPMnz9fubYxXh9x7949lJWVwcrKqsY66o9D9n+fJ9WrS1v1r9cYNE6AVq1apZIAGRgYoGPHjvDy8sJTTz3VqMGRfpDLG7ceEdUf/x4bruHfzRoAfbB0qQ1sbW+qvEYDqN/0II/78MMPYWdnV+2lpY9qzHNBF88rjROgyZMnN0EYpM8GDgQcHIDc3MpO0MdJJJXrBw5s/tiI9A3/HhuuLt+hgUHl4+DqSCQGcHCYjPffb5pH4pcuXYqdO3ciMTGx2qSxj2rMc0EXzyuNJ2vYvHkzdu/eXa189+7d2Lp1a6MERfpFKgXWrKn89+NTTFUtr16tm3NjELU2/HtsuLp8h+Hhlf+uz3fckNdHLF++HEuXLsUPP/yAZ599tsHHUddzQSfPK00HGHXp0kX89NNP1coTExM5CJoaRN38EI6OfOSWSBv499hwT/oOG/Id9+vXT8yYodn0IMuWLRPm5uYiOTm5UY9DW22po8n1WyKEus6ompmYmOD333+Hs7OzSnlWVhbc3d1x//79xsvOtKSwsBAWFhYoKCiAubm5tsPRKy1lVlQifcC/x4Z70ndY3+94165dCA4Oxpdffql8fcR//vMf/P7777Cxsan2+ohly5Zh/vz52LFjB/r3769sp127dmjXrl2Dj0MTTXleaXL91ngMkLW1Nf7f//t/1RKg3377De3bt9e0OSIVUikweLC2oyAigH+PjeFJ32F9v2NNX0myfv16PHz4EGPGjFFpZ8GCBVi4cGGDj0MTunJeadwD9OGHH2LXrl3YvHkzXnjhBQDA0aNHMWXKFIwZMwbLly9vkkCbE3uAiIiIWp4m7QFavHgxsrKyMHToULRpU7l5RUUFgoKCsGTJkvpFTERERNSMNO4BqnLp0iWkpaVBJpOhZ8+ecHJyauzYtIY9QERERC1Pk/YAVenSpQu6dOlS382JiIiItEbjeYBeffVVLFu2rFr5Z599hrFjxzZKUETUONatWwdnZ2eYmJjAy8sLKSkptda/e/cuQkNDIZfLYWxsjK5du+LQoUPNFC0RUfPROAE6duwYXn755Wrl/v7+OHbsWKMERUQNt2vXLoSHh2PBggVITU2Fh4cH/Pz8cPPmTbX1Hz58iGHDhiErKwt79uxBeno6NmzYAHt7+2aOnIio6Wl8C6y4uBhGRkbVyg0NDVFYWNgoQRFRw61cuRLTp09HSEgIACAqKgoHDx7Epk2bMHv27Gr1N23ahNu3b+PEiRMwNDQEgGrTXRARtRYa9wD17NkTu3btqla+c+dOdO/evVGCIqKGqXpb9KMvOnzS26L3798Pb29vhIaGwsbGBj169MCSJUugqOmFRURELZjGPUDz5s1DQEAALl++jBdffBEAkJCQgB07dmDPnj2NHiARaa4+b4u+cuUKfvrpJ7z22ms4dOgQMjIy8Pbbb6OsrAwLFixojrCJiJqNxgnQyJEjERsbiyVLlmDPnj2QyWTw8PDATz/9BCsrq6aIkYiaQUVFBaytrfHVV19BKpWiT58+yM3Nxeeff84EiIhanXo9Bj9ixAiMGDECQOUz999++y3ef/99nD59mt3lRDqgPm+LlsvlMDQ0hPSRl/K4u7sjPz8fDx8+VDv2j4iopdJ4DFCVY8eOITg4GHZ2dlixYgVefPFF/PLLLxq3U1RUhJkzZ8LJyQkymQw+Pj44efKkcn1MTAyGDx+O9u3bQyKRIC0t7YltDh48GBKJpNqnKmkjau2MjIzQp08fJCQkKMsqKiqQkJAAb29vtdv0798fGRkZqKioUJb98ccfkMvlTH6IqNXRKAHKz8/H0qVL0aVLF4wdOxbm5uYoLS1FbGwsli5diueee07jAKZNm4b4+HhER0fj7NmzGD58OHx9fZGbmwsAKCkpwYABA9TOPVSTmJgY5OXlKT/nzp2DVCrlPEWkV8LDw7FhwwZs3boVFy9exFtvvYWSkhLlU2FBQUGIiIhQ1n/rrbdw+/ZthIWF4Y8//sDBgwexZMkShIaGausQiIiajqijv/3tb8Lc3FwEBgaKAwcOiPLyciGEEG3atBHnz5+vazMq7t27J6RSqThw4IBKee/evcWcOXNUyjIzMwUAcebMGY33s2rVKmFmZiaKi4vrVL+goEAAEAUFBRrvi0iXfPHFF6JTp07CyMhI9OvXT/zyyy/KdYMGDRLBwcEq9U+cOCG8vLyEsbGx6Ny5s/j000+Vf+tERLpOk+t3nccAff/993jnnXfw1ltvNdorMMrLy6FQKGBiYqJSLpPJkJSU1Cj7AICNGzdiwoQJMDU1Vbu+tLQUpaWlymXOZ0QtkUIBHD8O5OUBcjkwcCAwY8YMzJgxQ239xMTEamXe3t71upVNRNTS1PkWWFJSEoqKitCnTx94eXlh7dq1uHXrVoN2bmZmBm9vbyxevBjXr1+HQqHA9u3bkZycjLy8vAa1XSUlJQXnzp3DtGnTaqwTGRkJCwsL5cfR0bFR9k3UXGJiAGdnYMgQYOLEyv86O1eWExFRdXVOgJ5//nls2LABeXl5eOONN7Bz507Y2dmhoqIC8fHxKCoqqlcA0dHREELA3t4exsbG+Ne//oXAwEAYGNR7fLaKjRs3omfPnujXr1+NdSIiIlBQUKD85OTkNMq+iZpDTAwwZgxw7ZpqeW5uZTmTICKi6jTOMkxNTTFlyhQkJSXh7NmzeO+997B06VJYW1vj73//u8YBuLq64ujRoyguLkZOTg5SUlJQVlaGzp07a9zW40pKSrBz505MnTq11nrGxsYwNzdX+RC1BAoFEBYGCFF9XVXZzJmV9YiI6C8N6mbp1q0bPvvsM1y7dg3ffvttgwIxNTWFXC7HnTt3EBcXh1GjRjWoPQDYvXs3SktL8frrrze4LSJddPx49Z6fRwkB5ORU1iMior/UayLEx0mlUowePRqjR4/WeNu4uDgIIdCtWzdkZGRg1qxZcHNzUz6qe/v2bWRnZ+P69esAgPT0dACAra2tckK3oKAg2NvbIzIyUqXtjRs3YvTo0Wjfvn0Djo5Id9V1qFwjDakjImo1GmegTQMUFBQgNDQUbm5uCAoKwoABAxAXF6d8G/X+/fvh6empnMRwwoQJ8PT0RFRUlLKN7OzsaoOm09PTkZSU9MTbX0QtmVzeuPWIiPSFRAh1owf0W2FhISwsLFBQUMDxQKTTFIrKp71yc9WPA5JIAAcHIDMTeOQNF0RErZIm12+t9wARUf1JpcCaNZX/lkhU11Utr17N5IeI6HFMgIhauIAAYM8ewN5etdzBobI8IEA7cRER6bJGGQRNRNoVEACMGlV9Jmj2/BARqccEiKiVkEqBwYO1HQURUcvAW2BERESkd5gAERERkd5hAkRERER6hwkQERER6R0mQESNYN26dXB2doaJiQm8vLyQkpJSY93BgwdDIpFU+1TNdk4tnybnw5YtW6qdCyYmJs0YLZF+YgJE1EC7du1CeHg4FixYgNTUVHh4eMDPzw83b95UWz8mJgZ5eXnKz7lz5yCVSjF27NhmjpyagqbnAwCYm5urnBNXr15txoiJ9BMTIKIGWrlyJaZPn46QkBB0794dUVFRaNu2LTZt2qS2vpWVlfJlvra2toiPj0fbtm2ZALUSmp4PACCRSFTOCRsbm2aMmEg/MQEiaoCHDx/i9OnT8PX1VZYZGBjA19cXycnJdWpj48aNmDBhAkxNTZsqTGom9T0fiouL4eTkBEdHR4waNQrnz59vjnCJ9BoTIKIGuHXrFhQKRbX/x25jY4P8/Pwnbp+SkoJz585h2rRpTRUiNaP6nA/dunXDpk2bsG/fPmzfvh0VFRXw8fHBtWvXmiNkIr3FmaCJtGjjxo3o2bMn+vXrp+1QSEu8vb3h7e2tXPbx8YG7uzu+/PJLLF68WIuREbVu7AEiaoAOHTpAKpXixo0bKuU3btyAra1trduWlJRg586dmDp1alOGSM2oIedDFUNDQ3h6eiIjI6MpQiSi/8MEiKgBjIyM0KdPHyQkJCjLKioqkJCQoPL/6tXZvXs3SktL8frrrzd1mNRMGnI+VFEoFDh79izkcnlThUlE4C0wogYLDw9HcHAw+vbti379+mH16tUoKSlBSEgIACAoKAj29vaIjIxU2W7jxo0YPXo02rdvr42wqYloej4sWrQIzz//PJ5++mncvXsXn3/+Oa5evcpxYURNjAkQUQONHz8ef/75J+bPn4/8/Hz06tULhw8fVg6Ezc7OhoGBamdreno6kpKS8MMPP2gjZGpCmp4Pd+7cwfTp05Gfn4+nnnoKffr0wYkTJ9C9e3dtHQKRXpAIIYS2g9A1hYWFsLCwQEFBAczNzbUdDukQhQI4fhzIywPkcmDgQEAq1XZUpE08J4h0hybXb/YAEdVRTAwQFgY8+nSygwOwZg0QEKC9uEh7eE4QtVwcBE1UBzExwJgxqhc6AMjNrSyPidFOXKQ9PCeIWjbeAlODt8DoUQoF4Oxc/UJXRSKp/H/9mZm89aEveE4Q6SZNrt/sASJ6guPHa77QAYAQQE5OZT3SDzwniFo+JkBET5CX17j1qOXjOUHU8jEBInqCus5Hx3nr9AfPCaKWjwkQ0RMMHFg5nkMiUb9eIgEcHSvrkX7gOUHU8jEBInoCqbTysWag+gWvann1ag521Sc8J4haPiZARHUQEADs2QPY26uWOzhUlnPOF/3Dc4KoZeNj8GrwMXiqCWf9pcfxnCDSHZwJmqiJSKXA4MHajoJ0Cc8JopaJt8CIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgFqpY8eOYeTIkbCzs4NEIkFsbGydt/3555/Rpk0b9OrVq9ljSExMRO/evWFsbIynn34aW7ZsaVAMRERE6jABaqVKSkrg4eGBdevWabTd3bt3ERQUhKFDhzZ7DJmZmRgxYgSGDBmCtLQ0zJw5E9OmTUNcXFyDYyEiInoUH4Nvpfz9/eHv76/xdm+++SYmTpwIqVSqUa9RY8QQFRUFFxcXrFixAgDg7u6OpKQkrFq1Cn5+fg2KhYiI6FHsASKlzZs348qVK1iwYIFW9p+cnAxfX1+VMj8/PyQnJ2slHiIiar3YA0QAgEuXLmH27Nk4fvw42rTRzmmRn58PGxsblTIbGxsUFhbi/v37kMlkWomLiIhaH/YAERQKBSZOnIiPP/4YXbt21XY4RERETY49QISioiKcOnUKZ86cwYwZMwAAFRUVEEKgTZs2+OGHH/Diiy82eRy2tra4ceOGStmNGzdgbm7O3h8iImpUTIAI5ubmOHv2rErZv//9b/z000/Ys2cPXFxcmiUOb29vHDp0SKUsPj4e3t7ezbJ/IiLSH0yAWqni4mJkZGQolzMzM5GWlgYrKyt06tQJERERyM3NxbZt22BgYIAePXqobG9tbQ0TE5Nq5U0VA1D5BNratWvxwQcfYMqUKfjpp5/wn//8BwcPHqx3DEREROowAWolFArg+HEgLw+QywGF4hR8fYco14eHhwMAgoODsWXLFuTl5SE7O1unYnBxccHBgwfx7rvvYs2aNXBwcMDXX3/NR+CJiKjRSYQQQttB6JrCwkJYWFigoKAA5ubm2g7niWJigLAw4Nq1v8ocHIA1a4CAAP2JgYiI9Jsm128+BdbCxcQAY8aoJh4AkJtbWR4Tox8xEBERaYI9QGq0lB4ghQJwdq6eeFSRSCp7YTIzAam09cZAREQEsAdIbxw/XnPiAQBCADk5lfVacwxERESaYgLUguXlNW69lhoDERGRppgAtWByeePWa6kxEBERaYoJUAs2cGDl+BqJRP16iQRwdKys15pjICIi0hQToBZMKq18zByonoBULa9e3bSDj3UhBiIiIk0xAWrhAgKAPXsAe3vVcgeHyvLmmINHF2IgIiLShFYToKKiIsycORNOTk6QyWTw8fHByZMnletjYmIwfPhwtG/fHhKJBGlpaXVq9+7duwgNDYVcLoexsTG6du1a7R1TrUlAAJCVBRw5AuzYUfnfzMzmTTx0IQYiIqK60uqrMKZNm4Zz584hOjoadnZ22L59O3x9fXHhwgXY29ujpKQEAwYMwLhx4zB9+vQ6tfnw4UMMGzYM1tbW2LNnD+zt7XH16lVYWlo27cFomVQKDB7MGIiIiOpCaxMh3r9/H2ZmZti3bx9GjBihLO/Tpw/8/f3xySefKMuysrLg4uKCM2fOoFevXrW2GxUVhc8//xy///47DA0N6xRLaWkpSktLlcuFhYVwdHTU+YkQiYiI6C8tYiLE8vJyKBQKmJiYqJTLZDIkJSXVu939+/fD29sboaGhsLGxQY8ePbBkyRIoFIoat4mMjISFhYXy4+joWO/9ExERke7TWgJkZmYGb29vLF68GNevX4dCocD27duRnJyMvAbMmnflyhXs2bMHCoUChw4dwrx587BixQqVHqXHRUREoKCgQPnJycmp9/6JiIhI92l1DFB0dDSmTJkCe3t7SKVS9O7dG4GBgTh9+nS926yoqIC1tTW++uorSKVS9OnTB7m5ufj888+xYMECtdsYGxvD2Ni43vskIiKilkWrT4G5urri6NGjKC4uRk5ODlJSUlBWVobOnTvXu025XI6uXbtC+sjEM+7u7sjPz8fDhw8bI2wiIiJq4XRiHiBTU1PI5XLcuXMHcXFxGDVqVL3b6t+/PzIyMlBRUaEs++OPPyCXy2FkZNQY4RIREVELp9UEKC4uDocPH0ZmZibi4+MxZMgQuLm5ISQkBABw+/ZtpKWl4cKFCwCA9PR0pKWlIT8/X9lGUFAQIiIilMtvvfUWbt++jbCwMPzxxx84ePAglixZgtDQ0OY9OCIiItJZWk2ACgoKEBoaCjc3NwQFBWHAgAGIi4tTPr6+f/9+eHp6Kh+TnzBhAjw9PREVFaVsIzs7W2XQtKOjI+Li4nDy5Ek8++yzeOeddxAWFobZs2c378ERERGRztLaPEC6TJN5BIiIiEg3tIh5gIiIiIi0hQkQERER6R0mQERERKR3mAARERGR3mECRERERHqHCRARERHpHSZAREREpHeYABEREZHeYQJEREREeocJEBEREekdJkBERESkd5gAERERkd5hAkRERER6hwkQERER6R0mQERERKR3mAA1s2PHjmHkyJGws7ODRCJBbGxsrfUTExMhkUiqffLz85snYCIiolaICVAzKykpgYeHB9atW6fRdunp6cjLy1N+rK2tmyhCIiKi1q+NtgPQN/7+/vD399d4O2tra1haWjZ+QERERHqIPUAtRK9evSCXyzFs2DD8/PPP2g6HiIioRWMCpOPkcjmioqKwd+9e7N27F46Ojhg8eDBSU1O1HRoREVGLxVtgOq5bt27o1q2bctnHxweXL1/GqlWrEB0drcXIiIiIWi72ALVA/fr1Q0ZGhrbDICIiarGYALVAaWlpkMvl2g6DiIioxeItsGZWXFys0nuTmZmJtLQ0WFlZoVOnToiIiEBubi62bdsGAFi9ejVcXFzwzDPP4MGDB/j666/x008/4YcfftDWIRAREbV4TICa2alTpzBkyBDlcnh4OAAgODgYW7ZsQV5eHrKzs5XrHz58iPfeew+5ublo27Ytnn32Wfz4448qbRAREZFmJEIIoe0gdE1hYSEsLCxQUFAAc3NzbYdDREREdaDJ9ZtjgIiIiEjvMAEiIiIivcMESMfcuXMH5eXl2g6DiIioVWMCpGN69+6tfAKMiIiImgYTIB2Tl5eHkpISbYdBRETUqjEB0iFCCJSWlkImk2k7FCIiolaNCZAOefDgAQAgKysLI0eOhJ2dHSQSCWJjY2vdbvLkyZBIJNU+zzzzTDNETURE1PIwAdIhVQmQEAIeHh5Yt25dnbZbs2YN8vLylJ+cnBxYWVlh7NixTRkuERFRi8WZoHVIVQLk4+ODESNG1Hk7CwsLWFhYKJdjY2Nx584dhISENHqMRERErQF7gHTI/fv3AQAmJiYNamfjxo3w9fWFk5NTY4RFRETU6rAHSIdU9QA1JAG6fv06vv/+e+zYsaOxwiIiImp12AOkQ6oSoIY8BbZ161ZYWlpi9OjRjRQVERFR68MESIc09BaYEAKbNm3CpEmTYGRk1JihERERtSpMgHRIQ2+BHT16FBkZGZg6dWpjhkVERNTqcAyQDqlKgCoqKpCWlqYsz8zMRFpaGqysrNCpUydEREQgNze32iszNm7cCC8vL/To0aM5wyYiImpx2AOkQ6pugV28eBGenp7w9PQEAISHh8PT0xPz588HUPm6jOzsbJVtCwoKsHfvXo16f44dO6bRhIsAsG7dOri7u0Mmk6Fbt258bxkREbVI7AHSIVU9QL6+vhBC1Fhvy5Yt1cosLCxw7949jfZXUlICDw8PTJkyBQEBAU+sv379ekRERGDDhg147rnnkJKSgunTp+Opp57CyJEjNdo3ERGRNjEB0iFVCZCxsXGz7M/f3x/+/v51rh8dHY033ngD48ePBwB07twZJ0+exLJly5gAERFRi8JbYDrkwYMHMDY2hoGBbv4spaWl1QZoy2QypKSkoKysTEtRERERaU43r7R66v79+zU+AfbgwQNcuHChmSNS5efnh6+//hqnT5+GEAKnTp3C119/jbKyMty6dUursREREWmCCZAOefDgQY2TIC5cuBBjxoxp5ohUzZs3D/7+/nj++edhaGiIUaNGITg4GAB0tteKiIhIHV61dMiDBw/U9gAJIfCf//wHAwcO1EJUf5HJZNi0aRPu3buHrKwsZGdnw9nZGWZmZujYsaNWYyMiItIEE6A6qM/j4qWlpZgzZw6cnJxgbGwMZ2dnbNq0qdZtaroFtnHjRmRmZmLPnj113v8333wDDw8PtG3bFnK5HFOmTMH//ve/J25XF4aGhnBwcIBUKsXOnTvxt7/9jT1ARETUovCqVQdVj4uvW7euztuMGzcOCQkJ2LhxI9LT0/Htt9+iW7dutW5T0y2wH3/8ESYmJoiKiqrTvn/++WcEBQVh6tSpOH/+PHbv3q18ZP1RxcXFSEtLU066WDXhYtUcQxEREQgKClLW/+OPP7B9+3ZcunQJKSkpmDBhAs6dO4clS5bUKS4iIiJdwcfg60DTx8UPHz6Mo0eP4sqVK7CysgIAODs7P3E7dbfAhBBITU1FYGAgxo4dW6f9Jycnw9nZGe+88w4AwMXFBW+88QaWLVumUu/UqVMYMmSIcjk8PBwAEBwcjC1btlSbcFGhUGDFihVIT0+HoaEhhgwZghMnTtTp2IiIiHQJe4CawP79+9G3b1989tlnsLe3R9euXfH+++8rZ3quiboE6Ny5c7h06ZJGA6C9vb2Rk5ODQ4cOQQiBGzduYM+ePXj55ZdV6g0ePBhCiGqfqokWt2zZgsTERGV9d3d3nDlzBvfu3UNBQQFiY2Of2KtFRESki9gD1ASuXLmCpKQkmJiY4LvvvsOtW7fw9ttv43//+x82b95c43b379+vdgtsz549MDc3x9ChQ+u8//79++Obb77B+PHj8eDBA5SXl2PkyJEa3cIjIiJqzbTeA1RUVISZM2fCyckJMpkMPj4+OHnypHJ9TEwMhg8fjvbt20Mikai8JLQmW7ZsgUQiUfnU9w3r9VFRUQGJRIJvvvkG/fr1w8svv4yVK1di69attfYCqesB2rt3L0aNGqXR7NAXLlxAWFgY5s+fj9OnT2Pz5s04evQo5HJ5vY+JiIioNdF6AjRt2jTEx8cjOjoaZ8+exfDhw+Hr64vc3FwAlQOQBwwYUG38ypOYm5sjLy9P+bl69WpThK+WXC6Hvb09LCwslGXu7u4QQuDatWs1bvd4AnTx4kWcP39e4/l/IiMj0b9/f7z55pv49ttv8cYbb8DIyAj/+9//kJeXp/kBERERtTJavQV2//597N27F/v27cMLL7wAoHLCv//+979Yv349PvnkE0yaNAkAkJWVpVHbEokEtra2dapbWlqK0tJS5XJhYaFG+3pc//79sXv3bhQXF6Ndu3YAKp+gMjAwgIODQ43bPf4U2N69e9GuXTsMHz5co/2XlJTg2rVr6Nq1K+7evYvZs2dj0KBBGDp0aK0vWSUiItIXWu0BKi8vh0KhUPt+qaSkpAa1XVxcDCcnJzg6OmLUqFE4f/58jXUjIyNhYWGh/Dg6OlZrS5PHxSdOnIj27dsjJCQEFy5cwLFjxzBr1ixMmTKlxpmehRA4d+6c8nUX9+7dw7p16zBs2DCUl5fXef9JSUlITU3FyZMnYW9vj/j4eAwfPhwffvgh+vXrBzs7O82/TCIiotZGaJm3t7cYNGiQyM3NFeXl5SI6OloYGBiIrl27qtTLzMwUAMSZM2ee2OaJEyfE1q1bxZkzZ0RiYqL429/+JszNzUVOTo7a+g8ePBAFBQXKT05OjgAgCgoKhBBCHDlyRACo9gkODhZCCBEcHCwGDRqk0ubFixeFr6+vkMlkwsHBQYSHh4uionviyBEhduwQ4sgRIcrL/6pfWlouAAgrK0exapUQ774bKwCI557zF3Pnqt9/UNBf+3/++efF+PHjBQDRp08f8eqrYcLevrswNpYJuVwuXnvtNXHt2rUn/yBEREQtVEFBgcr1uzYSIbR7T+Ty5cuYMmUKjh07BqlUit69e6Nr1644ffo0Ll68qKyXlZUFFxcXnDlzBr169dJoH2VlZXB3d0dgYCAWL178xPqFhYWwsLBAQUEBzM3NNT0ktWJigLAw4NEhQA4OwJo1lf+uXHcSgDOAjgBKAcwEsAxAZQxSKaBQqG4fFpaKS5e+xLZt22BpaYlXX12C2Nhg5OYaVNtPQECjHAoREZFO0uT6rfXH4F1dXXH06FGUlJSgsLAQcrkc48ePR+fOnRttH4aGhvD09ERGRkajtamJmBhgzBjg8VQzNxd49dVHS5575N/GANar1H80+anaftas5wBUYPbs2ejR4yNMmmSmdj9jxgB79jAJIiIiAnTgKbAqpqamkMvluHPnDuLi4jBq1KhGa1uhUODs2bNaeQxcoajs3VHXz9bQvrfK7efjqae+xMcfR2L27OrJz6P7mTmzehJVJTIyEs899xzMzMxgbW2N0aNHIz09/Ykx7N69G25ubjAxMUHPnj1x6NCh+h4OERFRs9F6AhQXF4fDhw8jMzMT8fHxGDJkCNzc3BASEgIAuH37NtLS0pSDg9PT05GWlob8/HxlG0FBQYiIiFAuL1q0CD/88AOuXLmC1NRUvP7667h69SqmTZvWvAcH4Phx1dtejW8B7tz5B/7979r3I0QFcnK2YffuLLXrjx49itDQUPzyyy+Ij49HWVkZhg8fjpKSkhrbPHHiBAIDAzF16lScOXMGo0ePxujRo3Hu3LkGHhMREVETa/IRSU+wa9cu0blzZ2FkZCRsbW1FaGiouHv3rnL95s2b1Q4AXrBggbLOoEGDlAOShRBi5syZolOnTsLIyEjY2NiIl19+WaSmptY5Jk0GUT3Jjh1CVPbBNO1nxown1Vmi/O7s7e1FXFxcrXHfvHlTABBHjx6tsc64cePEiBEjVMq8vLzEG2+80eDvjYiISFOaXL+1PgZo3LhxGDduXI3rJ0+ejMmTJ9faxqPvqwKAVatWYdWqVY0QXcM11103V9cn1XgfwA28+aYD5PJ7cHFxqbV2QUEBAChf5qpOcnKy8gWqVfz8/BAbG/vkgImIiLRI6wlQazdwYOVTWLm5DR/zo45EUtn+228DK1bUvB+JxBAODquxdm3l02S1qaiowMyZM9G/f3/06NGjxnr5+fmwsbFRKbOxsVG5PUlERKSLtD4GqLWTSv961F0iUV33+LKmqrZfvRowMnryflavfnLyAwChoaE4d+4cdu7c2bAAiYiIdBQToGYQEFD5CLq9vWq5gwOwd2/lp5Y3ZCg9nrw4OKg+2l7bfur6CPyMGTNw4MABHDlypNbXdgCAra0tbty4oVJ248aNOr+ChIiISFu0PhGiLmqKiRCBykfQjx8H8vIqxwYNHPhXUlO1LjcX+PNPoGNHoCqPuHmzsr6PD3DihPrt67qfmggh8M9//hPfffcdEhMT0aVLlycez/jx43Hv3j3897//VZb5+Pjg2WefRVRUVF2/FiIiokahyfWbCZAaTZUA6bK3334bO3bswL59+9CtWzdluYWFhfL9ZUFBQbC3t0dkZCSAysfgBw0ahKVLl2LEiBHYuXMnlixZgtTU1FrHDhERETUFTa7fvAVGAID169ejoKAAgwcPhlwuV3527dqlrJOdnY28vDzlso+PD3bs2IGvvvoKHh4e2LNnD2JjY5n8EBGRzmMPkBr62ANERETU0rEHiIiIiKgWTICIiIhI7zABIiIiIr3DBIiIiIj0DhMgIiIi0jtMgIiIiEjvMAEiIiIivcO3watRNTVSYWGhliMhIiKiuqq6btdlikMmQGoUFRUBABwdHbUcCREREWmqqKgIFhYWtdbhTNBqVFRU4Pr16zAzM4NEItF2OHqtsLAQjo6OyMnJ4azcLQh/t5aHv1nLxN9NlRACRUVFsLOzg4FB7aN82AOkhoGBARwcHLQdBj3C3Nycf9wtEH+3loe/WcvE3+0vT+r5qcJB0ERERKR3mAARERGR3mECRDrN2NgYCxYsgLGxsbZDIQ3wd2t5+Ju1TPzd6o+DoImIiEjvsAeIiIiI9A4TICIiItI7TICIiIhI7zABIiIiIr3DBIi0ZuHChZBIJCofNze3WrfZvXs33NzcYGJigp49e+LQoUPNFC1V0fR327JlS7X6JiYmzRgxAUBubi5ef/11tG/fHjKZDD179sSpU6dq3SYxMRG9e/eGsbExnn76aWzZsqV5giUlTX+3xMTEan9vEokE+fn5zRh1y8CZoEmrnnnmGfz444/K5TZtaj4lT5w4gcDAQERGRuJvf/sbduzYgdGjRyM1NRU9evRojnDp/2jyuwGVs9Smp6crl/mKmeZ1584d9O/fH0OGDMH333+Pjh074tKlS3jqqadq3CYzMxMjRozAm2++iW+++QYJCQmYNm0a5HI5/Pz8mjF6/VWf361Kenq6yszQ1tbWTRlqi8QEiLSqTZs2sLW1rVPdNWvW4KWXXsKsWbMAAIsXL0Z8fDzWrl2LqKiopgyTHqPJ7wZUJjya1KfGtWzZMjg6OmLz5s3KMhcXl1q3iYqKgouLC1asWAEAcHd3R1JSElatWsUEqJnU53erYm1tDUtLyyaKrHXgLTDSqkuXLsHOzg6dO3fGa6+9huzs7BrrJicnw9fXV6XMz88PycnJTR0mPUaT3w0AiouL4eTkBEdHR4waNQrnz59vpkgJAPbv34++ffti7NixsLa2hqenJzZs2FDrNvx70776/G5VevXqBblcjmHDhuHnn39u4khbJiZApDVeXl7YsmULDh8+jPXr1yMzMxMDBw5EUVGR2vr5+fmwsbFRKbOxseG97Wam6e/WrVs3bNq0Cfv27cP27dtRUVEBHx8fXLt2rZkj119XrlzB+vXr0aVLF8TFxeGtt97CO++8g61bt9a4TU1/b4WFhbh//35Th0yo3+8ml8sRFRWFvXv3Yu/evXB0dMTgwYORmprajJG3EIJIR9y5c0eYm5uLr7/+Wu16Q0NDsWPHDpWydevWCWtr6+YIj2rwpN/tcQ8fPhSurq5i7ty5TRwZVTE0NBTe3t4qZf/85z/F888/X+M2Xbp0EUuWLFEpO3jwoAAg7t271yRxkqr6/G7qvPDCC+L1119vzNBaBfYAkc6wtLRE165dkZGRoXa9ra0tbty4oVJ248YNji3Rsif9bo8zNDSEp6dnnetTw8nlcnTv3l2lzN3dvdZblzX9vZmbm0MmkzVJnKSqPr+bOv369ePfmxpMgEhnFBcX4/Lly5DL5WrXe3t7IyEhQaUsPj4e3t7ezREe1eBJv9vjFAoFzp49W+f61HD9+/dXeQoPAP744w84OTnVuA3/3rSvPr+bOmlpafx7U0fbXVCkv9577z2RmJgoMjMzxc8//yx8fX1Fhw4dxM2bN4UQQkyaNEnMnj1bWf/nn38Wbdq0EcuXLxcXL14UCxYsEIaGhuLs2bPaOgS9pOnv9vHHH4u4uDhx+fJlcfr0aTFhwgRhYmIizp8/r61D0DspKSmiTZs24tNPPxWXLl0S33zzjWjbtq3Yvn27ss7s2bPFpEmTlMtXrlwRbdu2FbNmzRIXL14U69atE1KpVBw+fFgbh6CX6vO7rVq1SsTGxopLly6Js2fPirCwMGFgYCB+/PFHbRyCTmMCRFozfvx4IZfLhZGRkbC3txfjx48XGRkZyvWDBg0SwcHBKtv85z//EV27dhVGRkbimWeeEQcPHmzmqEnT323mzJmiU6dOwsjISNjY2IiXX35ZpKamaiFy/fbf//5X9OjRQxgbGws3Nzfx1VdfqawPDg4WgwYNUik7cuSI6NWrlzAyMhKdO3cWmzdvbr6ASQih+e+2bNky4erqKkxMTISVlZUYPHiw+Omnn5o56pZBIoQQ2u6FIiIiImpOHANEREREeocJEBEREekdJkBERESkd5gAERERkd5hAkRERER6hwkQERER6R0mQERERKR3mAARERGR3mECRESNKj8/H8OGDYOpqSksLS21HU6zy8rKgkQiQVpamrZDIaJaMAEiohpNnjwZo0eP1mibVatWIS8vD2lpafjjjz+aJjAtWbhwISQSSa0fR0dH5OXloUePHtoOl4hqwQSIiBrV5cuX0adPH3Tp0gXW1tb1auPhw4eNHFXjeP/995GXl6f8ODg4YNGiRSplUqkUtra2aNOmjbbDJaJaMAEiojobPHgw3nnnHXzwwQewsrKCra0tFi5cqFzv7OyMvXv3Ytu2bZBIJJg8eTIA4O7du5g2bRo6duwIc3NzvPjii/jtt9+U2y1cuBC9evXC119/DRcXF5iYmGi0XXR0NJydnWFhYYEJEyagqKhIWaeiogKfffYZnn76aRgbG6NTp0749NNPletzcnIwbtw4WFpawsrKCqNGjUJWVpba42/Xrh1sbW2VH6lUCjMzM5Wyx2+BJSYmQiKRIC4uDp6enpDJZHjxxRdx8+ZNfP/993B3d4e5uTkmTpyIe/fuqcQdGRkJFxcXyGQyeHh4YM+ePcr1d+7cwWuvvYaOHTtCJpOhS5cu2Lx5s8a/KZG+YgJERBrZunUrTE1N8euvv+Kzzz7DokWLEB8fDwA4efIkXnrpJYwbNw55eXlYs2YNAGDs2LHKC/7p06fRu3dvDB06FLdv31a2m5GRgb179yImJkaZPNRlu8uXLyM2NhYHDhzAgQMHcPToUSxdulS5PiIiAkuXLsW8efNw4cIF7NixAzY2NgCAsrIy+Pn5wczMDMePH8fPP/+Mdu3a4aWXXmr0XqiFCxdi7dq1OHHihDLpWr16NXbs2IGDBw/ihx9+wBdffKGsHxkZiW3btiEqKgrnz5/Hu+++i9dffx1Hjx4FAOXxfP/997h48SLWr1+PDh06NGrMRK2atl9HT0S6Kzg4WIwaNUq5PGjQIDFgwACVOs8995z48MMPlcujRo0SwcHByuXjx48Lc3Nz8eDBA5XtXF1dxZdffimEEGLBggXC0NBQ3Lx5U+Pt2rZtKwoLC5XrZ82aJby8vIQQQhQWFgpjY2OxYcMGtccXHR0tunXrJioqKpRlpaWlQiaTibi4uBq/lypOTk5i1apVKmWZmZkCgDhz5owQQogjR44IAOLHH39U1omMjBQAxOXLl5Vlb7zxhvDz8xNCCPHgwQPRtm1bceLECZW2p06dKgIDA4UQQowcOVKEhIQ8MUYiUo83qYlII88++6zKslwux82bN2us/9tvv6G4uBjt27dXKb9//z4uX76sXHZyckLHjh013s7Z2RlmZmZq47l48SJKS0sxdOjQGmPLyMhQ2R4AHjx4oLKPxvDo92ZjY4O2bduic+fOKmUpKSkAKnvD7t27h2HDhqm08fDhQ3h6egIA3nrrLbz66qtITU3F8OHDMXr0aPj4+DRqzEStGRMgItKIoaGhyrJEIkFFRUWN9YuLiyGXy5GYmFht3aOPyZuamtZru9rikclkNcZVtY8+ffrgm2++qbbu0WSsMTwap0QiqTXu4uJiAMDBgwdhb2+vUs/Y2BgA4O/vj6tXr+LQoUOIj4/H0KFDERoaiuXLlzdq3EStFRMgImpSvXv3Rn5+Ptq0aQNnZ+cm3+5RXbp0gUwmQ0JCAqZNm6Z2H7t27YK1tTXMzc3rtY+m0L17dxgbGyM7OxuDBg2qsV7Hjh0RHByM4OBgDBw4ELNmzWICRFRHHARNRE3K19cX3t7eGD16NH744QdkZWXhxIkTmDNnDk6dOtXo2z3KxMQEH374IT744ANs27YNly9fxi+//IKNGzcCAF577TV06NABo0aNwvHjx5GZmYnExES88847uHbtWqMcf32YmZnh/fffx7vvvoutW7fi8uXLSE1NxRdffIGtW7cCAObPn499+/YhIyMD58+fx4EDB+Du7q61mIlaGvYAEVGTkkgkOHToEObMmYOQkBD8+eefsLW1xQsvvKB8Gqsxt3vcvHnz0KZNG8yfPx/Xr1+HXC7Hm2++CQBo27Ytjh07hg8//BABAQEoKiqCvb09hg4dqvUeocWLF6Njx46IjIzElStXYGlpid69e+Ojjz4CABgZGSEiIgJZWVmQyWQYOHAgdu7cqdWYiVoSiRBCaDsIIiIioubEW2BERESkd5gAERERkd5hAkRERER6hwkQERER6R0mQERERKR3mAARERGR3mECRERERHqHCRARERHpHSZAREREpHeYABEREZHeYQJEREREeuf/A6VHnu4L0L3mAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 5e+06x5e+06 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from adjustText import adjust_text\n",
        "entropies = [x/10 for x in range(0, 21)]\n",
        "# Creating the scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(inference_times, accuracies, c='blue')\n",
        "\n",
        "texts = []\n",
        "for i, txt in enumerate(entropies):\n",
        "    text = ax.annotate(str(txt), (inference_times[i], accuracies[i]))\n",
        "    texts.append(text)\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='black'))\n",
        "plt.figure(figsize=(50000, 50000))\n",
        "ax.set_xlabel('Inference Times')\n",
        "ax.set_ylabel('Accuracies')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
